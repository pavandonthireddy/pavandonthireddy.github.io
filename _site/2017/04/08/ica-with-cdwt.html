<!DOCTYPE html><html lang="en" ><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="ICA with CDWT" /><meta property="og:locale" content="en_US" /><meta name="description" content="ICA with CDWT" /><meta property="og:description" content="ICA with CDWT" /><link rel="canonical" href="http://localhost:4000/2017/04/08/ica-with-cdwt" /><meta property="og:url" content="http://localhost:4000/2017/04/08/ica-with-cdwt" /><meta property="og:site_name" content="Pavan Donthireddy" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2017-04-08T00:00:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ICA with CDWT" /><meta name="twitter:site" content="@" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2017-04-08T00:00:00+01:00","datePublished":"2017-04-08T00:00:00+01:00","description":"ICA with CDWT","headline":"ICA with CDWT","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/04/08/ica-with-cdwt"},"url":"http://localhost:4000/2017/04/08/ica-with-cdwt"}</script><title> ICA with CDWT - Pavan Donthireddy</title><meta charset="UTF-8"><link rel="canonical" href="http://localhost:4000/2017/04/08/ica-with-cdwt" /><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="It is well known that if the original sounds are mixed inthe real environment (in the time domain) then the observedsounds are a convolution mixture between ..."><meta property="og:site_name" content="Pavan Donthireddy"><meta property="og:description" content="It is well known that if the original sounds are mixed inthe real environment (in the time domain) then the observedsounds are a convolution mixture between ..."/><meta property="og:title" content="ICA with CDWT"><meta property="og:type" content="article"><meta property="article:published_time" content="2017-04-08T00:00:00+01:00"><meta property="article:author" content="http://localhost:4000/"><meta property="og:url" content="http://localhost:4000/2017/04/08/ica-with-cdwt" /><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="Pavan Donthireddy" href="/atom.xml"><link rel="alternate" type="application/json" title="Pavan Donthireddy" href="http://localhost:4000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ jax: ["input/TeX","input/MathML","output/SVG", "output/CommonHTML"], extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "CHTML-preview.js"], TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true, processEnvironments: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }, messageStyle: "none", "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }, TeX: { equationNumbers: { autoNumber: "AMS" }, extensions: ["AMSmath.js", "AMSsymbols.js","AMScd.js"], TagSide: "left", Macros: { field: ['\\mathbb{#1}', 1], C: ['\\field{C}'], E: ['\\field{E}'], F: ['\\field{F}'], N: ['\\field{N}'], P: ['\\field{P}'], Q: ['\\field{Q}'], R: ['\\field{R}'], Z: ['\\field{Z}'], ha : ['\\hat{#1}',1], Re: ['\\mathop{\\mathrm{Re}}'], Im: ['\\mathop{\\mathrm{Im}}'], Res: ['\\mathop{\\mathrm{Res}}'], } } }); </script> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full"></script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}.post-archive{font-size:15px;line-height:2;padding-bottom:.8em}.post-archive .date{padding-right:.7em}.pagination{width:100%;padding:0 20px;text-align:center}.pagination ul{list-style:none}.pagination ul li{display:inline;margin:0 5px}.pagination ul li a{color:#000;text-decoration:none}.pagination ul li a:hover{color:gray;text-decoration:underline}.pagination ul li.current-page a{background:#ddd;color:#fff}.post-link{position:relative;display:inline-block}.post-excerpt{display:none;position:absolute;z-index:1;top:100%;left:0;width:100%;padding:10px;background-color:#fff;box-shadow:0 2px 5px rgba(0,0,0,.1)}.post-link:hover .post-excerpt{display:block}.img-padding{width:200px;height:200px;padding:20px 20px 20px 20px}</style></head><body><main role="main"><header role="banner"> <!--<h1 class="logo">Pavan Donthireddy</h1>--><nav role="navigation"><ul><li><a href="/" >Notes</a></li><li><a href="/tags" >Tags</a></li><li><a href="/search" >Search</a></li><li><a href="/about" >About</a></li></ul></nav></header><link rel="stylesheet" href="/assets/js/prism.css"><link rel="stylesheet" href="/assets/js/prism-line-numbers.css"><section class="post"> <script src="/assets/js/prism.js"></script> <script src="/assets/js/prism-line-numbers.js"></script><h1 style="text-align: center;">ICA with CDWT</h1><div style="text-align: center;"><span class="meta"><time datetime="2017-04-08T00:00:00+01:00">April 8, 2017</time> </span></div><div style="text-align: center;"><span class="meta"> <a href="/tag/BlindSourceSeperation">BlindSourceSeperation</a>, <a href="/tag/ICA">ICA</a>, <a href="/tag/CDWT">CDWT</a>, <a href="/tag/STFT">STFT</a>, <a href="/tag/DWT">DWT</a>, <a href="/tag/wavelet">wavelet</a>, <a href="/tag/whitening">whitening</a>, <a href="/tag/ICAissues">ICAissues</a></span></div><p align="justify">It is well known that if the original sounds are mixed in the real environment (in the time domain) then the observed sounds are a convolution mixture between the original sounds with a delay and a reverberation. In order to simplify this convolution mixture, it is a good idea to convert the signal from the time domain into the time–frequency domain and transform the convolution mixture into the linear mixture by a time–frequency analysis method. By doing this the drawback of poor performance with unsteady sounds of the ICA also can be improved.</p><p align="justify">The time-frequency analysis method is usually a combination of the <a class="internal-link" href="/2017/04/06/blind-source-seperation-ica">ICA</a>, the Short Time Fourier Transform (STFT) and the Discrete Wavelet Transform (DWT).</p><p align="justify">The STFT is probably the most common approach for time–frequency analysis. It subdivides the signal into short time segments (it is the same as using a small window to divide the signal), and a discrete Fourier transform is computed for each of these. For each frequency component, however, the window length is fixed. So it is impossible to choose an optimal window for each frequency component, that is, the short time Fourier transform is unable to obtain optimal analysis results for individual frequency components.</p><p align="justify">On the other hand, the DWT that was carried out by Mattal’s fast algorithm also has a drawback of lacking shift invariance although it can solve the problem of the window width and obtain optimal frequency resolution for each frequency component. Fortunately, in order to improve the fault, a Complex Discrete Wavelet Transform (CDWT) was proposed and it has been applied widely to signal and image analysis</p><h2 id="ica-and-cdwt-for-blind-source-seperation">ICA and CDWT for blind source seperation</h2><p>In this method, the signals first were transformed from the time–domain into the time–frequency domain by using the CDWT and then the ICA was carried out in the time–frequency domain. As in traditional methods, such as the STFT + ICA and the DWT + ICA, the following two problems when the ICA processing was carry out in the time–frequency domain occurred. 1. Scaling problem: the signal’s amplitude and phase obtained by the ICA was changed, 2. Permutation problem: the separated signals are replaced at every frequency level mutually.</p><p>This method discuss the technique for solving the scaling and the permutation problems. Finally, the separated signals are obtained by the inverse CDWT.</p><p><img src="/assets/snips/ica_cdwt.png" alt="ICA_CDWT" /></p><p>Here, the case of two sound sources and two mikes has been considered for simplicity. First of all, the two sound signals $x_n(t) (n=1,2,$ where $n$ is the number of channels and $t$ is the time) were observed by mikes from two sound sources $s_{i}(t) ( i =1, 2)$. The relation between the observed signal $x_n(t)$ and the sound source $s_{i}(t)$ is as follows:</p>\[x_{n}(t) = \mathbf{A_{n,i}}(t) \ast S_{i}(t) \tag{1}\]<p>where $\ast$ denotes convolution, the $\mathbf{A_{n,i}}(t)$ , is the impulse response that is from the sound sources to the mikes and can be shown as the following equation:</p>\[\mathbf{A_{n,i}}(t) = \begin{bmatrix} a_{11}(t) &amp; a_{12}(t)\\ a_{21}(t) &amp; a_{22}(t)\\ \end{bmatrix}, n,i = 1,2\]<p>If one transforms the signal $x_{n}(t)$ from the time domain to the time–frequency domain by the CDWT then the (1) can be expressed as (2), in which the convolution of the sound source and the impulse response was changed to simple multiplication.</p>\[x_{n}(\omega , T) = \mathbf{A_{n,i}}(\omega) S_{i}(\omega,T) \tag{2}\]<p>where, $\omega$ is the frequency and $T$ the time in the time–frequency domain.</p><p>Next, whitening of the observed signal was carried out as follows:</p>\[\hat{x}_{n}(\omega , T) = Q(\omega) x_{n}(\omega,T) \tag{3}\]<p>where $\hat{x}_{n}(\omega ,T)$</p><p>is a whitened signal matrix and $Q(\omega)$ a whitened mixture, which can be obtained from the observed mixture signal $x_{n}(\omega , T)$ in each frequency.</p><p>Finally, the ICA was carried out by using the whitened signal matrix $\hat{x}_{n}(\omega , T)$</p><p>, in which the separation matrix $W(\omega)$ can be presumed. As a result, the separated signal $u_{i}(\omega , T)$ shown in (4) can be obtained.</p>\[u_{i}(\omega , T) = W(\omega) \hat{x}_{n}(\omega,T) \tag{4}\]<p>The convolution mixture signal $x_{n}(t)$ shown in (1) can be transformed into the linear mixture signal $x_{n}(\omega, T)$ shown in (2) by using the CDWT which simplifies the preprocessing of the ICA. A complex wavelet like, RI-Daubechies 6 wavelet can be applied as the mother wavelet.</p><h2 id="problem-and-correction-rule-of-ica-processing">Problem and correction rule of ICA processing</h2><p>The ICA is a technique for presuming the sound source $s_{i}(\omega,T)$ and the inverse matrix of $A_{ni}(\omega)$ from statistics without any former information of the observed signal. In this case, the amplitude of the separated signal $u_{i}(\omega,T)$ is a constant times the amplitude of the sound source $s_{i}(\omega,T)$ and a correction is needed.</p><p align="justify">In this method, a similar amplitude change at each frequency level also occurred in the preprocessing by CDWT introduced. This phenomenon is called a scaling irregularity. Furthermore, same as in the traditional method, it is also possible that the separated sound is replaced with noise at every frequency level mutually. This phenomenon is called the permutation problem. Therefore, after these two problems are solved, the inverse complex discrete wavelet transform is performed, and it is necessary to restore the sound signal observed with each mike.</p><h3 id="scaling-problem-and-correction-rule">Scaling problem and correction rule</h3><p>Not only the amplitude of the restored signal but the phase also differs depending on the frequency by making for signal whitening (making no correlation). To take an arbitrary complex value by processing, this is caused. In order to solve the scaling irregularity problem, a method has been proposed by Murata that uses the independent element $u_{i}(\omega,T)$ , which is obtained at each frequency and divides the spectrum. In this study, the method of correcting scaling is adopted from the divided spectrum and can be shown as follows:</p>\[v_{1}(\omega,T)=\begin{bmatrix} v_{11}(\omega,T)\\ v_{12}(\omega,T) \end{bmatrix} = (W(\omega)Q(\omega))^{-1}\begin{bmatrix} u_{1}(\omega,T) \\ 0 \end{bmatrix}\] \[v_{2}(\omega,T)=\begin{bmatrix} v_{21}(\omega,T)\\ v_{22}(\omega,T) \end{bmatrix} = (W(\omega)Q(\omega))^{-1}\begin{bmatrix} 0 \\ u_{2}(\omega,T) \end{bmatrix}\]<p>where $v_{11}(\omega,T),v_{22}(\omega,T)$ are divided spectrums. If the sum $v_{1}(\omega,T)+v_{2}(\omega,T)$ is calculated then the sum $v_{11}(\omega,T)+v_{21}(\omega,T)$ is the mixture signal $x_{1}(\omega,T)$ and the sum $v_{11}(\omega,T)+v_{22}(\omega,T)$ is the mixture signal $x_{2}(\omega,T)$</p><h3 id="permutation-problem-and-correction-rule">Permutation problem and correction rule</h3><p align="justify">The complex Fast-ICA performs separation based on non-Gaussian characteristics. Therefore, the possibility of the separating signal with higher non-Gaussian characteristics being output as the first channel is very high. However, the height of the frequency is not determined and noise with low non-Gaussian characteristics might also be output.</p><p>Therefore, there is a possibility that the output of each frequency level is separated without being united by the sound. The separated signal $u_{1}(\omega,T), u_{2}(\omega,T)$ of the 1st and 2nd channel without permutation is shown as follows.</p>\[u_{1}(\omega ,k) \approx s_{1}(\omega,T) \tag{5} ; u_{2}(\omega ,k) \approx s_{2}(\omega,T)\]<p>The above expression can be shown as the following equation by using the divided spectrum of the scaling correction.</p>\[\begin{bmatrix} v_{11}(\omega,T)\\ v_{22}(\omega,T) \end{bmatrix} = \begin{bmatrix} g_{11}(\omega,T)u_{1}(\omega,T) \\ g_{21}(\omega,T)u_{1}(\omega,T) \end{bmatrix}\] \[\begin{bmatrix} v_{21}(\omega,T)\\ v_{22}(\omega,T) \end{bmatrix} = \begin{bmatrix} g_{12}(\omega,T)u_{2}(\omega,T) \\ g_{22}(\omega,T)u_{2}(\omega,T) \end{bmatrix}\]<p>On the other hand, when permutation occurs, (5) becomes the next expression</p>\[u_{1}(\omega ,k) \approx s_{2}(\omega,T) \tag{6} ; u_{2}(\omega ,k) \approx s_{1}(\omega,T)\] \[\begin{bmatrix} v_{11}(\omega,T)\\ v_{22}(\omega,T) \end{bmatrix} = \begin{bmatrix} g_{12}(\omega,T)u_{2}(\omega,T) \\ g_{22}(\omega,T)u_{2}(\omega,T) \end{bmatrix}\] \[\begin{bmatrix} v_{21}(\omega,T)\\ v_{22}(\omega,T) \end{bmatrix} = \begin{bmatrix} g_{11}(\omega,T)u_{1}(\omega,T) \\ g_{21}(\omega,T)u_{1}(\omega,T) \end{bmatrix}\]<p>From these, we can know that the divided spectrum can be shown as a multiplication of the separated signal $u_{i}(\omega,T)$ and the transfer function $g_{ni}(\omega)$ , which is from the sound source to the mike.</p><p>The separation matrix $W(\omega)$ and the whitening matrix $Q(\omega)$ presumed by the ICA processing are used and the next equation can be obtained.</p>\[D = (W(\omega)Q(\omega))^{-1} = \begin{bmatrix} g_{11}(\omega) &amp; g_{12}(\omega) \\ g_{21}(\omega) &amp; g_{22}(\omega) \end{bmatrix} = e\begin{bmatrix} a_{11}(\omega) &amp; a_{12}(\omega) \\ a_{21}(\omega) &amp; a_{22}(\omega) \end{bmatrix} = eA_{ni}(\omega), e \in \mathbb{R}\]<h2 id="conclusion">Conclusion</h2><p>CDWT +Complex Value Fast ICA outperforms, STFT+ Complex value Fast ICA and DWT+Real Value Fast ICA</p><p>Reference : BLIND SOURCE SEPARATION BY COMBINING INDEPANDENT COMPONENT ANALYSIS WITH COMPLEX DISCRETE WAVELET TRANSFORM ZHONG ZHANG , TAKESHI ENOMOTO , TETSUO MIYAKE , TAKASHI IMAMURA</p><hr> <side style="font-size: 0.9em"><h3 style="margin-bottom: 1em">Notes mentioning this note</h3><div style="font-size: 0.9em"><p> There are no notes linking to this note.</p></div></side> <a href="" class="post-link"><h2></h2><p class="post-excerpt"></p></a> <script src="https://giscus.app/client.js" data-repo="pavandonthireddy/pavandonthireddy.github.io" data-repo-id="[ENTER REPO ID HERE]" data-category="[ENTER CATEGORY NAME HERE]" data-category-id="[ENTER CATEGORY ID HERE]" data-mapping="url" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light_high_contrast" data-lang="en" data-loading="lazy" crossorigin="anonymous" async> </script></section></main><div class="center"> <a href='https://ko-fi.com/G2G3KNTHM' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://storage.ko-fi.com/cdn/kofi5.png?v=3' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a></div></body></html>
