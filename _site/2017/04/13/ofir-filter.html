<!DOCTYPE html><html lang="en" ><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Optimal Finite Impulse Response (OFIR) Filter" /><meta property="og:locale" content="en_US" /><meta name="description" content="Optimal Finite Impulse Response (OFIR) Filter" /><meta property="og:description" content="Optimal Finite Impulse Response (OFIR) Filter" /><link rel="canonical" href="http://localhost:4000/2017/04/13/ofir-filter" /><meta property="og:url" content="http://localhost:4000/2017/04/13/ofir-filter" /><meta property="og:site_name" content="Pavan Donthireddy" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2017-04-13T00:00:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Optimal Finite Impulse Response (OFIR) Filter" /><meta name="twitter:site" content="@" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2017-04-13T00:00:00+01:00","datePublished":"2017-04-13T00:00:00+01:00","description":"Optimal Finite Impulse Response (OFIR) Filter","headline":"Optimal Finite Impulse Response (OFIR) Filter","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/04/13/ofir-filter"},"url":"http://localhost:4000/2017/04/13/ofir-filter"}</script><title> Optimal Finite Impulse Response (OFIR) Filter - Pavan Donthireddy</title><meta charset="UTF-8"><link rel="canonical" href="http://localhost:4000/2017/04/13/ofir-filter" /><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="The Kalman filter (KF) is themost widely used real-time optimal estimator. However, the KF is aBayesian estimator and its recursive algorithm has the infinit..."><meta property="og:site_name" content="Pavan Donthireddy"><meta property="og:description" content="The Kalman filter (KF) is themost widely used real-time optimal estimator. However, the KF is aBayesian estimator and its recursive algorithm has the infinit..."/><meta property="og:title" content="Optimal Finite Impulse Response (OFIR) Filter"><meta property="og:type" content="article"><meta property="article:published_time" content="2017-04-13T00:00:00+01:00"><meta property="article:author" content="http://localhost:4000/"><meta property="og:url" content="http://localhost:4000/2017/04/13/ofir-filter" /><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="Pavan Donthireddy" href="/atom.xml"><link rel="alternate" type="application/json" title="Pavan Donthireddy" href="http://localhost:4000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ jax: ["input/TeX","input/MathML","output/SVG", "output/CommonHTML"], extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "CHTML-preview.js"], TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true, processEnvironments: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }, messageStyle: "none", "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }, TeX: { equationNumbers: { autoNumber: "AMS" }, extensions: ["AMSmath.js", "AMSsymbols.js","AMScd.js"], TagSide: "left", Macros: { field: ['\\mathbb{#1}', 1], C: ['\\field{C}'], E: ['\\field{E}'], F: ['\\field{F}'], N: ['\\field{N}'], P: ['\\field{P}'], Q: ['\\field{Q}'], R: ['\\field{R}'], Z: ['\\field{Z}'], ha : ['\\hat{#1}',1], Re: ['\\mathop{\\mathrm{Re}}'], Im: ['\\mathop{\\mathrm{Im}}'], Res: ['\\mathop{\\mathrm{Res}}'], } } }); </script> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full"></script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}.post-archive{font-size:15px;line-height:2;padding-bottom:.8em}.post-archive .date{padding-right:.7em}.pagination{width:100%;padding:0 20px;text-align:center}.pagination ul{list-style:none}.pagination ul li{display:inline;margin:0 5px}.pagination ul li a{color:#000;text-decoration:none}.pagination ul li a:hover{color:gray;text-decoration:underline}.pagination ul li.current-page a{background:#ddd;color:#fff}.post-link{position:relative;display:inline-block}.post-excerpt{display:none;position:absolute;z-index:1;top:100%;left:0;width:100%;padding:10px;background-color:#fff;box-shadow:0 2px 5px rgba(0,0,0,.1)}.post-link:hover .post-excerpt{display:block}.img-padding{width:200px;height:200px;padding:20px 20px 20px 20px}</style></head><body><main role="main"><header role="banner"> <!--<h1 class="logo">Pavan Donthireddy</h1>--><nav role="navigation"><ul><li><a href="/" >Notes</a></li><li><a href="/tags" >Tags</a></li><li><a href="/search" >Search</a></li><li><a href="/about" >About</a></li></ul></nav></header><link rel="stylesheet" href="/assets/js/prism.css"><link rel="stylesheet" href="/assets/js/prism-line-numbers.css"><section class="post"> <script src="/assets/js/prism.js"></script> <script src="/assets/js/prism-line-numbers.js"></script><h1 style="text-align: center;">Optimal Finite Impulse Response (OFIR) Filter</h1><div style="text-align: center;"><span class="meta"><time datetime="2017-04-13T00:00:00+01:00">April 13, 2017</time> </span></div><div style="text-align: center;"><span class="meta"> <a href="/tag/filters">filters</a>, <a href="/tag/OFIR">OFIR</a>, <a href="/tag/FIR">FIR</a>, <a href="/tag/IIR">IIR</a>, <a href="/tag/kalman">kalman</a></span></div><p align="justify">The Kalman filter (KF) is the most widely used real-time optimal estimator. However, the KF is a Bayesian estimator and its recursive algorithm has the infinite impulse response (IIR), owing to which the KF often suffers of insufficient robustness. Better robustness is inherent to finite memory filters and to filters with finite impulse response (FIR).</p><p>Unlike the KF, the FIR filter utilizes measurements on an interval of N most recent neighbouring points called horizon. Compared to the KF, FIR filters demonstrate many useful properties such as the bound input/ bound output (BIBO) stability, higher robustness against temporary model uncertainties and round-off errors , and lower sensitivity to noise.</p><h3 id="preliminaries">Preliminaries</h3><p>Consider a general class of discrete-time linear systems represented in state-space with time-variant coefficients as</p>\[x_{k}=A_{k} x_{k-1}+B_{k} w_{k} \tag{1}\]<p>\(y_{k}=C_{k} x_{k}+v_{k}\tag{2}\) in which $k$ is the discrete time index, $x_{k} \in \mathbb{R}^{n}$ is the state vector, $y_{k} \in \mathbb{R}^{p}$ is the measurement vector, and $A_{k} \in \mathbb{R}^{n \times n}, B_{k} \in \mathbb{R}^{n \times u}$, and $C_{k} \in \mathbb{R}^{p \times n}$ are time-variant matrices. Here, $w_{k} \in \mathbb{R}^{u}$ and $v_{k} \in \mathbb{R}^{p}$ are additive process and measurement noise sources with known covariances</p><p>$Q_k=\E ( w_k w_{k}^{T} ) $ and $R_{k}=\mathbb{E}( v_{k} v_{k}^{T})$, respectively. We suppose that $w_{k}$ and $v_{k}$ are zero mean, white, and mutually uncorrelated; that is, $\mathbb{E}( w_{k})=0$, $\mathbb{E}( v_{k})=0, \mathbb{E}(w_{k} w_{j}^{T})=0$ and $\mathbb{E}( v_{k} v_{j}^{T})=0$ for all $k$ and $j \neq k$, and $\mathbb{E}( w_{k} v_{j}^{T})=0$ for all $k$ and $j$.</p><p>The FIR filter requires simultaneously $N$ data points taken from the horizon $[l=k-N+1, k]$. Therefore, (1) and (2) need to be extended on $[l, k]$. That can be done if to use the recursively computed forward in-time solutions and write</p>\[X_{k, l}=A_{k, l} x_{l}+B_{k, l} W_{k, l}\tag{3}\] \[Y_{k, l}=C_{k, l} x_{l}+H_{k, l} W_{k, l}+V_{k, l} \tag{5}\]<p>where the extended vectors are $X_{k, l}=\left[x_{k}^{T}, x_{k-1}^{T}, \ldots, x_{l}^{T}\right]^{T} \in \mathbb{R}^{N n \times 1}$, $Y_{k, l}=\left[y_{k}^{T}, y_{k-1}^{T}, \ldots, y_{l}^{T}\right]^{T} \in \mathbb{R}^{N p \times 1}, W_{k, l}=\left[w_{k}^{T}, w_{k-1}^{T}, \ldots, w_{l}^{T}\right]^{T} \in \mathbb{R}^{N u \times 1}$, and $V_{k, l}=\left[v_{k}^{T}, v_{k-1}^{T}, \ldots, v_{l}^{T}\right]^{T} \in \mathbb{R}^{N p \times 1}$. The extended $k$ - and $N$-variant matrices $A_{k, l} \in \mathbb{R}^{N n \times n}, B_{k, l} \in \mathbb{R}^{N n \times N u}, C_{k, l} \in \mathbb{R}^{N p \times n}$, and $H_{k, l} \in \mathbb{R}^{N p \times N u}$ can be represented as, respectively,</p><p>\(A_{k, l}=\left[\mathscr{A}_{k, l+1}^{T}, \mathscr{A}_{k-1, l+1}^{T}, \ldots, \mathscr{A}_{l+1, l+1}^{T}, I\right]^{T}\) \(B_{k, l}=\left[\begin{array}{ccccc}B_{k} &amp; \mathscr{A}_{k, k} B_{k-1} &amp; \cdots &amp; \mathbf{A}_{k, l+2} B_{l+1} &amp; \mathscr{A}_{k, l+1} B_{l} \\ 0 &amp; B_{k-1} &amp; \cdots &amp; \mathscr{A}_{k-1, l+2} B_{l+1} &amp; \mathscr{A}_{k-1, l+1} B_{l} \\ \vdots &amp; \vdots &amp; \cdots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; B_{l+1} &amp; \mathscr{A}_{l+1, l+1} B_{l} \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; B_{l}\end{array}\right]\) ,</p>\[C_{k, l}=\bar{C}_{k, l} A_{k, l}\] \[H_{k, l}=\bar{C}_{k, l} B_{k, l}\]<p>where</p>\[\bar{C}_{k, l}=\operatorname{diag}\left(C_{k} C_{k-1} \cdots C_{l}\right)\] \[\mathbf{A}_{i, j}=\prod_{r=0}^{i-j} A_{i-r}=A_{i} A_{i-1} \ldots A_{j}\]<p>At the initial horizon point, (3) becomes $x_{l}=x_{l}+B_{l} w_{l}$ that is uniquely satisfied if $w_{l}$ is zero-valued, provided that $B_{l}$ is not zeroth. That means that the initial state must be known in advance or estimated optimally.</p><p>The FIR filtering estimate can be obtained at $k$ via (4) using the discrete convolution as</p>\[\hat{x}_{k \mid k}=K_{k} Y_{k, l} \tag{5}\]<p>where $x_{t \vert r} $ means the estimate at $t$ via measurements from the past to and including at $r$ and $K_{k}$ is the FIR filter gain, which needs to be defined to obey some cost function. Note that the aforementioned inherent properties of FIR filtering are associated with the fact that measurements prior to $l$ are discarded in (5) and thus do not affect the estimate unlike in the KF which has IIR. It is also necessary to emphasize that when the system considered is time-invariant, the FIR estimate (5) will becomes $x_{k \mid k}=K_{N} Y_{k, l}$, which means that the filter gain $K_{N}$ is time-invariant and can be determined off-line once the horizon length $N$ is available. In this case, $K_{N}$ is not necessarily to be realized into iterative computation structure.</p><p>The optimal gain $K_{k}$ can be obtained for (5) in the minimum MSE sense by minimizing the trace of the MSE as</p>\[\hat{K}_{k}=\underset{K_{k}}{\arg \min } E\left\{\operatorname{tr}\left(e_{k} e_{k}^{T}\right)\right\}\]<p>where $e_{k}=x_{k}-x_{k \mid k}$ is the estimation error. Provided $x_{k \mid k}$ via (5), the one-step prediction required by feedback control and associated with receding horizon filtering can be formed as $x_{k+1 \mid k}=A_{k+1} x_{k \mid k}$, similarly to the KF.</p><h3 id="ofir-algorithm">OFIR algorithm</h3><p>Given the model (1) and (2) with white and mutually uncorrelated noise processes $w_{k}$ and $v_{k}$ which have covariances $Q_{k}$ and $R_{k}$, respectively. The iterative form for OFIR estimate (10) with gain (16) is the following,</p>\[\begin{aligned} \Xi_{i}= &amp; A_{i} \Xi_{i-1} A_{i}^{T}+B_{i} Q_{i} B_{i}^{T}-A_{i} \Xi_{i-1} C_{i-1}^{T} \\ &amp; \times\left(R_{i-1}+C_{i-1} \Xi_{i-1} C_{i-1}^{T}\right)^{-1} C_{i-1} \Xi_{i-1} A_{i}^{T} \\ G_{i}= &amp; \Xi_{i} C_{i}^{T}\left(R_{i}+C_{i} \Xi_{i} C_{i}^{T}\right)^{-1} \end{aligned} \tag{6}\] \[\hat{x}_{i \mid i}=A_{i} \hat{x}_{i-1 \mid i-1}+G_{i}\left(y_{i}-C_{i} A_{i} \hat{x}_{i-1 \mid i-1}\right)\tag{7}\]<p>where $i$ ranges from $l+1$ to $k$ and the output is taken when $i=k$. The initial state $x_{l \vert l}$ is given and the initial prior error $\Xi_{i}$ is provided at l by</p><p>$\Xi_{l}=\Theta_{x, l}+B_{l} Q_{l} B_{l}^{T}$</p><p>where $\Theta_{x, l}$ is given.</p><p>As can be seen (7), is the Kalman-like recursion in which $A_{i} x_{i-1 \mid i-1}$ predicts the state from $i-1$ to $i$ and the bias correction gain (6) corrects the prediction for the residual. Although the KF and OFIR filter both minimize the MSE, $G_{i}$ is not the Kalman gain, because the KF has IIR. However, an increase in the horizon length $N$ reduces the estimation error and makes it such that the OFIR estimate converges to the KF estimate: the estimates become practically equal when $N&gt;N_{\mathrm{opt}}$ . In this sense, the KF can be considered as a special case of a more general OFIR filter when $N=\infty$, provided the initial conditions. Another difference is that $N$ measurements are processed by the OFIR filter simultaneously at each time index $k$, while only one measurement is processed by the KF at $k$. That means that the computational complexity of OFIR filter $\mathcal{O}(N)$ is $N$ times larger than $\mathcal{O}(1)$ of the KF. On the other hand, the iterative algorithm reduces essentially the computational complexity $\mathcal{O}\left(N^{2}\right)$ of the batch OFIR form.</p><hr> <side style="font-size: 0.9em"><h3 style="margin-bottom: 1em">Notes mentioning this note</h3><div style="font-size: 0.9em"><p> There are no notes linking to this note.</p></div></side> <a href="" class="post-link"><h2></h2><p class="post-excerpt"></p></a> <script src="https://giscus.app/client.js" data-repo="pavandonthireddy/pavandonthireddy.github.io" data-repo-id="[ENTER REPO ID HERE]" data-category="[ENTER CATEGORY NAME HERE]" data-category-id="[ENTER CATEGORY ID HERE]" data-mapping="url" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light_high_contrast" data-lang="en" data-loading="lazy" crossorigin="anonymous" async> </script></section></main></body></html>
