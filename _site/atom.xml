<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Pavan Donthireddy</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2023-04-23T17:19:57+01:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Pavan Donthireddy</name>
   <email>quarterpastix@gmail.com</email>
 </author>

 
 <entry>
   <title>Switching Kalman Filter and Its Variants</title>
   <link href="http://localhost:4000/2023/04/22/switching-kalman-filter"/>
   <updated>2023-04-22T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/22/switching-kalman-filter</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;A Kalman filter is a widely used algorithm that provides optimal estimation of a state variable based on a series of noisy measurements. It makes use of the past measurements and uses them, along with the system dynamics, to predict the future state of the system. This predicted state is then compared with the actual measurement, and the filter generates an optimal estimation of the true state. However, the standard Kalman filter assumes that the underlying system behaves in a certain way, and if the assumption is incorrect, the filter may not perform optimally. In such cases, we need to switch between multiple Kalman filters to estimate the system state accurately. This article discusses the switching Kalman filter and its variants.&lt;/p&gt;

&lt;h1 id=&quot;switching-kalman-filter&quot;&gt;Switching Kalman Filter&lt;/h1&gt;
&lt;p&gt;A switching Kalman filter (SKF) is an extension of the standard Kalman filter that efficiently addresses the problem of switching between different models. The idea behind SKF is to use a set of different models that describe the different regimes of the system. In each regime, a different Kalman filter is used to estimate the system state.&lt;/p&gt;

&lt;p&gt;Consider a system with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; different regimes, and let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z_t&lt;/code&gt; be a discrete random variable that takes values in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{1, 2, ..., N}&lt;/code&gt; at time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;, indicating which regime the system is currently in. Further, let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_t&lt;/code&gt; be the state of the system at time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_t&lt;/code&gt; be the observation (measurement) of the system at time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;. Assuming that the system transitions between regimes according to a Markov process, the state transition equation can be written as follows:&lt;/p&gt;

\[x_t = A_{z_t} x_{t-1} + w_t\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w_t&lt;/code&gt; is a zero-mean Gaussian noise with covariance &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Q_{z_t}&lt;/code&gt;. The observation equation is given by:&lt;/p&gt;

\[y_t = H_{z_t} x_t + v_t\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v_t&lt;/code&gt; is a zero-mean Gaussian noise with covariance &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R_{z_t}&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A_i, H_i, Q_i, R_i&lt;/code&gt; are the state model, observation model, process noise covariance, and measurement noise covariance, respectively, for regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The SKF algorithm consists of two steps: (i) filtering, and (ii) mode estimation.&lt;/p&gt;

&lt;h2 id=&quot;filtering-with-switching-kalman-filter&quot;&gt;Filtering with switching Kalman Filter&lt;/h2&gt;
&lt;p&gt;In the first step, we use a set of Kalman filters to filter the observations &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_t&lt;/code&gt; and estimate the state &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_t&lt;/code&gt; in each regime. Suppose we have &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; different Kalman filters, each corresponding to a different regime. For each regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, the Kalman filter consists of the following equations:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prediction step:&lt;/strong&gt;&lt;/p&gt;

\[\hat{x}_{t|t-1}^{(i)} = A_{i} \hat{x}_{t-1|t-1}^{(i)}\]

\[P_{t|t-1}^{(i)} = A_{i} P_{t-1|t-1}^{(i)} A_{i}^T + Q_{i}\]

&lt;p&gt;&lt;strong&gt;Update step:&lt;/strong&gt;&lt;/p&gt;

\[K_t^{(i)} = P_{t|t-1}^{(i)} H_{i}^T [H_{i} P_{t|t-1}^{(i)} H_{i}^T + R_{i}]^{-1}\]

\[\hat{x}_{t|t}^{(i)} = \hat{x}_{t|t-1}^{(i)} + K_t^{(i)} (y_t - H_{i} \hat{x}_{t|t-1}^{(i)})\]

\[P_{t|t}^{(i)} = (I - K_t^{(i)} H_{i}) P_{t|t-1}^{(i)}\]

&lt;p&gt;Here, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P_{t|t}^{(i)}&lt;/code&gt; is the error covariance matrix of the Kalman filter for regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; at time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;K_t^{(i)}&lt;/code&gt; is the Kalman gain matrix, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_t&lt;/code&gt; is the observation at time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;mode-estimation&quot;&gt;Mode Estimation&lt;/h2&gt;
&lt;p&gt;Once we have the estimated state &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_t&lt;/code&gt; and error covariance matrix &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P_{t|t}^{(i)}&lt;/code&gt; for each regime, we need to estimate the mode &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z_t&lt;/code&gt; of the system, which tells us which regime the system is currently in. This is done using Bayesian model selection. We estimate the posterior probability of each model given the observations up to time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;:&lt;/p&gt;

\[P(z_t = i | y_{1:t}) = \frac{P(y_{1:t}|z_t=i)P(z_t=i)}{\sum_{j=1}^N P(y_{1:t}|z_t=j)P(z_t=j)}\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(z_t=i)&lt;/code&gt; is the prior probability of regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(y_{1:t}|z_t=i)&lt;/code&gt; is the likelihood of the observations up to time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; given that the system is in regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;. The prior probabilities can be set uniformly, i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(z_t=i) = 1/N&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The likelihood can be computed using the Kalman filter prediction and update steps as follows:&lt;/p&gt;

\[P(y_{1:t}|z_t=i) = \int P(y_t|x_t) P(x_t|x_{t-1}, z_t=i)dx_t\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(x_t|x_{t-1}, z_t=i)&lt;/code&gt; is the state transition probability for regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(y_t|x_t)&lt;/code&gt; is the observation probability. These probabilities are given by the state model and observation model for each regime.&lt;/p&gt;

&lt;p&gt;Once we have computed the posterior probabilities, the mode &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z_t&lt;/code&gt; can be estimated as:&lt;/p&gt;

\[\hat{z}_t = \arg\max_{i=1}^N P(z_t=i|y_{1:t})\]

&lt;h1 id=&quot;variants-of-switching-kalman-filter&quot;&gt;Variants of Switching Kalman Filter&lt;/h1&gt;
&lt;p&gt;The SKF algorithm described above assumes that the models for different regimes are known a priori. In practice, the models may not be known, or they may change over time. To address these issues, several variants of SKF have been proposed.&lt;/p&gt;

&lt;h2 id=&quot;adaptive-switching-kalman-filter&quot;&gt;Adaptive Switching Kalman Filter&lt;/h2&gt;
&lt;p&gt;The adaptive switching Kalman filter (ASKF) is a variant of SKF that adapts to changes in the system. It is based on the assumption that the parameters of the different regimes may change slowly over time. The ASKF estimates the parameters of each regime using a recursive least-squares algorithm and updates them periodically.&lt;/p&gt;

&lt;p&gt;The state transition equation for the ASKF can be written as:&lt;/p&gt;

\[x_t = A_{\theta_t} x_{t-1} + w_t\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A_{\theta_t}&lt;/code&gt; is the state model parameterized by a vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;theta_t&lt;/code&gt;. The observation equation is the same as that for SKF.&lt;/p&gt;

&lt;p&gt;The ASKF algorithm consists of the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize the state &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_0&lt;/code&gt; and the error covariance matrix &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P_0&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;For each regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, initialize the state model parameters &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;theta_i&lt;/code&gt; using a set of prior values.&lt;/li&gt;
  &lt;li&gt;For each time step &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;, do the following:
 a. Using the current mode estimate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z_t&lt;/code&gt;, compute the Kalman filter prediction and update as described above.
 b. Update the state model parameters for each regime using a recursive least-squares algorithm.
 c. Compute the posterior probabilities and estimate the mode &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z_t&lt;/code&gt; as described above.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The recursive least-squares algorithm updates the state model parameters &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;theta_t^{(i)}&lt;/code&gt; as follows:&lt;/p&gt;

\[\theta_t^{(i)} = \theta_{t-1}^{(i)} + K_t^{(i)}[y_t - H_i \hat{x}_{t|t-1}^{(i)}]x_{t-1}^T\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;K_t^{(i)}&lt;/code&gt; is the Kalman gain matrix for regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_{t-1}&lt;/code&gt; is the state at time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t-1&lt;/code&gt;. The error covariance of the parameter estimate is updated as follows:&lt;/p&gt;

\[P_{\theta,t}^{(i)} = P_{\theta,t-1}^{(i)} - K_t^{(i)} [H_i P_{t|t-1}^{(i)} H_i^T + R_i] K_t^{(i)T}\]

&lt;p&gt;The state model parameters can also be regularized to prevent overfitting.&lt;/p&gt;

&lt;h2 id=&quot;particle-switching-kalman-filter&quot;&gt;Particle Switching Kalman Filter&lt;/h2&gt;
&lt;p&gt;The particle filtering approach to the SKF is called the particle switching Kalman filter (PSKF). In the PSKF, we use a set of particle filters instead of Kalman filters to estimate the state in each regime. Particle filtering is a non-parametric approach to filtering that approximates the posterior distribution of the state using a set of weighted particles.&lt;/p&gt;

&lt;p&gt;The PSKF algorithm consists of the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize a set of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; particles for each regime.&lt;/li&gt;
  &lt;li&gt;For each time step &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;, do the following:
 a. For each regime &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, propagate the particles using the state transition equation and compute the weights based on the observation model.
 b. Resample the particles with replacement based on their weights, and compute the Kalman filter prediction and update for each regime.
 c. Compute the posterior probabilities and estimate the mode &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z_t&lt;/code&gt; as described above.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The PSKF has several advantages over the SKF. It can handle non-linear and non-Gaussian models and does not make any assumptions about the system dynamics. However, it is computationally expensive and requires a large number of particles to get accurate estimates.&lt;/p&gt;

&lt;h1 id=&quot;implementation-in-python&quot;&gt;Implementation in Python&lt;/h1&gt;
&lt;p&gt;In this section, we provide an implementation of the SKF algorithm in Python using NumPy and SciPy. We assume that the state and observation models for each regime are known a priori.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KalmanFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P0&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SwitchingKalmanFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pz0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pz0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pz0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;compute_posterior&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_posterior&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;likelihoods&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;likelihoods&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;likelihoods&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;likelihoods&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_error_cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;__main__&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;H1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Q1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;R1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x01&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P01&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;H2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Q2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;R2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x02&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P02&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;KalmanFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;KalmanFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SwitchingKalmanFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_error_cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is a simple example of SKF with two regimes, where the state model and observation model for each regime are the same. We define the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KalmanFilter&lt;/code&gt; class to represent the Kalman filter for each regime and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SwitchingKalmanFilter&lt;/code&gt; class to represent the SKF. The functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;predict&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;update&lt;/code&gt; implement the Kalman filter prediction and update steps, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;compute_posterior&lt;/code&gt; computes the posterior probabilities of each regime.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main&lt;/code&gt; function, we define two regimes with different state models and observation models, and we use SKF to estimate the system state based on noisy measurements. We generate the measurements using a Gaussian distribution with mean &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt; and covariance &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R1&lt;/code&gt;. Finally, we print the estimated state and error covariance.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Expectation Maximization for Change Point Detection in Time Series</title>
   <link href="http://localhost:4000/2023/04/21/em-turning-points"/>
   <updated>2023-04-21T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/21/em-turning-points</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Change point detection in time series data is a fundamental problem in statistics and machine learning. A change point is a time at which some property of the time series changes abruptly. For example, a change point in stock prices could indicate a shift in market trends or a significant world event. Change point detection is therefore useful in many applications such as finance, weather forecasting, and medical research.&lt;/p&gt;

&lt;p&gt;One approach for detecting change points is the Expectation Maximization (EM) algorithm. The EM algorithm is a powerful tool for finding the underlying structure of data that has been generated from an unknown source. It works by iteratively fitting a statistical model to the data, estimating the parameters of the model, and then using those parameters to predict the underlying structure of the data.&lt;/p&gt;

&lt;p&gt;In this article, we will start by introducing the EM algorithm and its basic principles. We will then explain how it can be used to detect change points in time series data. Finally, we will demonstrate the algorithm through a Python implementation.&lt;/p&gt;

&lt;h2 id=&quot;the-expectation-maximization-algorithm&quot;&gt;The Expectation Maximization Algorithm&lt;/h2&gt;

&lt;p&gt;The Expectation Maximization algorithm is a general algorithm for finding maximum likelihood estimates of parameters in statistical models with hidden variables. It is often used when there is missing or incomplete information in the data.&lt;/p&gt;

&lt;p&gt;In essence, the algorithm works by iteratively updating two sets of variables: the expectation variables (E-step) and the maximization variables (M-step). The expectation variables represent the expected value of the hidden variables given the observed data and the current estimate of the model parameters. The maximization variables represent the parameter estimates that maximize the likelihood of the observed data given the current estimate of the hidden variables.&lt;/p&gt;

&lt;p&gt;The EM algorithm can be summarized in the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize the parameters of the model.&lt;/li&gt;
  &lt;li&gt;Compute the expectation variables given the current estimate of the parameters.&lt;/li&gt;
  &lt;li&gt;Compute the maximization variables by maximizing the likelihood function given the expectation variables.&lt;/li&gt;
  &lt;li&gt;Repeat steps 2 and 3 until convergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This algorithm is guaranteed to converge to a local maximum of the likelihood function. However, there is no guarantee that this maximum is the global maximum. Therefore, it is often run multiple times with different initial conditions to ensure that the global maximum is found.&lt;/p&gt;

&lt;h2 id=&quot;em-algorithm-for-change-point-detection&quot;&gt;EM Algorithm for Change Point Detection&lt;/h2&gt;

&lt;p&gt;Now that we have covered the basic principles of the EM algorithm, let us explain how it can be used for change point detection in time series data.&lt;/p&gt;

&lt;p&gt;Suppose we have a time series { $x_1$, $x_2$, , $x_n$ } and we would like to detect any change points in the data. The EM algorithm can be used to fit a statistical model to the data that assumes that there are a fixed number of segments with different means.&lt;/p&gt;

&lt;p&gt;Let us assume that the data is generated from the following statistical model:&lt;/p&gt;

\[x_i = \mu_{z_i} + \epsilon_i\]

&lt;p&gt;where $z_i$ is the segment index, $\mu_{z_i}$ is the mean of segment $z_i$, and $\epsilon_i$ is the noise term for observation $i$.&lt;/p&gt;

&lt;p&gt;We can think of this statistical model as a hidden Markov model, where the segment index $z_i$ is the hidden state and the observation $x_i$ is the observed variable.&lt;/p&gt;

&lt;p&gt;To apply the EM algorithm, we need to define the expectation and maximization steps. Let $\theta = { \mu_1, , \mu_k, \pi_1, , \pi_k }$ be the set of parameters of the model, where $k$ is the number of segments in the data and $\pi_i$ is the probability of being in segment $i$.&lt;/p&gt;

&lt;h3 id=&quot;batch-mode&quot;&gt;Batch Mode&lt;/h3&gt;

&lt;p&gt;In the batch mode of the EM algorithm, we assume that we have access to the entire time series data at once. The algorithm proceeds as follows:&lt;/p&gt;

&lt;h4 id=&quot;expectation-step&quot;&gt;Expectation Step:&lt;/h4&gt;

&lt;p&gt;We compute the probability of being in segment $i$ given the observed data and the current estimate of the parameters:&lt;/p&gt;

\[\gamma_{i,j} = p(z_i = j \mid x_1, ..., x_n, \theta) = \frac{\pi_j f(x_i \mid \mu_j)}{\sum_{r=1}^k \pi_r f(x_i \mid \mu_r)}\]

&lt;p&gt;where $f(x_i \mid \mu_j)$ is the probability density function of a normal distribution with mean $\mu_j$ and variance $\sigma^2$, and $\sigma$ is assumed to be constant for all segments.&lt;/p&gt;

&lt;h4 id=&quot;maximization-step&quot;&gt;Maximization Step:&lt;/h4&gt;

&lt;p&gt;We update the parameters by maximizing the log-likelihood of the observed data given the expectation variables, subject to the constraint that the probabilities of being in the different segments add up to one:&lt;/p&gt;

\[\begin{aligned}
\pi_j &amp;amp;= \frac{1}{n} \sum_{i=1}^n \gamma_{i,j} \\
\mu_j &amp;amp;= \frac{\sum_{i=1}^n \gamma_{i,j} x_i}{\sum_{i=1}^n \gamma_{i,j}}
\end{aligned}\]

&lt;p&gt;We repeat the expectation and maximization steps until convergence.&lt;/p&gt;

&lt;h4 id=&quot;interpretation&quot;&gt;Interpretation:&lt;/h4&gt;

&lt;p&gt;The EM algorithm in batch mode provides us with the maximum likelihood estimates of the segment means and probabilities of being in each segment. We can use this information to identify the change points in the data. A change point is identified as the time where the segment mean changes.&lt;/p&gt;

&lt;h3 id=&quot;online-mode&quot;&gt;Online Mode&lt;/h3&gt;

&lt;p&gt;In the online mode of the EM algorithm, we assume that we have access to the time series data one observation at a time. We update the model parameters after each observation is received. The algorithm proceeds as follows:&lt;/p&gt;

&lt;h4 id=&quot;expectation-step-1&quot;&gt;Expectation Step:&lt;/h4&gt;

&lt;p&gt;The expectation step remains the same as in the batch mode:&lt;/p&gt;

\[\gamma_{i,j} = p(z_i = j \mid x_1, ..., x_n, \theta) = \frac{\pi_j f(x_i \mid \mu_j)}{\sum_{r=1}^k \pi_r f(x_i \mid \mu_r)}\]

&lt;h4 id=&quot;maximization-step-1&quot;&gt;Maximization Step:&lt;/h4&gt;

&lt;p&gt;We update the parameters after each observation by maximizing the log-likelihood of the observed data up to that point subject to the same constraint as in the batch mode:&lt;/p&gt;

\[\begin{aligned}
\pi_{j}^{(t)} &amp;amp;= \pi_{j}^{(t-1)} + \alpha_j \gamma_{n,j} \\
\mu_{j}^{(t)} &amp;amp;= \mu_{j}^{(t-1)} + \beta_j \gamma _{n,j} (x_{n} - \mu_{j}^{(t-1)})
\end{aligned}\]

&lt;p&gt;where $t$ is the time step, $\alpha_j$ and $\beta_j$ are the learning rates for the mixture weight and the mean parameter respectively.&lt;/p&gt;

&lt;p&gt;We repeat the expectation and maximization steps after each observation is received.&lt;/p&gt;

&lt;h4 id=&quot;interpretation-1&quot;&gt;Interpretation:&lt;/h4&gt;

&lt;p&gt;The EM algorithm in online mode provides the same information as in batch mode. However, it is more useful in applications where online learning is critical. For example, in a stock trading application where stock prices change frequently and rapidly, online change point detection using the EM algorithm can help predict future trends and alter trading strategies on the fly.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;p&gt;We present a Python implementation of the EM algorithm for change point detection in time series data. The implementation is optimized for the batch mode of the algorithm.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;em_cp_detection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Expectation Maximization algorithm for change point detection
    Args:
        X: 1D numpy array of observations
        K: int, number of segments to fit
        max_iter: int, maximum number of EM iterations
        tol: float, tolerance for convergence
    Returns:
        tuple of numpy arrays:
            * Z: 1D np array of segment assignments (length N)
            * mu: np array of segment means (length K)
            * pi: np array of segment probabilities (length K)
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sig_sq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# assume constant variance for all segments
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ll_old&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inf&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# E-step
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;likelihood&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sig_sq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# M-step
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;n_j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_j&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute log-likelihood
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;ll_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ll_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sig_sq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Check for convergence
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ll_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ll_old&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll_old&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ll_new&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The Expectation Maximization algorithm is a powerful tool for finding maximum likelihood estimates of parameters in statistical models with hidden variables. Its applicability in batch and online mode makes it useful in many applications, including change point detection in time series data.&lt;/p&gt;

&lt;p&gt;In this article, we have presented the EM algorithm for change point detection in time series data. We have explained the algorithm in both batch and online mode, and provided a Python implementation for the batch mode. We hope that this article will serve as a useful reference for those interested in implementing the EM algorithm for change point detection.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Expectation Maximization: A Powerful Tool for Trading Analysis</title>
   <link href="http://localhost:4000/2023/04/20/expectation-maximization"/>
   <updated>2023-04-20T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/20/expectation-maximization</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Expectation Maximization, or EM, is a powerful algorithm for solving a wide range of statistical problems, particularly in the field of machine learning. The algorithm estimates the parameters of a model, assuming that some of the data is missing or unobserved. EM is an iterative algorithm with two steps: the expectation step, which computes the expected values of the unobserved data or missing values, given the observed data and the estimated parameters, and the maximization step, which maximizes the likelihood of the observed data while updating the parameter estimates. EM can be applied in both batch and online modes, depending on how the data is processed. This article explains the theoretical background and algorithmic approach of EM and demonstrates its potential use cases in financial trading analysis, highlighting both modes.&lt;/p&gt;

&lt;h2 id=&quot;theoretical-background&quot;&gt;Theoretical background&lt;/h2&gt;
&lt;p&gt;The EM algorithm is based on the maximum likelihood estimation principle, which is used to estimate the parameters of a statistical model that maximizes the likelihood function. The likelihood function calculates the probability of the observed data given the parameters of the model. However, in some cases, part of the data may be unobserved or missing, which makes it impossible to maximize the likelihood function directly. The EM algorithm provides a way to find the maximum likelihood estimates of the parameters in such cases.&lt;/p&gt;

&lt;p&gt;The EM algorithm solves this problem by introducing a latent or unobserved variable, which represents the missing data. The algorithm then iteratively estimates the parameters of the model by computing the expected values of the missing data given the observed data and the current estimate of the parameters, and then computes the maximum likelihood estimate of the parameters using the expected values. This process repeats until convergence is achieved, or a stopping criterion is satisfied.&lt;/p&gt;

&lt;p&gt;EM has several advantages over other parameter estimation algorithms, such as gradient descent or Newton-Raphson, particularly in cases where the likelihood function is not easily differentiable. Furthermore, EM provides a way to estimate the parameters of models with incomplete data or models that depend on unobserved variables.&lt;/p&gt;

&lt;h2 id=&quot;the-algorithm&quot;&gt;The Algorithm&lt;/h2&gt;
&lt;p&gt;The EM algorithm can be described in two steps: the expectation step (E-step) and the maximization step (M-step).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E-step: 
Given the observed data $X$ and the current parameter estimates $\theta^{(t)}$, we compute the expected value of the unobserved or missing data $Z$ using the conditional probability distribution $p(Z|X,\theta^{(t)})$. This distribution is called the posterior distribution of $Z$ given $X$ and $\theta^{(t)}$, and it tells us the probability of the missing data given the observed data and the current parameter estimates.&lt;/li&gt;
&lt;/ol&gt;

\[\gamma(z_i)=p(z_i|x_i,\theta^{(t)})=\frac{p(x_i|z_i,\theta^{(t)})p(z_i|\theta^{(t)})}{\sum_{z_i}p(x_i|z_i,\theta^{(t)})p(z_i|\theta^{(t)})}\]

&lt;p&gt;where $z_i$ is the missing data for the $i^{th}$ observation $x_i$, and $\gamma(z_i)$ is the probability of $z_i$ given $x_i$ and the current parameter estimates $\theta^{(t)}$. The denominator in the equation normalizes the probabilities over all possible values of $z_i$.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;M-step: 
In the M-step, we compute the maximum likelihood estimate of the parameters $\theta$ given the observed data and the expected values of the missing data obtained in the E-step.&lt;/li&gt;
&lt;/ol&gt;

\[\theta^{(t+1)}=\arg\max_{\theta}\sum_{i=1}^N\sum_{z_i}\gamma(z_i)\log p(x_i,z_i|\theta)\]

&lt;p&gt;where $N$ is the number of observations, and $\theta^{(t+1)}$ is the updated estimate of the parameters. The expression inside the logarithm is the joint probability of the observed data $x_i$ and its missing data $z_i$ given the parameter estimates $\theta$.&lt;/p&gt;

&lt;p&gt;The EM algorithm iterates between the E-step and the M-step until convergence is achieved. The convergence criterion can be based on the change in the log-likelihood of the observed data or on the change in the parameter estimates.&lt;/p&gt;

&lt;h2 id=&quot;potential-use-cases-in-trading-analysis&quot;&gt;Potential use cases in trading analysis&lt;/h2&gt;
&lt;p&gt;EM has several potential use cases in financial trading analysis, particularly in cases where the data is incomplete, missing, or noisy. EM can be applied in both batch and online modes depending on the trading strategy and data formats.&lt;/p&gt;

&lt;h3 id=&quot;batch-mode&quot;&gt;Batch mode&lt;/h3&gt;
&lt;p&gt;In the batch mode, the algorithm processes a fixed set of historical data all at once. The algorithm can be used for various purposes including:&lt;/p&gt;

&lt;h4 id=&quot;portfolio-optimization&quot;&gt;Portfolio optimization&lt;/h4&gt;
&lt;p&gt;EM can be used for portfolio optimization by estimating the asset returns and covariances from historical data. The estimated returns and covariances can then be used to construct an optimal portfolio for a given set of constraints such as risk tolerance and expected return.&lt;/p&gt;

&lt;p&gt;We can estimate the expected asset returns by assuming a normal distribution and using the EM algorithm to estimate the mean and variance of the distribution. We can also estimate the covariance matrix of the asset returns by modeling the returns as a multivariate normal distribution and using the EM algorithm to estimate the covariance matrix.&lt;/p&gt;

&lt;p&gt;The Python code for mean and variance estimation is shown below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Batch EM for mean and variance estimation
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate mock data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize mean and variance
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Run EM algorithm for mean and variance estimation
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# E-step
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Normalize gamma
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# M-step
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Iteration:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Mean:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Variance:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;hidden-markov-models&quot;&gt;Hidden Markov models&lt;/h4&gt;
&lt;p&gt;EM can be used for modeling and predicting financial time series data with a Hidden Markov Model (HMM). A HMM is a statistical model that describes a sequence of observations, where each observation is generated from one of several underlying hidden states with some probability. HMMs can be used to model the hidden states of financial markets or assets and to predict future market conditions.&lt;/p&gt;

&lt;p&gt;We can use the EM algorithm to train the HMM parameters by estimating the transition probabilities between the hidden states and the emission probabilities for each observation. The transition probabilities represent the probabilities of moving from one hidden state to another, and the emission probabilities represent the probabilities of observing an observation given a hidden state.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Batch EM for HMM parameter estimation
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hmmlearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hmm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate mock data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize HMM with 2 hidden states
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hmm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GaussianHMM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train HMM with EM algorithm
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Print estimated parameters
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Transition probabilities:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transmat_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Means:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;means_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Covariances:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covars_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;online-mode&quot;&gt;Online mode&lt;/h3&gt;
&lt;p&gt;In the online mode, the algorithm processes data point by point or in small batches. The algorithm can be used for various purposes including:&lt;/p&gt;

&lt;h4 id=&quot;anomaly-detection&quot;&gt;Anomaly detection&lt;/h4&gt;
&lt;p&gt;EM can be used for detecting anomalies in financial data such as fraud detection or detecting unusual market conditions. The algorithm can be used to estimate the normal or expected behavior of the data and identify data points that deviate significantly from the expected behavior.&lt;/p&gt;

&lt;p&gt;We can use the EM algorithm to estimate the parameters of a normal distribution from the historical data and then calculate the probability of a new data point belonging to the same normal distribution. If the probability is lower than a threshold, the data point is considered an anomaly.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Online EM for anomaly detection
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate mock data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize mean and variance
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Run EM algorithm for mean and variance estimation
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# E-step
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Normalize gamma
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# M-step
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Anomaly detection
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Anomaly detected at index:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;short-term-trading&quot;&gt;Short-term trading&lt;/h4&gt;
&lt;p&gt;EM can be used for short-term trading strategies by predicting the direction of the market or asset price movements. The algorithm can be used to estimate the parameters of a distribution from the historical data and then predict the next data point using the estimated parameters.&lt;/p&gt;

&lt;p&gt;We can use the EM algorithm to estimate the mean and variance of a normal distribution from the historical data and then predict the next data point as the mean of the distribution.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Online EM for short-term trading
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate mock data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize mean and variance
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Run EM algorithm for mean and variance estimation
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# E-step
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Normalize gamma
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# M-step
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Short-term trading
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Buy&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Sell&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;EM is a powerful algorithm for solving a wide range of statistical problems, particularly in machine learning. The algorithm estimates the parameters of the model, assuming that some of the data is missing or unobserved. EM can be applied in both batch and online modes and has several potential use cases in financial trading analysis, including portfolio optimization, hidden Markov models, anomaly detection, and short-term trading strategies. EM can provide reliable and accurate results for statistical problems in finance, which makes it an important tool for financial analysis and decision-making.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Recursive Algorithms for Trailing Stop Stochastic Approximation Approach</title>
   <link href="http://localhost:4000/2023/04/19/recursive-algorithms-for-trailing-stop-stochastic-approximation-approach"/>
   <updated>2023-04-19T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/19/recursive-algorithms-for-trailing-stop-stochastic-approximation-approach</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Trailing stops are often used in stock trading to limit the maximum of a
possible loss and to lock in a profit. This work develops stochastic approximation
algorithms to estimate the optimal trailing stop percentage. A stochastic optimization
approach is proposed to recursively estimate the desired trailing stop percentage.
A modification using projection is developed to ensure that the approximation
sequence constructed stays in a reasonable range. Convergence of the algorithm is
obtained. Moreover, interval estimates are constructed. Simulation examples are presented
to compare our algorithm with Monte Carlo methods. Finally, we use real
market data to demonstrate the algorithms.&lt;/p&gt;
&lt;h2 id=&quot;formulation&quot;&gt;Formulation&lt;/h2&gt;

&lt;p&gt;In our formulation, we shall not require the stock price $S(t)$ be any specific stochastic process or follow any specific distributions; we only assume the stock price being observable. Based on the observed stock price, for a given time $t$, we define the stop price at a trailing stop percentage $h$ with $0&amp;lt;h&amp;lt;1$ as
\(T_h(t)=(1-h) S_{\max }(t)\)
where
\(S_{\max }(t)=\max \{S(u): 0 \leq u \leq t\}\)
Let
\(\tau=\inf \left\{t&amp;gt;0: S(t) \leq T_h(t)\right\}\)
Then $\tau$ is the first time the stock price reaches the stop price. We aim to find the optimal trailing stop percentage $h_* \in[a, 1]$ with $a&amp;gt;0$ that maximize a suitable objective function. Thus the problem is
$(\mathcal{P})$ Find $\operatorname{argmax} J(h)=E[\Phi(S(\tau)) \exp (-\rho \tau)], \quad h \in[a, 1]$
Here $\rho&amp;gt;0$ is an appropriate discount rate and the reward function is
\(\Phi(S)=\frac{S-S_0}{S_0}\)
In practice, a trailing stop $h$ has to be greater than 0 because $h=0$ means selling right after bought the stock. In view of this, the lower bound $a$ is assumed to be greater than 0 , which represents a reasonable lower bound for the trailing stop percentage.
In general, an analytic solution is difficult to obtain even if $S(t)$ is a specific process, e.g., a geometric Brownian motion. This is mainly due to the pathdependence nature of the problem. Our contribution is to devise a numerical approximation procedure that estimates the optimal trailing stop percentage $h$. We will use a stochastic approximation procedure to resolve the problem by constructing a sequence of estimates of the optimal trailing stop percentage $h$, using
\(\left.h_{n+1}=h_n+\{\text { stepsize }\} \text { gradient estimate of } J(h)\right\} .\)
Moreover, in accordance with (4), we need to make sure the iterate $h_n \in[a, 1]$.&lt;/p&gt;

&lt;h3 id=&quot;recursive-algorithm&quot;&gt;Recursive Algorithm&lt;/h3&gt;

&lt;p&gt;Let us begin with a simple noisy finite difference scheme. The only provision is that $S(t)$ can be observed. Associated with the iteration number $n$, denote the trailing stop percentage by $h_n$. Beginning at an arbitrary initial guess, we construct a sequence of estimates $\left{h_n\right}$ recursively as follows. We figure out $\tau_n$, the first time when the stock price declines under the stop price as
\(\tau_n=\inf \left\{t&amp;gt;0: S(t) \leq T_{h_n}(t)\right\} .\)&lt;/p&gt;

&lt;p&gt;Define a combined process $\xi_n$ that includes the random effect from $S(t)$ and the stopping time $\tau_n$ as
\(\xi_n=\left(S\left(\tau_n\right), \tau_n\right)^{\prime}\)
where $S\left(\tau_n\right)$ denotes the stock price process $S(t)$ stopped at stopping time $\tau_n$. Henceforth, we call $\left{\xi_n\right}$ the sequence of collective noise. Let $\hat{J}(h, \xi)$ be the observed value of $J(h)$ with collective noise $\xi$. With the values $h \pm \delta_n$, define $Y_n^{ \pm}$as
\(Y_n^{ \pm}\left(h, \xi_n^{ \pm}\right)=\hat{J}\left(h \pm \delta_n, \xi_n^{ \pm}\right) .\)
$\xi_n^{ \pm}$being the two different collective noises taken at the trailing stop percentages $h \pm$ $\delta_n$, where $\delta_n$ is the finite difference sequence satisfying $\delta_n \rightarrow 0$ as $n \rightarrow \infty$. We shall write $Y_n^{ \pm}=Y_n^{ \pm}\left(h, \xi_n^{ \pm}\right)$. For simplicity, in what follows, we often use $\xi_n$ to represent both $\xi_n^{+}$and $\xi_n^{-}$if there is no confusion. The gradient estimate at iteration $n$ is given by
\(D \hat{J}\left(h_n, \xi_n\right) \stackrel{\text { def }}{=}\left(Y_n^{+}-Y_n^{-}\right) /\left(2 \delta_n\right)\)
Then the recursive algorithm is
\(h_{n+1}=h_n+\varepsilon_n D \hat{J}\left(h_n, \xi_n\right),\)
where $\varepsilon_n$ is a sequence of real numbers known as stepsizes. A frequently used choice of step size and finite difference sequences is $\varepsilon_n=O(1 / n)$ and $\delta_n=O\left(1 / n^{1 / 6}\right)$. Throughout this paper, this is our default choice of stepsize and finite difference sequences.
To proceed, define
\(\begin{aligned}
&amp;amp; \rho_n=\left(Y_n^{+}-Y_n^{-}\right)-E_n\left(Y_n^{+}-Y_n^{-}\right), \\
&amp;amp; \eta_n=\left[E_n Y_n^{+}-J\left(h_n+\delta_n\right)\right]-\left[E_n Y_n^{-}-J\left(h_n-\delta_n\right)\right], \\
&amp;amp; \beta_n=\frac{J\left(h_n+\delta_n\right)-J\left(h_n-\delta_n\right)}{2 \delta_n}-J_h\left(h_n\right),
\end{aligned}\)
where $E_n$ denotes the conditional expectation with respect to $\mathcal{F}_n$, the $\sigma$-algebra generated by $\left{h_j, \xi_j^{ \pm}: j&amp;lt;n\right}, J_h\left(h_n\right)=(\partial / \partial h) J\left(h_n\right)$. In the above, $\eta_n$ and $\beta_n$ represent the noise and bias, and $\left{\rho_n\right}$ is a martingale difference sequence. We separate the noise into two parts, uncorrelated noise $\rho_n$ and correlated noise $\eta_n$. It is reasonable to assume that after taking the conditional expectations, the resulting function is smooth. With the above definitions, algorithm (9) can be rewritten as
\(h_{n+1}=h_n+\varepsilon_n J_h\left(h_n\right)+\varepsilon_n \frac{\rho_n}{2 \delta_n}+\varepsilon_n \beta_n+\varepsilon_n \frac{\eta_n\left(h_n, \xi_n\right)}{2 \delta_n} .\)&lt;/p&gt;

&lt;h3 id=&quot;projection-algorithms&quot;&gt;Projection Algorithms&lt;/h3&gt;

&lt;p&gt;The use of projections in the algorithms stems from two reasons. First, for the purpose of computations, it is more convenient if one uses projections to force the iterates to remain in a bounded region. In addition, the problems under consideration may well be constrained so that the iterates will be in a given set. Current problem under consideration is such an example (the iterates need to stay in the interval $[a, 1]$ ). For example, one might choose a lowest trailing stop percentage of $10 \%$ to ensure the holding position will not be closed due to the normal fluctuations of daily stock price. Obviously, there is a upper bound for the optimal trailing stop percentage, $100 \%$. To solve the problem (4) with constrains, we construct the following stochastic approximation algorithm with a projection
\(h_{n+1}=\Pi\left[h_n+\varepsilon_n D \hat{J}\left(h_n, \xi_n\right)\right]\)
where $\varepsilon_n=1 / n, \delta_n=\delta /\left(n^{1 / 6}\right)$ and $\Pi[x]$ is a projection given by
\(\Pi[h]= \begin{cases}a, &amp;amp; \text { if } h&amp;lt;a, \\ 1, &amp;amp; \text { if } h&amp;gt;1, \\ h, &amp;amp; \text { otherwise. }\end{cases}\)
As in Kushner and Yin [4], the projection algorithm (11) can be rewritten as
\(h_{n+1}=h_n+\varepsilon_n D \hat{J}\left(h_n, \xi_n\right)+\varepsilon_n r_n,\)
where $\varepsilon_n r_n=h_{n+1}-h_n-\varepsilon_n D \hat{J}\left(h_n, \xi_n\right)$ is the real number with the shortest distance needed to bring $h_n+\varepsilon_n D \hat{J}\left(h_n, \xi_n\right)$ back $[a, 1]$ if it is outside this set.&lt;/p&gt;

&lt;h2 id=&quot;interval-estimates&quot;&gt;Interval Estimates&lt;/h2&gt;

&lt;p&gt;This section is devoted to obtaining interval estimates as well as a piratically useful stopping rule for the recursive computation. Roughly, with prescribed confidence level, we wish to show that with large probability (probability close to 1 ), a sequence of scaled and centered estimates and a stopped sequence converge weakly to a diffusion process. Based on this result, we will then be able to build confidence interval for the iterates.&lt;/p&gt;

&lt;p&gt;To proceed, for simplicity of notation, we take $\varepsilon_n=1 / n$ and $\delta_n=\delta_0 / n^{1 / 6}$. In the analysis to follow, for simplicity and without loss of generality, we take $\delta_0=1$. We assume all the conditions of Theorem 3.1 holds. To carry out the subsequent study, we also assume an additional condition.
(A3) $J_h(h)=J_{h h}\left(h_&lt;em&gt;\right)\left(h-h_&lt;/em&gt;\right)+o\left(\left|h-h_&lt;em&gt;\right|^2\right)$, where $J_{h h}\left(h_&lt;/em&gt;\right)-(1 / 2)&amp;lt;0$. In addition, $k^{2 / 3} E\left(h_k-h_*\right)^2=O(1)$ and the bound holds uniformly in $k$.&lt;/p&gt;

&lt;p&gt;Remark 4.1 The first condition in (A3) indicates that $J_h(h)$ is linearizable. The second condition is a moment estimate. Sufficient conditions guaranteeing this can be provided by means of perturbed Lyapunov function methods; see for example [7] for liquidation related issues and the more extensive discussion in [4] for general setting. For simplicity, here we assume this condition.
Define
\(\rho_n^*=\left[Y\left(h_*, \xi_n^{+}\right)-Y\left(h_*, \xi_n^{-}\right)\right]-E_n\left[Y\left(h_*, \xi_n^{+}\right)-Y\left(h_*, \xi_n^{-}\right)\right] .\)
That is, $\rho_n^&lt;em&gt;$ is $\rho_n$ with the argument $h_n$ replaced by $h_&lt;/em&gt;$. The detailed development of the interval estimates can be outlined as follows. Suppose that we can show that $n^{1 / 3}\left(h_n-h_&lt;em&gt;\right)$ is asymptotically normal with mean zero and asymptotic variance $\sigma^2$. Choose $\alpha$, such that $0&amp;lt;\alpha&amp;lt;1$ and $1-\alpha$ is the desired confidence coefficient. Given $\varepsilon&amp;gt;0$, then the asymptotic normality implies that
\(P\left(\frac{n^{1 / 3}\left|h_n-h_*\right|}{\sigma} \leq z_{\alpha / 2}\right) \rightarrow 1-\alpha, \text { as } n \rightarrow \infty .\)
This will lead to the desired confidence interval estimator. Then we require the length of the interval $\left|h_n-h_&lt;/em&gt;\right|$ be small enough in that for any $\varepsilon&amp;gt;0$, for sufficiently large&lt;/p&gt;

&lt;p&gt;$n$, we can make $\sigma z_{\alpha / 2} / n^{1 / 3}&amp;lt;\varepsilon$ or equivalently $n&amp;gt;\left\lfloor\sigma z_{\alpha / 2} / \varepsilon\right\rfloor$. Define
\(M_{\varepsilon, \alpha}^n=\left\lfloor\frac{\sigma z_{\alpha / 2}}{\varepsilon}\right\rfloor, \quad \mu_{\varepsilon, \alpha}=\inf \left\{n: M_{\varepsilon, \alpha}^n \leq n\right\},\)
where $\lfloor z\rfloor$ denotes the greatest integer that is less than or equal to $z$. Then $\mu_{\varepsilon, \alpha}$ is a stopping rule for the iterating sequence $\left{h_n\right}$. Denote
\(I_{\mu_{\varepsilon, \alpha}}=\left[h_{\mu_{\varepsilon, \alpha}}-\sigma \frac{z_{\alpha / 2}}{n^{2 / 3}}, h_{\mu_{\varepsilon, \alpha}}+\sigma \frac{z_{\alpha / 2}}{n^{2 / 3}}\right] .\)
We shall show that as the length of the interval shrinks, i.e., $\varepsilon \rightarrow 0$,
\(P\left\{h \in I_{\mu_{\varepsilon, \alpha}} \text { and }\left|I_{\mu_{\varepsilon, \alpha}}\right| \leq \varepsilon\right\} \rightarrow 1-\alpha,\)
where $\left|I_{\mu_{\varepsilon, \alpha}}\right|$ denotes the length of the interval $I_{\mu_{\varepsilon, \alpha}}$.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Stochastic Optimization and Its Potential Use Cases in Trading</title>
   <link href="http://localhost:4000/2023/04/18/stochastic-optimization"/>
   <updated>2023-04-18T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/18/stochastic-optimization</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Stochastic optimization is a branch of optimization that makes use of random variables and probability distributions to solve optimization problems. This approach is particularly useful when the underlying problem involves uncertainty or randomness. In recent years, stochastic optimization has found numerous applications in finance, particularly in the domain of algorithmic trading.&lt;/p&gt;

&lt;p&gt;Algorithmic trading refers to the use of sophisticated algorithms to automate trading decisions. In the context of stochastic optimization, these algorithms leverage probabilistic models to optimize various aspects of trading strategies such as portfolio allocation, risk management, and order execution. In this article, we provide a brief overview of stochastic optimization and explore its potential use cases in trading.&lt;/p&gt;

&lt;h1 id=&quot;stochastic-optimization-fundamentals&quot;&gt;Stochastic Optimization Fundamentals&lt;/h1&gt;

&lt;p&gt;Before delving into the applications of stochastic optimization in trading, let us first establish some fundamental concepts in the field.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-programming&quot;&gt;Stochastic Programming&lt;/h2&gt;

&lt;p&gt;Stochastic programming is a subfield of optimization that deals with problems where some or all of the parameters are uncertain. In these problems, the objective function and constraints are specified in terms of probability distributions rather than fixed values. The goal of stochastic programming is to find a decision that minimizes the expected value of the objective function subject to the constraints.&lt;/p&gt;

&lt;p&gt;Mathematically, a stochastic programming problem can be formulated as follows:&lt;/p&gt;

\[\min_{\boldsymbol{x}}\ \mathbb{E}_{\boldsymbol{\xi}}[f(\boldsymbol{x},\boldsymbol{\xi})]\quad\text{s.t.}\quad \boldsymbol{x}\in\mathcal{X}(\boldsymbol{\xi}) \quad\text{and}\quad g_i(\boldsymbol{x})\leq 0\ \forall i\in\{1,\ldots,m\}\]

&lt;p&gt;where $\boldsymbol{x}\in\mathbb{R}^{n}$ is the decision variable, $\boldsymbol{\xi}\in\mathbb{R}^{p}$ is a random vector representing the uncertain parameters, $f(\boldsymbol{x},\boldsymbol{\xi})$ is the objective function, $\mathcal{X}(\boldsymbol{\xi})$ is the feasible set that depends on the uncertain parameters, and $g_i(\boldsymbol{x})$ are the inequality constraints.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h2&gt;

&lt;p&gt;Stochastic gradient descent (SGD) is an optimization algorithm that is widely used in machine learning for training models. The algorithm updates the parameters of the model iteratively by computing the gradient of the loss function with respect to a small subset of the training data referred to as a mini-batch. Unlike the batch gradient descent algorithm, which computes the gradient using the entire training set, SGD is a quicker and more scalable algorithm that can be applied to large datasets.&lt;/p&gt;

&lt;p&gt;In the context of stochastic optimization, SGD can be used to solve problems where the objective function is not known in closed-form or is too expensive to compute. The algorithm converges to the optimal solution in expectation, under certain conditions on the objective function.&lt;/p&gt;

&lt;h1 id=&quot;stochastic-optimization-in-trading&quot;&gt;Stochastic Optimization in Trading&lt;/h1&gt;

&lt;p&gt;Now that we are familiar with the fundamentals of stochastic optimization, let us turn our attention to its potential use cases in trading.&lt;/p&gt;

&lt;h2 id=&quot;portfolio-optimization&quot;&gt;Portfolio Optimization&lt;/h2&gt;

&lt;p&gt;Portfolio optimization refers to the problem of allocating assets in a portfolio to achieve a desired objective, such as maximizing returns or minimizing risk. Traditional portfolio optimization techniques assume that the underlying parameters, such as asset returns and correlations, are known with certainty. However, this assumption is unrealistic as financial markets are inherently uncertain and unpredictable.&lt;/p&gt;

&lt;p&gt;Stochastic optimization can be used to incorporate uncertainty into the portfolio optimization problem. In this context, the uncertain parameters could include the expected returns and volatilities of the assets, as well as the correlations between them. A common approach to solving the stochastic portfolio optimization problem is to use chance-constrained programming, where the constraints are specified in terms of the probability that the portfolio returns do not fall below a certain threshold.&lt;/p&gt;

&lt;p&gt;Mathematically, the stochastic portfolio optimization problem can be formulated as follows:&lt;/p&gt;

\[\max_{\boldsymbol{w}}\ \mathbb{E}_{\boldsymbol{\xi}}[r_p(\boldsymbol{w},\boldsymbol{\xi})]\quad\text{s.t.}\quad \mathbb{P}_{\boldsymbol{\xi}}[r_p(\boldsymbol{w},\boldsymbol{\xi})\geq R]\geq 1-\alpha, \quad \boldsymbol{w}\in\Delta^{n}\]

&lt;p&gt;where $\boldsymbol{w}\in\mathbb{R}^{n}$ represents the portfolio weights, $r_p(\boldsymbol{w},\boldsymbol{\xi})$ is the portfolio return, $\Delta^{n}$ is the simplex of $n$-dimensional vectors, $R$ is the target return, and $\alpha$ is the confidence level.&lt;/p&gt;

&lt;p&gt;Python Implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.optimize&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stochastic_portfolio_optimization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;chance_constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covariances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;type&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;eq&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;fun&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;type&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;ineq&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;fun&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chance_constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;bounds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bounds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;risk-management&quot;&gt;Risk Management&lt;/h2&gt;

&lt;p&gt;Risk management is a critical aspect of trading, particularly in volatile markets. While portfolio optimization can be used to minimize risk, it is often not sufficient to manage extreme events such as market crashes or black swan events.&lt;/p&gt;

&lt;p&gt;Stochastic optimization techniques such as robust optimization and distributionally robust optimization can be used to explicitly account for worst-case scenarios and ensure the portfolio is resilient to such events. These techniques involve optimizing the performance of the portfolio under a distribution that is designed to capture extreme events.&lt;/p&gt;

&lt;p&gt;Mathematically, the risk management problem can be formulated as follows:&lt;/p&gt;

\[\max_{\boldsymbol{w}}\ \mathbb{E}_{\boldsymbol{\xi}}[r_p(\boldsymbol{w},\boldsymbol{\xi})]\quad\text{s.t.}\quad \sup_{\boldsymbol{\xi}\in\Xi}\mathbb{E}_{\boldsymbol{\xi}}[r_p(\boldsymbol{w},\boldsymbol{\xi})]\geq R, \quad \boldsymbol{w}\in\Delta^{n}\]

&lt;p&gt;where $\Xi$ is a set of distributions that are designed to capture extreme scenarios.&lt;/p&gt;

&lt;p&gt;Python Implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.optimize&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;robust_portfolio_optimization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;worst_case_constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covariances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;type&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;eq&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;fun&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                   &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;type&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;ineq&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;fun&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worst_case_constraint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;bounds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bounds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;order-execution&quot;&gt;Order Execution&lt;/h2&gt;

&lt;p&gt;Order execution refers to the process of executing trades in the market. In the context of stochastic optimization, the order execution problem involves optimizing the timing and size of trades to minimize slippage costs and maximize execution efficiency.&lt;/p&gt;

&lt;p&gt;One approach to solving the order execution problem is to use reinforcement learning, which involves using trial and error to learn an optimal policy for executing trades. Reinforcement learning algorithms such as Q-learning and deep reinforcement learning have been shown to be effective in solving the order execution problem, particularly in the presence of uncertainty and dynamic market conditions.&lt;/p&gt;

&lt;p&gt;Python Implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OrderExecution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q_learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_learning_rate&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q_learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Stochastic optimization is a powerful tool that can be used to address the challenges of uncertainty and randomness in trading. By incorporating probabilistic models into trading strategies, traders can optimize their portfolios, manage risk, and improve the efficiency of order execution. As financial markets continue to evolve and become more complex, the use of stochastic optimization is likely to play an increasingly important role in the trading industry.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Understanding L Peak and L Trough in Time Series Data</title>
   <link href="http://localhost:4000/2023/04/17/peak-trough"/>
   <updated>2023-04-17T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/17/peak-trough</id>
   <content type="html">&lt;p&gt;L Peak and L Trough are two concepts that are commonly used in time series analysis. L Peak is the highest value of a time series, while L Trough is the lowest value of a time series. Both L Peak and L Trough play an important role in understanding the trends and patterns of a time series, and can help in making future predictions.&lt;/p&gt;

&lt;h3 id=&quot;calculating-l-peak-and-l-trough&quot;&gt;Calculating L Peak and L Trough&lt;/h3&gt;
&lt;p&gt;In order to calculate L Peak and L Trough, we first need to have a time series data set. A time series is a sequence of measurements taken at equal intervals over time. It can be represented as a mathematical function with time as the independent variable and the value at each time point as the dependent variable.&lt;/p&gt;

&lt;p&gt;Suppose we have a time series such as the following:&lt;/p&gt;

\[y = [5, 7, 8, 10, 11, 13, 12, 9, 6, 3, 1]\]

&lt;p&gt;To calculate L Peak and L Trough, we first need to find the maximum and minimum values of the time series.&lt;/p&gt;

&lt;p&gt;We can use the NumPy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min()&lt;/code&gt; functions to find the maximum and minimum values, respectively:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;L_peak&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;L_trough&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this case, the output should be:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;L_peak: 13
L_trough: 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;interpretation-of-l-peak-and-l-trough&quot;&gt;Interpretation of L Peak and L Trough&lt;/h3&gt;
&lt;p&gt;Once we have calculated L Peak and L Trough, we can use them to interpret the trends in the time series.&lt;/p&gt;

&lt;p&gt;If L Peak is increasing over time, then the time series is said to have an increasing trend. Similarly, if L Trough is decreasing over time, then the time series is said to have a decreasing trend.&lt;/p&gt;

&lt;p&gt;On the other hand, if L Peak is decreasing over time and L Trough is increasing over time, then the time series is said to have a decreasing trend.&lt;/p&gt;

&lt;p&gt;If L Peak and L Trough remain relatively constant over time, then the time series is said to be stationary.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;L Peak and L Trough are important concepts in time series analysis. They provide important information about the trends in a time series, and can help in making future predictions. In this article, we provided a Python implementation for calculating L Peak and L Trough using NumPy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Time Series Segmentation using Turning Points and their Variants</title>
   <link href="http://localhost:4000/2023/04/16/segmentation-turning-points"/>
   <updated>2023-04-16T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/16/segmentation-turning-points</id>
   <content type="html">&lt;p&gt;Time series segmentation is a crucial task in time series analysis. It involves dividing a time series into homogeneous segments, thereby facilitating further analysis and modeling. Turning points, which are defined as local minima or maxima, are widely used as anchors for segmenting time series. This article provides an overview of various methods for identifying turning points and their variants, along with their applications in practical time series analysis. Implementations in Python are provided for all variants.&lt;/p&gt;

&lt;h2 id=&quot;turning-points&quot;&gt;Turning Points&lt;/h2&gt;

&lt;p&gt;A turning point in a time series is a value of the series where the trend changes direction. In other words, it is a local minimum or maximum in the series. Turning points play a crucial role in time series segmentation, as they are often used as anchors for dividing the series into homogeneous segments. The detection of turning points can be done by various methods, as discussed below.&lt;/p&gt;

&lt;h2 id=&quot;fixed-interval-method&quot;&gt;Fixed Interval Method&lt;/h2&gt;

&lt;p&gt;The fixed interval method involves dividing a time series into fixed-sized intervals and identifying the turning points within each interval. This method is computationally simple and easy to implement, but it may miss key turning points if they occur at the boundaries of the intervals.&lt;/p&gt;

&lt;h2 id=&quot;moving-average-method&quot;&gt;Moving Average Method&lt;/h2&gt;

&lt;p&gt;The moving average method involves computing a moving average of the time series and identifying the turning points based on the slope of the moving average. Specifically, a turning point is identified as a point where the difference between the moving average at that point and the moving average at the previous point changes sign. This method is computationally efficient and more robust than the fixed interval method, as it is less affected by local noise in the series.&lt;/p&gt;

&lt;h2 id=&quot;regression-method&quot;&gt;Regression Method&lt;/h2&gt;

&lt;p&gt;The regression method involves fitting a regression model to the time series and identifying turning points as the local minima or maxima of the fitted function. The regression function can be a linear or nonlinear function, depending on the nature of the time series. This method is more accurate than the previous methods but can be computationally intensive, especially for large time series.&lt;/p&gt;

&lt;h2 id=&quot;wavelet-method&quot;&gt;Wavelet Method&lt;/h2&gt;

&lt;p&gt;The wavelet method involves applying wavelet analysis to the time series and identifying turning points as the local minima or maxima of the wavelet transform. Wavelet analysis is a powerful tool for time series analysis that allows for both time and frequency localization. This method is more complex than the previous methods but is more robust and accurate, especially for nonstationary time series.&lt;/p&gt;

&lt;h2 id=&quot;variants-of-turning-points&quot;&gt;Variants of Turning Points&lt;/h2&gt;

&lt;p&gt;Several variants of the turning points concept have been proposed to address specific issues in time series analysis. Some of the commonly used variants are discussed below.&lt;/p&gt;

&lt;h3 id=&quot;l-peaks-and-troughs&quot;&gt;L-Peaks and Troughs&lt;/h3&gt;

&lt;p&gt;L-peaks and troughs are local extrema that are defined using both the amplitude and the length of a series of consecutive points. Specifically, an L-peak is a point that has a value greater than its surrounding points and whose height is greater than a certain threshold, which is defined as the average of the heights of the n highest peaks in the series. Similarly, an L-trough is a point that has a value less than its surrounding points and whose depth is less than a certain threshold, which is defined as the average of the depths of the n deepest troughs in the series. This variant is useful for identifying significant turning points in noisy time series.&lt;/p&gt;

&lt;h3 id=&quot;dynamic-time-warping&quot;&gt;Dynamic Time Warping&lt;/h3&gt;

&lt;p&gt;Dynamic time warping (DTW) is a technique for aligning two time series by warping their time axes to minimize the difference between them. DTW can be used to identify turning points in time series by comparing the distance between each point in the series and the best matching point in a reference series. This variant is useful for comparing time series with different lengths or for identifying turning points in nonstationary time series.&lt;/p&gt;

&lt;h3 id=&quot;hidden-markov-models&quot;&gt;Hidden Markov Models&lt;/h3&gt;

&lt;p&gt;Hidden Markov models (HMM) are stochastic models that capture the underlying structure of a time series by modeling its transitions between states. HMM can be used for identifying turning points in time series by inferring the state sequence that generates the observed series and identifying the transition points between states. This variant is useful for identifying turning points in complex time series with multiple trends or regimes.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;p&gt;Below is an example Python implementation for identifying turning points in a time series using the moving average method.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;valid&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;turning_points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;moving_average&lt;/code&gt; function computes a moving average of the input time series &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; using a window of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;window_size&lt;/code&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;turning_points&lt;/code&gt; function identifies the turning points in the original time series &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; based on the slope of the moving average. Specifically, it checks for points where the difference between the moving average at that point and the moving average at the previous point changes sign. The function returns a list of indices corresponding to the turning points.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Time series segmentation is a fundamental task in time series analysis, and turning points are widely used as anchors for this task. Various methods and variants for identifying turning points have been proposed, each with its own strengths and weaknesses. These methods and variants can be applied to a wide range of time series analysis problems, ranging from simple anomaly detection to complex regime switching models. Python implementations for all variants make it easy to explore these methods and variants on real-world time series data.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Using HMM to Find Out the Trend of a Signal or Time Series in Real Time</title>
   <link href="http://localhost:4000/2023/04/15/hmm-trend-detection"/>
   <updated>2023-04-15T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/15/hmm-trend-detection</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Hidden Markov Models (HMMs) are widely used in time series analysis and other machine learning applications. HMMs are a type of statistical model that uses observed data to infer the hidden state of a system. They have been successfully applied in speech recognition, text recognition, bioinformatics, and many other domains.&lt;/p&gt;

&lt;p&gt;One important application of HMMs is in real-time trend analysis of time series data. In this article, we will discuss how HMMs can be used to identify the trend of a signal or time series in real time. We will start with a brief overview of the theory behind HMMs and then move on to the implementation using Python code.&lt;/p&gt;

&lt;h1 id=&quot;theory&quot;&gt;Theory&lt;/h1&gt;

&lt;h2 id=&quot;hidden-markov-models&quot;&gt;Hidden Markov Models&lt;/h2&gt;

&lt;p&gt;A Hidden Markov Model is a statistical model that can be used to model time series data. It consists of a set of latent variables, known as hidden states, that are not directly observable. The hidden states generate the observed data, which are the observations.&lt;/p&gt;

&lt;p&gt;The basic idea is that the hidden states encode information about the underlying pattern in the data, while the observations are simply noisy measurements of these underlying patterns. The goal is to infer the hidden states from the observations.&lt;/p&gt;

&lt;p&gt;The HMM is characterized by three components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;State transition probability matrix&lt;/strong&gt;: This matrix defines the probability of moving from one state to another in the underlying Markov chain that generates the hidden states.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Observation probability distribution&lt;/strong&gt;: This distribution defines the probability of observing a given observation given the current hidden state.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Initial state probability distribution&lt;/strong&gt;: This distribution defines the probability of starting in each of the possible hidden states.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The HMM can be thought of as a generative model of the observed data. That is, given the hidden states, we can use the observation probability distribution to generate a sequence of observations. Conversely, given a sequence of observations, we can use the Viterbi algorithm or the forward-backward algorithm to infer the most likely sequence of hidden states that generated the observations.&lt;/p&gt;

&lt;h2 id=&quot;trend-analysis-with-hmms&quot;&gt;Trend Analysis with HMMs&lt;/h2&gt;

&lt;p&gt;In the context of time series analysis, we can use HMMs to identify the trend of a signal in real time. The idea is to model the trend as a sequence of hidden states, with each state corresponding to a different trend regime. For example, in a financial time series, we might have a bull market regime, a bear market regime, and a sideways market regime.&lt;/p&gt;

&lt;p&gt;We can then use the observation probability distribution to model the observed data as a noisy version of the underlying trend. This allows us to identify the current trend regime in real time, as well as predict future trends.&lt;/p&gt;

&lt;h1 id=&quot;implementation&quot;&gt;Implementation&lt;/h1&gt;

&lt;p&gt;We will now discuss the implementation of the HMM for trend analysis using Python code. We will use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hmmlearn&lt;/code&gt; library, which is a widely used library for HMMs.&lt;/p&gt;

&lt;h2 id=&quot;data-preparation&quot;&gt;Data Preparation&lt;/h2&gt;

&lt;p&gt;We will use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sunspots&lt;/code&gt; dataset from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;statsmodels&lt;/code&gt; library, which contains monthly sunspot numbers from 1749 to 2017. We will use the number of sunspots as our observed data.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statsmodels.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sunspots&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load the dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sunspots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;SUNACTIVITY&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;model-definition&quot;&gt;Model Definition&lt;/h2&gt;

&lt;p&gt;We will define our HMM model as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hmmlearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hmm&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Define the model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hmm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GaussianHMM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariance_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;full&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we are using a Gaussian HMM with three hidden states, a full covariance matrix, and 100 iterations of the Baum-Welch algorithm for parameter estimation.&lt;/p&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;

&lt;p&gt;We can train the model on the data using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fit&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Train the model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;predicting-hidden-states-and-trends&quot;&gt;Predicting Hidden States and Trends&lt;/h2&gt;

&lt;p&gt;We can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;predict&lt;/code&gt; function to predict the most likely sequence of hidden states:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Predict the hidden states
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can then plot the observed data and the predicted hidden states:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Plot the data with the hidden states
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;Hidden States&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see that the HMM has successfully identified the major trend regimes in the data.&lt;/p&gt;

&lt;h2 id=&quot;generating-future-observations&quot;&gt;Generating Future Observations&lt;/h2&gt;

&lt;p&gt;We can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sample&lt;/code&gt; function to generate future observations based on the learned model:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Generate future observations
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;future_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we are generating 24 new observations based on the learned model.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;In this article, we discussed how Hidden Markov Models can be used to identify the trend of a signal or time series in real time. We provided a detailed explanation of the theory behind HMMs and their implementation using Python code. We showed how HMMs can be trained on time series data to identify trend regimes, and how future observations can be generated based on the learned model.&lt;/p&gt;

&lt;p&gt;HMMs are a powerful tool for time series analysis, and their application to trend analysis can have many practical uses. By identifying trends in real time, we can make more informed decisions about financial investments, weather patterns, and more.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Matched Filters and their Variants</title>
   <link href="http://localhost:4000/2023/04/14/matched-filters"/>
   <updated>2023-04-14T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/14/matched-filters</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Matched Filters are a popular tool used for signal processing, primarily for detecting and extracting signals from noisy data. This article discusses the working of matched filters and their different variants. The variants covered in this article are Matched Filter Banks and Matched Subspace Filters.&lt;/p&gt;

&lt;h2 id=&quot;matched-filters&quot;&gt;Matched Filters&lt;/h2&gt;

&lt;p&gt;Matched Filters are linear filters used for signal detection and extraction, where the filter output is maximized when the input signal matches a predefined template. The matched filters advantage is that it maximizes the signal-to-noise ratio for the target signal while suppressing other noise sources.&lt;/p&gt;

&lt;p&gt;Mathematically, a matched filter $h(t)$ for a signal $s(t)$ with energy $E_s$, is given as:&lt;/p&gt;

\[h(t) = \frac{s(T-t)}{E_s}\]

&lt;p&gt;where T is the duration of the signal. The matched filter output $y(t)$ is the convolution of the input signal $x(t)$ with the matched filter $h(t)$:&lt;/p&gt;

\[y(t) = x(t) * h(t) = \int_{-\infty}^{\infty} x(\tau)h(t-\tau)d\tau\]

&lt;p&gt;The output of the matched filter is proportional to the cross-correlation between the input signal and the template signal $s(t)$ shifted by a time lag $t$. Thus, the matched filter maximizes the detection probability of the target signal in the presence of noise.&lt;/p&gt;

&lt;p&gt;The matched filter can be implemented using classical convolution, Fourier transform or digital filters. In digital implementation, input samples $x[n]$ are convolved with the matched filter impulse response $h[n]$:&lt;/p&gt;

\[y[n] = \sum_{k=0}^{N-1}x[n-k]h[k]\]

&lt;p&gt;where $N$ is the length of the matched filter impulse response.&lt;/p&gt;

&lt;h2 id=&quot;matched-filter-banks&quot;&gt;Matched Filter Banks&lt;/h2&gt;

&lt;p&gt;Matched Filter Banks are used when there are multiple target signals at different frequencies or pulse durations. Instead of using a single matched filter for detecting all target signals, a bank of matched filters is used. Each filter in the bank is designed to detect a specific pulse duration or frequency.&lt;/p&gt;

&lt;p&gt;A Matched Filter Bank for signals ${s_1(t), s_2(t), \dots, s_N(t)}$ is given as:&lt;/p&gt;

\[H(f) = \sum_{i=1}^{N}\frac{\bar{S_i(f)}}{E_{S_i}}S_i(f)\]

&lt;p&gt;where $S_i(f)$ is the Fourier transform of $s_i(t)$ and $E_{S_i}$ is the energy of $s_i(t)$. The output of the Matched Filter Bank for an input signal $x(t)$ is given as:&lt;/p&gt;

\[Y(f) = X(f)H(f)\]

&lt;p&gt;where $X(f)$ is the Fourier transform of $x(t)$.&lt;/p&gt;

&lt;p&gt;In the digital domain, the matched filter bank is implemented using a filter bank consisting of multiple matched filters, with each filter covering a specific frequency band.&lt;/p&gt;

&lt;h2 id=&quot;matched-subspace-filters&quot;&gt;Matched Subspace Filters&lt;/h2&gt;

&lt;p&gt;Matched Subspace Filters are used when the number of signal sources is unknown, and the signals are correlated. In such cases, a subspace containing the signals can be formed, and a matched filter is designed for extracting the signals from the subspace.&lt;/p&gt;

&lt;p&gt;The input signal matrix $X$ can be represented as a sum of a subspace matrix $S$ containing the target signals and a noise matrix $N$:&lt;/p&gt;

\[X = S + N\]

&lt;p&gt;The subspace matrix $S$ can be factorized using Singular Value Decomposition (SVD) as:&lt;/p&gt;

\[S = U\sum V^T\]

&lt;p&gt;where $U$ and $V$ are unitary matrices, and $\sum$ is a diagonal matrix containing the singular values of $S$. A matched filter $h$ can be designed using the subspace matrix $S$ as:&lt;/p&gt;

\[h = \frac{\sum V^T}{\|\sum V^T\|}\]

&lt;p&gt;The output of the matched filter bank is given as:&lt;/p&gt;

\[y(t) = h^Tx(t)\]

&lt;p&gt;In Python, a matched filter can be easily implemented using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy.signal&lt;/code&gt; library. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy.signal.correlate&lt;/code&gt; function can be used to implement the matched filter, as shown below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correlate&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Define the signal and template
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Implement the matched filter
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;valid&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot the output signal
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Matched Filters are a powerful tool used for signal detection and extraction in noisy data. Matched Filter Banks and Matched Subspace Filters are variants of the matched filter used for detecting multiple signals at different frequencies and extracting signals from a correlated subspace, respectively. In this article, we discussed the working of Matched Filters and their variants along with their mathematical formulations and Python implementations.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Non-Linear Detectors like SC Detector and its Variants</title>
   <link href="http://localhost:4000/2023/04/13/nonlinear-detectors"/>
   <updated>2023-04-13T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/13/nonlinear-detectors</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Non-linear detectors play an important role in signal processing applications. They are used in various applications, such as communications, radar, and medical imaging. The non-linear detectors are classified into two categories, namely parametric and non-parametric detectors. The parametric detectors require knowledge of the signal statistics, whereas the non-parametric detectors do not require any statistical information about the signals.&lt;/p&gt;

&lt;p&gt;One popular non-linear detector is the Sequentially Cyclic (SC) detector (also known as the Sawtooth detector), which is widely used in communication systems. In this article, we will discuss the SC detector in detail, along with its variants and their statistics and equations in LaTeX. Additionally, we will include Python implementation for all variants.&lt;/p&gt;

&lt;h2 id=&quot;sc-detector&quot;&gt;SC Detector&lt;/h2&gt;

&lt;p&gt;The Sequentially Cyclic (SC) detector is a non-linear detector used for detecting the presence of a signal of known frequency in noise. It is a simple but effective detector that is widely used in communication systems. The SC detector works by multiplying the input signal with a reference signal, which is a sawtooth waveform with the same frequency as the input signal. The sawtooth waveform is generated by a voltage-controlled oscillator (VCO), as shown in Figure 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/dsw5V7O.png&quot; alt=&quot;SC Detector Block Diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 1: Block Diagram of SC Detector&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The output of the multiplier is a sum of harmonics of the input signal frequency, which is filtered by a bandpass filter (BPF) centered at the input frequency. The output of the BPF is then rectified and low-pass filtered (LPF) to obtain the Envelope of the input signal, as shown in Figure 2.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/2ZQURWd.png&quot; alt=&quot;SC Detector Output Waveforms&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 2: SC Detector Output Waveforms&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The envelope output is compared to a threshold, which is set according to the noise level. If the envelope output exceeds the threshold, it is considered as a signal present.&lt;/p&gt;

&lt;h2 id=&quot;sc-detector-variants&quot;&gt;SC Detector Variants&lt;/h2&gt;

&lt;p&gt;There are several variants of the SC detector, which are listed below:&lt;/p&gt;

&lt;h3 id=&quot;quadrature-sc-detector-qscd&quot;&gt;Quadrature SC Detector (QSCD)&lt;/h3&gt;

&lt;p&gt;The Quadrature SC Detector (QSCD) is a variant of the SC detector that uses two reference signals, which are in-phase and quadrature-phase (I/Q) with the input signal. The reference signals are generated by two voltage-controlled oscillators (VCOs), as shown in Figure 3.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/65Fcgs0.png&quot; alt=&quot;QSCD Block Diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 3: Block Diagram of QSCD&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The output of the QSCD is obtained by adding the envelope outputs of the I and Q channels. The threshold for the QSCD is set according to the noise level.&lt;/p&gt;

&lt;h3 id=&quot;multi-stage-sc-detector-msscd&quot;&gt;Multi-Stage SC Detector (MSSCD)&lt;/h3&gt;

&lt;p&gt;The Multi-Stage SC Detector (MSSCD) is a variant of the SC detector that uses multiple stages of bandpass filtering to suppress noise. The MSSCD works by bandpass filtering the input signal at multiple stages, as shown in Figure 4.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/gtDfHtI.png&quot; alt=&quot;MSSCD Block Diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 4: Block Diagram of MSSCD&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The output of each stage is rectified and low-pass filtered, and then added to obtain the final output. The threshold for the MSSCD is set according to the noise level.&lt;/p&gt;

&lt;h3 id=&quot;multi-band-sc-detector-mbscd&quot;&gt;Multi-Band SC Detector (MBSCD)&lt;/h3&gt;

&lt;p&gt;The Multi-Band SC Detector (MBSCD) is a variant of the SC detector that uses multiple bandpass filters to separate the input signal into multiple frequency bands. The MBSCD works by splitting the input signal into multiple frequency bands using bandpass filters, as shown in Figure 5.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Yc3W6Oe.png&quot; alt=&quot;MBSCD Block Diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 5: Block Diagram of MBSCD&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The output of each bandpass filter is rectified and low-pass filtered, and then added to obtain the final output. The threshold for the MBSCD is set according to the noise level.&lt;/p&gt;

&lt;h2 id=&quot;statistics-and-equations&quot;&gt;Statistics and Equations&lt;/h2&gt;

&lt;p&gt;In this section, we will discuss the statistics and equations for the SC detector and its variants.&lt;/p&gt;

&lt;h3 id=&quot;sc-detector-1&quot;&gt;SC Detector&lt;/h3&gt;

&lt;p&gt;The output of the SC detector is given by:&lt;/p&gt;

\[S_{out} = \sqrt{2}A_I\sum_{n=-\infty}^{\infty} J_n(B)cos(\omega_0 nt + \phi_n) + \sqrt{2}A_Q\sum_{n=-\infty}^{\infty} J_n(B)sin(\omega_0 nt + \psi_n) + N(t)\]

&lt;p&gt;where $J_n(B)$ is the Bessel function of the first kind and order $n$, $B$ is the modulation index, $A_I$ and $A_Q$ are the amplitudes of the I and Q channels, $\omega_0$ is the frequency of the input signal, $t$ is time, and $N(t)$ is the Gaussian noise.&lt;/p&gt;

&lt;p&gt;The envelope output of the SC detector is given by:&lt;/p&gt;

\[E(t) = \sqrt{(S_{out})^2} = \sqrt{2}\sum_{n=-\infty}^{\infty} J_n(B)cos(\omega_0 nt + \phi_n) + \sqrt{2}\sum_{n=-\infty}^{\infty} J_n(B)sin(\omega_0 nt + \psi_n) + \sqrt{(N(t))^2}\]

&lt;p&gt;where $\phi_n$ and $\psi_n$ are the phases of the I and Q channels, respectively.&lt;/p&gt;

&lt;p&gt;The detection probability ($P_D$) and false alarm probability ($P_{FA}$) of the SC detector are given by:&lt;/p&gt;

\[P_D = Q(\frac{\gamma - d^2}{2\sigma})\]

\[P_{FA} = Q(\frac{\gamma}{2\sigma})\]

&lt;p&gt;where $\gamma$ is the detection threshold, $\sigma$ is the noise standard deviation, and $d$ is the signal-to-noise ratio.&lt;/p&gt;

&lt;h3 id=&quot;qscd&quot;&gt;QSCD&lt;/h3&gt;

&lt;p&gt;The output of the QSCD is given by:&lt;/p&gt;

\[S_{out} = \sqrt{2}A_I\sum_{n=-\infty}^{\infty} J_n(B)cos(\omega_0 nt + \phi_n) + \sqrt{2}A_Q\sum_{n=-\infty}^{\infty} J_n(B)sin(\omega_0 nt + \psi_n) + N(t)\]

&lt;p&gt;The envelope output of the QSCD is given by:&lt;/p&gt;

\[E(t) = \sqrt{(S_{out})^2} = \sqrt{2}\sum_{n=-\infty}^{\infty} J_n(B)cos(\omega_0 nt + \phi_n) + \sqrt{2}\sum_{n=-\infty}^{\infty} J_n(B)sin(\omega_0 nt + \psi_n) + \sqrt{(N(t))^2}\]

&lt;p&gt;The detection probability ($P_D$) and false alarm probability ($P_{FA}$) of the QSCD are given by:&lt;/p&gt;

\[P_D = Q(\frac{\gamma - d^2}{2\sigma})\]

\[P_{FA} = Q(\frac{\gamma}{2\sigma})\]

&lt;p&gt;where $\gamma$ is the detection threshold, $\sigma$ is the noise standard deviation, and $d$ is the signal-to-noise ratio.&lt;/p&gt;

&lt;h3 id=&quot;msscd&quot;&gt;MSSCD&lt;/h3&gt;

&lt;p&gt;The output of the MSSCD is given by:&lt;/p&gt;

\[S_{out} = \sum_{i=1}^{N} \sqrt{2}A_i\sum_{n=-\infty}^{\infty} J_n(B_i)cos(\omega_{0i} nt + \phi_{ni}) + N(t)\]

&lt;p&gt;The envelope output of the MSSCD is given by:&lt;/p&gt;

\[E(t) = \sqrt{(S_{out})^2} = \sqrt{2}\sum_{i=1}^{N}\sum_{n=-\infty}^{\infty} J_n(B_i)cos(\omega_{0i} nt + \phi_{ni}) + \sqrt{(N(t))^2}\]

&lt;p&gt;The detection probability ($P_D$) and false alarm probability ($P_{FA}$) of the MSSCD are given by:&lt;/p&gt;

\[P_D = Q(\frac{\gamma - d^2}{2\sigma})\]

\[P_{FA} = Q(\frac{\gamma}{2\sigma})\]

&lt;p&gt;where $\gamma$ is the detection threshold, $\sigma$ is the noise standard deviation, and $d$ is the signal-to-noise ratio.&lt;/p&gt;

&lt;h3 id=&quot;mbscd&quot;&gt;MBSCD&lt;/h3&gt;

&lt;p&gt;The output of the MBSCD is given by:&lt;/p&gt;

\[S_{out} = \sum_{i=1}^{N} \sqrt{2}A_i\sum_{n=-\infty}^{\infty} J_n(B_i)cos(\omega_{0i} nt + \phi_{ni}) + N(t)\]

&lt;p&gt;The envelope output of the MBSCD is given by:&lt;/p&gt;

\[E(t) = \sqrt{(S_{out})^2} = \sqrt{2}\sum_{i=1}^{N}\sum_{n=-\infty}^{\infty} J_n(B_i)cos(\omega_{0i} nt + \phi_{ni}) + \sqrt{(N(t))^2}\]

&lt;p&gt;The detection probability ($P_D$) and false alarm probability ($P_{FA}$) of the MBSCD are given by:&lt;/p&gt;

\[P_D = Q(\frac{\gamma - d^2}{2\sigma})\]

\[P_{FA} = Q(\frac{\gamma}{2\sigma})\]

&lt;p&gt;where $\gamma$ is the detection threshold, $\sigma$ is the noise standard deviation, and $d$ is the signal-to-noise ratio.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;p&gt;In this section, we will provide Python implementation for the SC detector and its variants.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.special&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sc_detector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Generate sawtooth waveform
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sawtooth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sawtooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Multiply input signal with sawtooth waveform
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sawtooth&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Apply bandpass filter
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;band&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Rectify and low-pass filter
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;low&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Thresholding
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;qsc_detector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Generate I and Q reference signals
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i_ref&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q_ref&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Multiply input signal with I and Q reference signals
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_ref&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_ref&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Apply bandpass filter
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;band&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Rectify and low-pass filter
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;low&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Sum the envelope outputs of I and Q channels
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_out&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Thresholding
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mss_detector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Generate sawtooth waveform for each stage
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sawtooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Apply bandpass filter for each stage
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;band&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s_out_stage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Rectify and low-pass filter
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;s_out_stage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out_stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;low&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s_out_stage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_out_stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Add the envelope output of the current stage to the final output
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_out_stage&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Thresholding
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mbs_detector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Apply bandpass filter for each band
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;band&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s_out_band&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Rectify and low-pass filter
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;s_out_band&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out_band&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;low&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s_out_band&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_out_band&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Add the envelope output of the current band to the final output
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_out_band&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Thresholding
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In summary, non-linear detectors like the Sequentially Cyclic (SC) detector and its variants (Quadrature SC Detector, Multi-Stage SC Detector, Multi-Band SC Detector) are widely used in communication systems for detecting the presence of a signal in noise. The SC detector works by multiplying the input signal with a sawtooth waveform and filtering the output signal to obtain the envelope. The envelope is compared to a threshold to determine the presence of a signal.&lt;/p&gt;

&lt;p&gt;We have detailed the statistics and equations for the SC detector and its variants, along with Python implementation for each variant. These detectors have practical applications in various areas of signal processing, such as communications, radar, and medical imaging.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>S Transform: A Denoising Method in Time-Frequency Domain</title>
   <link href="http://localhost:4000/2023/04/12/s-transform"/>
   <updated>2023-04-12T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/12/s-transform</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Time-frequency analysis is an important tool for analyzing signals that contain both time-varying and frequency-varying components. The Short Time Fourier Transform (STFT) is the most commonly used technique for time-frequency analysis, but it suffers from a time-frequency resolution trade-off problem. The S transform is an alternative time-frequency analysis technique that overcomes this problem by using a windows of variable length. In addition to time-frequency analysis, the S transform has also been used as a denoising method for signals.&lt;/p&gt;

&lt;p&gt;In this article, we will provide an overview of the S transform and its usage as a denoising method in time-frequency domain. We will also provide a Python implementation of the S transform and its denoising operation.&lt;/p&gt;

&lt;h1 id=&quot;the-s-transform&quot;&gt;The S Transform&lt;/h1&gt;
&lt;p&gt;The S transform is a time-frequency analysis technique that uses a variable length window to estimate the local frequency content of a signal. The S transform of a signal is defined as follows:&lt;/p&gt;

\[S(\tau, f) = \int_{-\infty}^{\infty} x(t) w(t-\tau) e^{-2\pi i f t} dt\]

&lt;p&gt;where x(t) is the signal, w(t) is a complex valued window function, $f \in \mathbb{R}$ is the frequency variable, and $\tau \in \mathbb{R}$ is the time variable.&lt;/p&gt;

&lt;p&gt;The window function w(t) has to satisfy some conditions in order for the S transform to be well defined. First, w(t) should be a complex valued function that is differentiable in some region. Second, the window function should have finite energy, i.e., $\int_{-\infty}^{\infty} \lvert w(t) \rvert^2 dt &amp;lt; \infty$. Third, the window function should be compactly supported, i.e., w(t) = 0 for $\lvert t \rvert &amp;gt; W$, where W is the window length. Fourth, the window function should have a minimum uncertainty property, which means that the product of the window function and its Fourier transform should have a minimum uncertainty.&lt;/p&gt;

&lt;p&gt;The S transform can be computed efficiently using the Fast Fourier Transform (FFT) algorithm. The S transform of a signal x can be obtained as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Divide the signal x into overlapping segments of length L and apply the window function w to each segment.&lt;/li&gt;
  &lt;li&gt;Compute the FFT of the windowed segments.&lt;/li&gt;
  &lt;li&gt;Multiply the FFT of the windowed segments by a phase factor corresponding to the time shift $\tau$.&lt;/li&gt;
  &lt;li&gt;Compute the inverse FFT of the product obtained in step 3.&lt;/li&gt;
  &lt;li&gt;Repeat steps 2 to 4 for different values of $\tau$ and $f$ to obtain the S transform.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;denoising-using-the-s-transform&quot;&gt;Denoising using the S Transform&lt;/h1&gt;
&lt;p&gt;The S transform has been used as a denoising method for signals. The idea behind using the S transform for denoising is that in the time-frequency domain, the noise is spread out over a wide range of frequencies, whereas the signal is concentrated in a few frequency bands. Therefore, by thresholding the S transform coefficients corresponding to the noise, the noise can be effectively removed while preserving the signal.&lt;/p&gt;

&lt;p&gt;The denoising operation using the S transform can be described as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the S transform of the noisy signal.&lt;/li&gt;
  &lt;li&gt;Calculate the noise threshold using some thresholding function (e.g., universal threshold, soft threshold, hard threshold).&lt;/li&gt;
  &lt;li&gt;Set the S transform coefficients with magnitude less than the threshold to zero.&lt;/li&gt;
  &lt;li&gt;Compute the inverse S transform to obtain the denoised signal.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h1&gt;
&lt;p&gt;We provide a Python implementation of the S transform and its denoising operation using the PyWavelets library.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;s_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_frequencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Compute the S transform of a signal x using a given window function and number of frequencies.
    
    Parameters:
        x (numpy array): The input signal.
        window (numpy array): The complex valued window function.
        n_frequencies (int): The number of frequencies to compute.
        
    Returns:
        st (numpy array): The S transform of the signal.
        freqs (numpy array): The array of frequency values.
        times (numpy array): The array of time values.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;timesteps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fftfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_frequencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timesteps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;complex128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timesteps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_frequencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scale2time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_frequencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Threshold the S transform coefficients based on a given thresholding function.
    
    Parameters:
        S (numpy array): The S transform of the signal.
        threshold_fn (function): The thresholding function.
        sigma (float): The standard deviation of the noise.
        
    Returns:
        S_thresholded (numpy array): The thresholded S transform of the signal.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;noise_std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6745&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;threshold_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;S_thresholded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;S_thresholded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S_thresholded&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inverse_s_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Compute the inverse S transform of a thresholded S transform.
    
    Parameters:
        S (numpy array): The thresholded S transform.
        
    Returns:
        x (numpy array): The denoised signal.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;timesteps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timesteps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;complex128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ifft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;half_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;blackmanharris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;s_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st_thresholded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thresholding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_denoised&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inverse_s_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_thresholded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this article, we discussed the concept of the S transform and its usage as a denoising method in time-frequency domain. We provided a Python implementation of the S transform and its denoising operation using the PyWavelets library. The S transform has advantages over the STFT in terms of time-frequency resolution and the denoising operation using the S transform has shown promising results in various applications of signal processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Improved signal detection using efficient timefrequency de-noising technique and Pre-whitening filter</title>
   <link href="http://localhost:4000/2023/04/11/improved-signal-detection"/>
   <updated>2023-04-11T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/11/improved-signal-detection</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In the present study, the proposed Gaussian noise injection
detector (GNID) represents a complete detection system. This
detector is developed to improve the probability of detection (PD)
using a pre-whitening filter, a timefrequency de-noising algorithm
based on S-transform, and an inverse whitening filter. Stransform
is used in the de-noising process to overcome the limitations
and poor performance of de-noising using the wavelet
transform [25]. The UWAN used for the validation of the system
is sea-truth data, which are collected at the Desaru Beach on the
eastern shore of Johor in Malaysia using broadband hydrophones.
The performance results of the proposed detector are compared
with other nonlinear detectors, namely, locally optimal (LO), sign
correlation (SC), and conventional LC.&lt;/p&gt;

&lt;h2 id=&quot;signal-detection-problem&quot;&gt;Signal detection problem&lt;/h2&gt;

&lt;p&gt;In this section, a known signal is to be detected in an additive noise channel representing a common problem in communication, radar, and sonar systems, that is, where the noise follows a Students t-distribution and the noise samples are uncorrelated.
2.1. Signal model
The signals used are single-frequency sinusoidal and linear frequency modulated (LFM) signals. These signals represent the fixed frequency and time-varying signals that can be encountered in practical situations. An arbitrary sinusoidal signal can be defined as follows:
\(\begin{aligned}
s(n) &amp;amp; =A \cos (\alpha(n)) &amp;amp; &amp;amp; 0 \leqslant n \leqslant N-1 \\
&amp;amp; =0 &amp;amp; &amp;amp; \text { elsewhere }
\end{aligned}\)
where $N$ is the signal duration in the samples, $A$ is signal amplitude, and $\alpha(n)$ is the instantaneous phase. For a fixed-frequency signal, the instantaneous phase is defined as
\(\alpha(n)=2 \pi f_m n T_s\)
where $f_m$ is signal frequency, and $T_s$ is the sampling period. The instantaneous phase for the LFM signal is
\(\alpha(n)=2 \pi\left(f_m+\frac{\varphi}{2} n T_s\right) n T_s\)
where $\varphi$ is the frequency defined as $\varphi=f_{B W} / N T_S$, where $f_{B W}$ is the signal bandwidth.&lt;/p&gt;

&lt;p&gt;Given the combined influences of the internal measurement system and the external environmental factors, measured signals are often contaminated with noise. Thus, the received signal can be defined as follows:
\(x(n)=s(n)+v(n)\)
where $s(n)$ is the signal of interest, and $v(n)$ is the UWAN. The assumption of a Gaussian distribution for UWAN is explained in [26]. However, recent studies have suggested that UWAN follows a t-distribution [27] and a stable alpha distribution [11]. Therefore, the purpose of de-noising is to reduce the degree of corruption on $s(n)$ by $v(n)$&lt;/p&gt;

&lt;p&gt;The main idea of detection is to determine the presence of a signal in the noise. Given an observation vector $x$ and several hypotheses $\mathrm{H} i$, the aim is to find the data set that matches a hypothesis. Although the number of hypotheses can be arbitrary,
the case of having two hypotheses, $\mathrm{H}_0$ and $\mathrm{H}_1$, is considered applicable to communication, radar, and sonar systems [8]. If the pdf for each hypothesis is assumed to be completely known, then the hypothesis-testing problem is formulated as follows:
$H_0($ Null hypothesis $): y(n)=v(n) n=0,1, \ldots, N-1$
$H_1$ (Alternative hypothesis) : $x(n)=s(n)+v(n) n=0,1, \ldots, N-1$
Neyman-Pearson (NP) and Bayesian methods are primarily used for hypothesis testing. Method selection depends on the availability of prior probability. Although digital communication and pattern recognition systems use the Bayes risk [28], the NP criterion is employed for radar and sonar systems. Furthermore, the derivation of optimal detectors depends on the assumption about the noise [8]. Given that UWAN is frequency dependent [1,29], the assumption of AWGN is invalid, and UWAN is more appropriately modelled as colored noise $[12,13,30]$. The power spectrum of the colored noise is defined as $[31,32]$
\(S_{V V}\left(e^{j 2 \pi f}\right)=\frac{1}{f^\delta} \quad \delta&amp;gt;0, \quad \frac{-f_s}{2} \leqslant f \leqslant \frac{f_s}{2}\)
AWGN has a delta autocorrelation function, that is, the adjacent samples are independent and identically distributed. Conversely, $\frac{1}{f^\delta}$ noise has a $\operatorname{sinc}()$ autocorrelation function $[28,31]$. Unlike AWGN, the samples of $\frac{1}{f^s}$ noise are correlated.&lt;/p&gt;

&lt;h2 id=&quot;complete-detection-system&quot;&gt;Complete detection system&lt;/h2&gt;

&lt;p&gt;Since the UWAN is colored with a non-Gaussian distribution, the proposed detection system is a GNID, which is shown in Fig. 5. The complete detection system based on the noise models consists of the broadband hydrophone, pre-whitening filter, time-frequency distribution, de-noising method, inverse whitening filter, and detection stage. In this section, the performance of the GNID is compared with three other linear and nonlinear detectors.&lt;/p&gt;

&lt;h3 id=&quot;signal-detection-in-the-t-distributed-noise-using-gnid&quot;&gt;Signal detection in the t-distributed noise using GNID&lt;/h3&gt;

&lt;p&gt;For non-Gaussian detection, linear and nonlinear detectors demonstrate optimal or at least near-optimal performance. In this study, the performances of four detectors for the detection of a known signal in additive UWAN are compared: LO, SC, and LC detectors, and the proposed GNID.&lt;/p&gt;

&lt;p&gt;In the presence of a Gaussian noise, the LC detector is optimal for detecting a known signal. Many communication systems use this detector as a matched filter. The test statistic for the matched filter is given by [8]
\(T(x)=\sum_{n=0}^{N-1} x[n] s[n]\)
where $s(n)$ is the signal to be detected (reference signal) and $x(n)$ denotes the observed data. The expected value $\left(E\left{T ; H_i\right}\right.$ for $i=0$, 1) and the variance of the test statistic $\left(\operatorname{Var}\left{T ; H_i\right}\right.$ for $\left.i=0,1\right)$ are $T(x)= \begin{cases}N\left(0, v \operatorname{var}(v) \cdot E_s\right) &amp;amp; \text { under } H_0 \ N\left(E_s, \operatorname{var}(v) \cdot E_s\right) &amp;amp; \text { under } H_1\end{cases}$
where $E_s$ is the energy of the signal, and $\operatorname{var}(v)$ is the variance of the noise that follows the $t$-distribution defined in Eq. (7). The false alarm probability $\left(P_{F A}\right)$ is defined as&lt;/p&gt;

&lt;p&gt;\(\mathrm{P}_{F A}=\mathrm{P}\left(\mathrm{H}_1 ; \mathrm{H}_0\right)=P_r\left\{x[0]&amp;gt;\gamma ; H_0\right\}=Q\left(\frac{\gamma}{\left(\operatorname{var}(v) \cdot E_s\right)^{1 / 2}}\right)\)
where $\gamma$ is the threshold value for a given $P_{F A}$, and this threshold value is determined using
\(\gamma=Q^{-1}\left(P_{F A}\right) \cdot\left(\operatorname{var}(v) \cdot E_s\right)^{1 / 2}\)
The $P_D$ is defined as
\(P_D=P\left(H_1 ; H_1\right)=P_r\left\{x[0]&amp;gt;\gamma ; H_1\right\}=Q\left(\frac{\gamma-E_s}{\left(v \operatorname{var}(v) \cdot E_s\right)^{1 / 2}}\right)\)
By using Eqs. (9) and (11) in Eq. (12), we obtain the following equation [8]:
\(P_D=Q\left[Q^{-1}\left(P_{F A}\right)-\sqrt{\frac{E_S}{\operatorname{var}(v)}}\right]\)
As mentioned in the previous section, the LC detector shows performance degradation in the presence of non-Gaussian noise. Furthermore, nonlinear detectors have several limitations when used for non-Gaussian detection. For example, the LO detector is used for the detection of weak signals by introducing a nonlinear transfer function before a standard LC detector. The test statistic for the LO detector is given by [8-11]
\(T(x)=\sum_{n=0}^{N-1} g(x[n]) s[n]\)
where $g(x[n])$ is the nonlinear transfer function that can be determined from the noise pdf:
\(g(x)=-\frac{1}{\rho(x)} \frac{d \rho(x)}{d x}\)
where $\rho(x)$ is the pdf for a $t$-distribution defined in Eq. (7).
Another nonlinear detector is the SC detector, which is a nonparametric detector designed without predetermining the exact distribution of noise. Although the aforementioned feature of the SC detector can be considered advantageous, a negative effect on the performance may result from the lack of detailed information on noise distribution. The test statistic for the SC detector is as follows
\(T(x)=\sum_{n=0}^{N-1} \operatorname{sgn}(x[n]) s[n]\)
In this paper, we propose a GNID based on a noise-enhanced signal detection [14] using an S-transform de-noising method and prewhitening filter to ensure that the noise follows a Gaussian distri-bution and overcome the limitations of nonlinear detectors exclusively used for non-Gaussian detection. The basic idea of this proposed method is to insert a Gaussian noise to the UWAN that follows a t-distribution and convert that UWAN into a noise following a Gaussian distribution, which has a lighter tail than a t-distribution [15]. Given that the noise power has increased because of the insertion process, a de-noising algorithm using the S-transform is required before performing matched-filter detection, as shown in Fig. 5.&lt;/p&gt;

&lt;p&gt;The sum of two independent random variables $X$ and $Y$, whose pdfs are $\rho_X(x)$ and $\rho_Y(y)$, respectively, produces a random variable $Z$ whose pdf $\rho_Z(z)$ is
\(\rho_Z(z)=\rho_X(x) * \rho_Y(y)=\int_{-\infty}^{\infty} \rho_Y(y) \rho_X(z-x) d y\)
The expression in Eq. (17), is a convolution integral. The distribution of the sum of two independent Gaussian and Students $t$ (for three degrees of freedom) spherical random variables was studied in [15]. Two random variables $X$ and $Y$ are considered. $X$ is a Gaussian random variable with mean $\bar{X}$, variance $\sigma_v^2$, and pdf $\rho_X(x) ; Y$ is a $t$-distributed random variable with $v$-degrees of freedom, mean $\mu_v$, variance $\operatorname{var}(v)$, and pdf $\rho_y(y)$ [15]. The pdf for the sum of the random variables is [35]
\(f_Z(z)=\frac{\Gamma\left(\frac{d+1}{2}\right)}{\sqrt{2 \pi} \sigma_v \Gamma\left(\frac{d}{2}\right)} \cdot \Psi\left(\frac{1}{2}, 1-\frac{d}{2} ; \frac{d}{2 \sigma_v^2}\right) \cdot e^{-\frac{z^2}{2 \sigma_v^2}}\)
where $|z| \leqslant \infty, v&amp;gt;0$, and $\sigma_v&amp;gt;0 ; \Psi($.$) denotes the Kummers$ hypergeometric function. By substituting $v=1$ and using the relationship between Kummers hypergeometric function and the complementary error function [36], the following equation is obtained: $\operatorname{erfc}(x)=\frac{1}{\sqrt{\pi}} \cdot e^{-x^2} \cdot \Psi\left(\frac{1}{2}, \frac{1}{2} ; x^2\right)$&lt;/p&gt;

&lt;p&gt;Subsequently, Eq. (19) is substituted into Eq. (18) to obtain
\(f_z(z)=\frac{1}{\sqrt{2 \pi} \sigma_v} \cdot e^{\frac{1}{2 \sigma_v^2}} \cdot \operatorname{erfc}\left(\frac{1}{\sqrt{2} \sigma_v^2}\right) \cdot e^{-\frac{z^2}{2 \sigma_v^2}}\)
Eq. (20) shows that the function approaches a Gaussian distribution as the variance or the degrees of freedom increases. A normality test, such as the Lilliefors test, is performed to determine if the pdf of the sum of the random variables is approximately Gaussian [37,38]. If the degree of freedom is greater than 1, the pdf in Eq. (20) is approximately Gaussian. The threshold derived from the $P_{F A}$ can be calculated by Eq. (11). The $P_D$ can be calculated by the threshold defined in Eq. (13).&lt;/p&gt;

&lt;p&gt;!&lt;span title=&quot;There is no note that matches this link.&quot; class=&quot;invalid-link&quot;&gt;  &lt;span class=&quot;invalid-link-brackets&quot;&gt;[[&lt;/span&gt;  gnid.png  &lt;span class=&quot;invalid-link-brackets&quot;&gt;]]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&quot;whitening-process-and-inverse-whitening-filter&quot;&gt;Whitening process and inverse whitening filter&lt;/h3&gt;

&lt;p&gt;The colored noise can be transformed into white by passing into a linear time invariant (LTI) whitening filter $[28,39]$. The prediction error filter (PEF) with transfer function $H_p(z)$ is used for this purpose $[32,40]$. The output of the PEF is used as the difference between the estimate of the linear predictor and the actual sequence. The transfer function of the PEF can be expressed as
\(H_p(z)=1+a_1 z^{-1}+a_2 z^{-2}+\ldots+a_p z^{-p}\)
where $\mathrm{p}$ is the length of the forward predictor filter, and $a_p(n)$ is the filter coefficients and depends on the UWAN data recording. If the order $p$ of the PEF is sufficiently large, then the forward prediction error is orthogonal with constant variance; thus, the output of filter is similar to AWGN [32]. Selecting the model order to use for the pre-whitening and the inverse pre-whitening filters is done using several standard order selection techniques. These methods include Akaikes information criterion (AIC), Rissanens minimum description length, and maximum a posteriori probability [32,41,42]. The AIC provides a distinct minimum at the optimum model order $P$
and is the criteria selected for deciding the pre-whitening filter model order in this study.&lt;/p&gt;

&lt;p&gt;The output of the PEF is referred to as $x_w(n)$ and represents the convolution process between the input noisy signal $x(n)$ and the impulse response of the whitening filter $h_w(n)$. Thus, the resulting PEF is the transform of the signal with the AWGN, which is expressed as follows
\(x_w(n)=x(n) * h_w(n)=s(n) * h_w(n)+v(n) * h_w(n)\)&lt;/p&gt;

&lt;p&gt;After the filter coefficients are determined, the de-noising process minimizes the noise term $v(n) * h_w(n)$ to produce a clean estimate of the transform signal, which can be obtained as follows
\(\hat{s}_w(n)=s(n) * h_w\)
The original signal $s(n)$ can be recovered with an inverse whitening filter [43] with impulse response $h_{I W F}(n)$ and transfer function $1 / H_p(z)$. The estimate of the original signal is&lt;/p&gt;

&lt;p&gt;\(\hat{s}(n)=\hat{s}_w(n) * h_{I W F}(n)=s(n) * h_w(n) * h_{I W F}(n)\)
In the z-domain, the estimation of the original signal can be expressed as
\(\hat{S}(z)=S(z) \cdot H_P(z) \cdot \frac{1}{H_P(z)}=S(z)\)&lt;/p&gt;
&lt;h3 id=&quot;time-frequency-de-noising-process-based-on-the-s-transform&quot;&gt;Time-frequency de-noising process based on the S-transform&lt;/h3&gt;

&lt;p&gt;The S-transform is used for the signal transformation in the denoising process, as shown in Fig. 6. S-transform can be considered a special case of the short-time Fourier transform); the window function is replaced with a frequency-dependent Gaussian window $[44,45]$. The Gaussian window width is inversely proportional to the frequency, and its height is scaled linearly with the frequency. Given this window scaling behaviour, the S-transform possesses a good time resolution for high-frequency components and a good frequency resolution for low-frequency components. Thus, the S-transform is suitable to use for signal de-noising in underwater applications because the underwater acoustic signals are mostly in the $0-2500 \mathrm{~Hz}$ frequency band that represents low-frequency signals [46]. The S-transform can be expressed as [44]
\(X(t, f)=\int_{-\infty}^{\infty} x(\tau) \cdot g(\tau-t, f) \cdot e^{-j 2 \pi f \tau} d \tau\)
where $x(t)$ is the signal, and $g(t, f)$ is the frequency-dependent Gaussian window, which is expressed as follows [44]:
\(g(t, f)=\frac{|f|}{\sqrt{2 \pi}} e^{\left(\frac{t^2 f^2}{2}\right)}\)
The presence of the variable $f$ renders the frequency-dependent window spread. Given that $X(t, f)$ is a complex value, the modulus $|X(t, f)|$ is usually plotted in practice to construct a time-frequency representation. The S-transform represents the local spectrum; thus, averaging the local spectrum over time generates the Fourier spectrum, which can be expressed as follows [44]:
\(\int_{-\infty}^{\infty} X(t, f) d t=X(f)\)
The signal in time representation $x(t)$ is exactly recoverable from $X(t, f)$ based on the following expression $[44,47]$ :
\(x(t)=\int_{-\infty}^{\infty}\left\{\int_{-\infty}^{\infty} X(t, f) d t\right\} e^{j 2 \pi f t} d f\)
In this study, de-noising is performed in the time-frequency representation, and the signal is recovered from the noise using Eq. (29).
The discrete S-transform is used in this study to allow the processing in the continuous S-transform. Let $x(n), n=0,1, \ldots(N-1)$ denote a discrete time series corresponding to $x(t)$ with a time sampling interval of $T_s$. The S-transform of the discrete time series $x(n)$ is expressed as:&lt;/p&gt;

&lt;p&gt;\(X(n, k)=\sum_{m=0}^{N-1} x(m-n) e^{\frac{-2 \pi^2 m^2}{k^2}} e^{\frac{-j 2 \pi m k}{N}}\)
The inverse of the discrete S-transform is expressed as follows [48]: $x(n)=\frac{1}{N} \sum_{k=0}^{N-1}\left{\sum_{n=0}^{N-1} X(n, k)\right} e^{\frac{i 2 \pi n k}{N}}$&lt;/p&gt;

&lt;p&gt;In this study, a de-noising method based on a time-frequency analysis is proposed, with the S-transform used as an alternative to the wavelet transform. A key feature of the S-transform is its capacity to uniquely combine a frequency-dependent resolution with the simultaneously localizing real and imaginary spectra [49]. In contrast&lt;/p&gt;

&lt;p&gt;to the wavelet approach, the S-transform provides a frequency invariant amplitude response. Moreover, the S-transform uses a time-frequency axis rather than a time-scale axis, which is used in the wavelet transform. Therefore, the interpretation of the frequency information in the S-transform is more straightforward than that in the wavelet approach. Furthermore, the use of the S-transform is beneficial to the removal of noises for all frequency components [50].
The de-noising process using the S-transform is described as follows:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;A discrete S-transform using Eq. (30) is applied to noisy signals (signals that are corrupted by UWAN and defined in Eqs. (1-4)), as shown in Fig. 7. Based on the properties of the discrete Fourier transform and convolution theorem, the S-transform in Eq. (30) can be considered a convolution process in the frequency domain between the signal $X(k)$ and the localizing scalable Gaussian window ( $k$. The S-transform can be expressed as
\(\begin{aligned}
X(n, k) &amp;amp; =\sum_{m=0}^{N-1} x(m-n) e^{\frac{-2 \pi^2 m^2}{k^2}} e^{\frac{-j 2 \pi m k}{N}}=\sum_{m=0}^{N-1} x(m-n) w(m) e^{\frac{-j 2 \pi m k}{N}} \\
&amp;amp; =X(k) * W(k) e^{-j \frac{2 \pi n k}{N}}
\end{aligned}\)
(k)
If the signal is considered in terms of real and imaginary components, Eq. (31) can be written as
\(X(n, k)=\left[X_{r e}(k)+j X_{i m}(k)\right] * \quad W(k) e^{-j \frac{j \pi n k}{N}}\)
$(k)$
\(=\left[\begin{array}{cc}
X_{r e}(k) * W(k) e^{-j \frac{2 \pi n k}{N}}+j X_{i m}(k) * W(k) e^{-j \frac{2 \pi n k}{N}} \\
(k) &amp;amp; (k)
\end{array}\right]\)
The complex exponential denoted by $\left(e^{-j \frac{2 \pi n k}{N}}\right)$ represents the shift of the window in the time domain.&lt;/li&gt;
  &lt;li&gt;A pre-whitening transform is applied to the input data before generating the time-frequency representation of noisy signals. The output of the pre-whitening filter is a colored version of the signal in additive white noise, as shown in Fig. 8.&lt;/li&gt;
  &lt;li&gt;After a pre-whitening transform is applied to the input data, de-noising is performed using soft thresholding by adaptive universal threshold estimation. Subsequently, a pre-whitening filter, which alleviates the need to calculate a separate threshold for every scale, is used. The use of a pre-whitening transform produces better results than that of applying level-wise thresholding on the data that was proposed in [51]. The threshold value applied to the time-frequency coefficients estimated by adaptive universal threshold estimation [52] is expressed as:
\(\lambda=c \cdot \sigma_v \sqrt{2 \log (N)}\)
where $N$ is the signal length, $\sigma_v$ is the noise standard deviation estimated for the first voice [53], and $c$ is the adaptive universal threshold factor $0&amp;lt;c&amp;lt;1$. The noise standard deviation for each voice is $\sigma_v=\frac{\operatorname{median}(|X(n, k)|)}{0.6745}$
where $X(n, k)$ represents all the coefficients for the first voice [51].
The threshold value $\lambda$ is used to remove noise and recover the original signal efficiently. The adaptive threshold factor $c$ is introduced to enhance the de-noising performance further [54]. The value of $c$ is determined by gradually changing it in increments of 0.1 for each voice to find the best results at the highest SNR.
According to Eq. (33), thresholding for both real and imaginary components of the spectrum should be performed in the&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;de-noising process in the frequency domain. Thus, the adaptive universal threshold estimation described in Eq. (34) should include both real and imaginary components. The threshold value is obtained as follows
\(\begin{aligned}
&amp;amp; \lambda_{r e}=c . \sigma_{v, r e} \sqrt{2 \log (N)} \\
&amp;amp; \lambda_{i m}=c \cdot \sigma_{v, i m} \sqrt{2 \log (N)}
\end{aligned}\)
where $\sigma_{v, k, r e}$ and $\sigma_{v, k, i m}$ are the noise standard deviations for the real and imaginary components, respectively. The $k$-th noise standard deviations are calculated as
\(\begin{aligned}
\sigma_{v, r e} &amp;amp; =\frac{\operatorname{median}\left(\left|X_{r e}(n, k)\right|\right)}{0.6745} \\
\sigma_{v, i m} &amp;amp; =\frac{\operatorname{median}\left(\left|X_{i m}(n, k)\right|\right)}{0.6745}
\end{aligned}\)
After the threshold values $\lambda_{k, r e}$ and $\lambda_{k, i m}$ are determined for the real and imaginary components, respectively, the time-frequency representations of the real and imaginary components after hard thresholding are
\(\begin{aligned}
&amp;amp; X_{\lambda, r e}(n, k)=\left\{\begin{array}{l}
X_{r e}(n, k) i f\left|X_{r e}(n, k)\right|&amp;gt;\lambda_{r e} \\
0 i f\left|X_{r e}(n, k)\right| \leqslant \lambda_{r e}
\end{array}\right. \\
&amp;amp; X_{\lambda, i m}(n, k)=\left\{\begin{array}{l}
X_{i m}(n, k) i f\left|X_{i m}(n, k)\right|&amp;gt;\lambda_{i m} \\
0 i f\left|X_{i m}(n, k)\right| \leqslant \lambda_{i m}
\end{array}\right.
\end{aligned}\)
Alternatively, the time-frequency representations of the real and imaginary components after soft thresholding are
\(\begin{aligned}
&amp;amp; X_{\lambda, r e}(n, k)=\left\{\begin{array}{l}
\operatorname{sgn}\left(X_{r e}(n, k)\right)\left(\left|X_{r e}(n, k)\right|-\gamma_{k, r e}\right) i f\left|X_{r e}(n, k)\right|&amp;gt;\lambda_{r e} \\
0 i f\left|X_{r e}(n, k)\right| \leqslant \lambda_{r e}
\end{array}\right. \\
&amp;amp; X_{\lambda, i m}(n, k)=\left\{\begin{array}{l}
\operatorname{sgn}\left(X_{i m}(n, k)\right)\left(\left|X_{i m}(n, k)\right|-\gamma_{k, i m}\right) i f\left|X_{i m}(n, k)\right|&amp;gt;\lambda_{i m} \\
0 i f\left|X_{i m}(n, k)\right| \leqslant \lambda_{i m}
\end{array}\right.
\end{aligned}\)
The time-frequency representation obtained by combining the real and imaginary components is
\(X_\lambda(n, k)=X_{\lambda, r e}(n, k)+j X_{\lambda, i m}(n, k)\)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The de-noised signal $x(n)$ in the time representation can be recovered using the inverse discrete S-transform in Eq. (31). The time-frequency representation of the noisy signal after the de-noising process and inverse whitening filter is shown in Fig. 9.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Adaptive Wavelet Shrinkage Method and Its Variants</title>
   <link href="http://localhost:4000/2023/04/10/adaptive-wavelet-shrinkage"/>
   <updated>2023-04-10T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/10/adaptive-wavelet-shrinkage</id>
   <content type="html">&lt;h1 id=&quot;adaptive-wavelet-shrinkage-method-and-its-variants&quot;&gt;Adaptive Wavelet Shrinkage Method and Its Variants&lt;/h1&gt;

&lt;p&gt;The Adaptive Wavelet Shrinkage Method (AWSM) is a signal processing technique used to denoise and compress signals efficiently, without losing important features of the signal. In many signal processing applications, noise can be a major issue which affects the accuracy of the signal. The AWSM provides a solution to this issue by removing noise from the signal while preserving the important features.&lt;/p&gt;

&lt;p&gt;The concept of AWSM was first introduced by Donoho and Johnstone in 1994 [1]. Since then, it has been widely used in various areas of signal processing such as data compression, image processing, speech processing, and many more.&lt;/p&gt;

&lt;h2 id=&quot;wavelet-transform&quot;&gt;Wavelet Transform&lt;/h2&gt;

&lt;p&gt;The Wavelet Transform is a mathematical tool used to decompose a signal into wavelets. It is a time-frequency analysis technique that provides a multi-resolution analysis of the signal. The wavelet transform can be represented as:&lt;/p&gt;

&lt;p&gt;\(W(a,b) = \int x(t)\Psi_{a,b}(t)dt\)
where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x(t)$ - Input signal&lt;/li&gt;
  &lt;li&gt;$\Psi _{a,b}(t)$ - Wavelet function with scale $a$ and translation $b$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The wavelet transform represents the signal $x(t)$ in terms of wavelets at different scales and positions. The wavelets form a set of basis functions that can capture the local features of the signal.&lt;/p&gt;

&lt;h2 id=&quot;thresholding&quot;&gt;Thresholding&lt;/h2&gt;

&lt;p&gt;Thresholding is a process where the coefficients of the wavelet transform are shrunk or thresholded. The thresholding process is done based on a threshold value, which determines which coefficients are retained and which are discarded.&lt;/p&gt;

&lt;h2 id=&quot;hard-thresholding&quot;&gt;Hard Thresholding&lt;/h2&gt;

&lt;p&gt;Hard Thresholding is a thresholding technique where the coefficients below a certain threshold value are set to zero, and the coefficients above the threshold value are retained.&lt;/p&gt;

&lt;p&gt;The hard thresholding operator $H_T$ can be represented as:&lt;/p&gt;

&lt;p&gt;\(y(t) = H_T[x(t)] = \sum_{j=1}^k x_j \Phi_j(t) + \sum_{j=k+1}^n \delta_j \Psi_j(t)\)
where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$k$ - The largest integer such that $&lt;/td&gt;
          &lt;td&gt;x_j&lt;/td&gt;
          &lt;td&gt;&amp;gt;T$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;$x_j$ - Wavelet coefficients&lt;/li&gt;
  &lt;li&gt;$\Phi_j(t)$ - Scaling function&lt;/li&gt;
  &lt;li&gt;$\Psi_j(t)$ - Wavelet function&lt;/li&gt;
  &lt;li&gt;$\delta_j$ - The sign of $x_j$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;soft-thresholding&quot;&gt;Soft Thresholding&lt;/h2&gt;

&lt;p&gt;Soft thresholding is a thresholding technique where the coefficients below a certain threshold value are set to zero, and the coefficients above the threshold value are shrunk towards zero.&lt;/p&gt;

&lt;p&gt;The soft thresholding operator $S_T$ can be represented as:&lt;/p&gt;

&lt;p&gt;\(y(t) = S_T[x(t)] = \text{sign}(x)(|x| - T)_{+}\)
where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$&lt;/td&gt;
          &lt;td&gt;x&lt;/td&gt;
          &lt;td&gt;$ - Magnitude of the wavelet coefficients&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;$\text{sign}(x)$ - Sign of the wavelet coefficients&lt;/li&gt;
  &lt;li&gt;$T$ - Threshold value&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adaptive-wavelet-shrinkage-method-awsm&quot;&gt;Adaptive Wavelet Shrinkage Method (AWSM)&lt;/h2&gt;

&lt;p&gt;The AWSM is a thresholding technique where the threshold value is adaptively determined. The threshold value is determined based on the statistics of the wavelet coefficients.&lt;/p&gt;

&lt;p&gt;The AWSM has three main steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Decompose the signal using the wavelet transform&lt;/li&gt;
  &lt;li&gt;Estimate the noise level from the wavelet coefficients&lt;/li&gt;
  &lt;li&gt;Threshold the wavelet coefficients based on the estimated noise level.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;estimation-of-noise-level&quot;&gt;Estimation of Noise Level&lt;/h3&gt;

&lt;p&gt;The estimation of noise level is an important step in the AWSM. The noise level is estimated using the Median Absolute Deviation (MAD) of the wavelet coefficients. The MAD is a robust estimator of the noise level, which is less sensitive to outliers.&lt;/p&gt;

&lt;p&gt;The MAD can be represented as:&lt;/p&gt;

&lt;p&gt;\({\rm MAD} = {\rm median}(|x_i - {\rm median}(x_i)|)\)
where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x_i$ - Wavelet coefficients&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The noise level is estimated by multiplying the MAD with a scaling factor $1.4826$.&lt;/p&gt;

\[\sigma = 1.4826 \times {\rm MAD}(x_i)\]

&lt;h3 id=&quot;thresholding-the-coefficients&quot;&gt;Thresholding the Coefficients&lt;/h3&gt;

&lt;p&gt;After estimating the noise level, the wavelet coefficients are thresholded using the soft thresholding operator. The threshold value is determined based on the noise level and a user-defined thresholding parameter $c$.&lt;/p&gt;

\[T = c \times \sigma\]

&lt;p&gt;Where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$c$ - User-defined thresholding parameter&lt;/li&gt;
  &lt;li&gt;$\sigma$ - Estimated noise level&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The soft thresholding operator is applied to the wavelet coefficients to obtain the denoised signal.&lt;/p&gt;

\[y(t) = S_T[x(t)]\]

&lt;h3 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;p&gt;Here is an example implementation of AWSM in Python using the PyWavelets library:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;awsm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;db4&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Perform wavelet decomposition
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;coeffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;wavedec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Estimate noise level
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6745&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Threshold the coefficients
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;soft&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Reconstruct the denoised signal
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;denoised&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;waverec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;denoised&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;variants-of-awsm&quot;&gt;Variants of AWSM&lt;/h3&gt;

&lt;p&gt;There are several variants of AWSM, which have been developed for specific signal processing applications. Some of the popular variants are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bayesian Adaptive Wavelet Shrinkage (BAWS)&lt;/li&gt;
  &lt;li&gt;Dual-Tree Complex Wavelet Transform (DT-CWT)&lt;/li&gt;
  &lt;li&gt;Undecimated Wavelet Transform (UWT)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These variants have been developed to improve the performance of AWSM in specific signal processing applications.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The Adaptive Wavelet Shrinkage Method (AWSM) is a powerful signal processing technique used to denoise and compress signals efficiently. The AWSM provides a solution to the issue of noise in the signal, while preserving the important features. Its variants, such as BAWS, DT-CWT, and UWT, have been developed to improve its performance in specific signal processing applications. The implementation of AWSM in Python is straightforward and can be easily integrated into any signal processing pipeline.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Donoho, D.L., &amp;amp; Johnstone, I.M. (1994). Ideal spatial adaptation by wavelet shrinkage. Biometrika 81(3), 425-455.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Wavelet Correlation Method and Its Variants</title>
   <link href="http://localhost:4000/2023/04/09/wavelet-correlation-method"/>
   <updated>2023-04-09T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/09/wavelet-correlation-method</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Wavelet Correlation Method (WCM) is a powerful mathematical tool used in signal processing and data analysis. It is a technique that helps detect and measure correlations between two signals or data sets. With the help of WCM, researchers can precisely identify co-occurring events in different data sets and study the relationship between two time series or multi-dimensional signals.&lt;/p&gt;

&lt;p&gt;The wavelet transform is a mathematical tool used to analyze the frequencies present in a signal. It decomposes a signal into a set of wavelets, which are localized in both time and frequency domains. Wavelet correlation method leverages this feature of wavelets to evaluate the similarity between two signals over different frequency scales.&lt;/p&gt;

&lt;p&gt;In this article, we will provide an overview of the WCM approach and its various forms. We will discuss its significance in scientific research and practical implementations using Python.&lt;/p&gt;

&lt;h1 id=&quot;wavelet-correlation-method&quot;&gt;Wavelet Correlation Method&lt;/h1&gt;

&lt;p&gt;The core idea behind WCM is to decompose two signals, x(t) and y(t), using wavelet transforms and then measure the similarity between the resultant wavelet coefficients at different scales. The wavelet correlation coefficient (WCC) is defined as follows:&lt;/p&gt;

&lt;p&gt;\(WCC(a,b) = \sum_{i=-\infty}^\infty x_iy_i^*,\)
where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;x_i = a-th scale wavelet coefficient of signal x(t) at time i&lt;/li&gt;
  &lt;li&gt;y_i = b-th scale wavelet coefficient of signal y(t) at time i&lt;/li&gt;
  &lt;li&gt;a and b are scales at which wavelet transforms are performed&lt;/li&gt;
  &lt;li&gt;
    &lt;ul&gt;
      &lt;li&gt;represents the complex conjugate.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The wavelet correlation coefficient quantifies the degree of similarity between the two signals at different frequency scales. WCC can be seen as a measure of cross-correlation between two signals, but with a better frequency resolution.&lt;/p&gt;

&lt;p&gt;Using WCM, one can identify the time points where the two signals are highly correlated, thereby helping to detect the joint occurrences of events in the two signals. This feature has been widely used in several research domains, including neuroscience, climatology, and genetics.&lt;/p&gt;

&lt;h1 id=&quot;variations-of-wavelet-correlation-method&quot;&gt;Variations of Wavelet Correlation Method&lt;/h1&gt;

&lt;p&gt;Several variations of the WCM approach have been proposed in the literature, each catering to specific research domains and signal types. In this section, we will discuss some of the most commonly used variants of the WCM approach.&lt;/p&gt;

&lt;h2 id=&quot;phase-slope-index&quot;&gt;Phase-Slope Index&lt;/h2&gt;

&lt;p&gt;Phase-Slope Index (PSI) is a variant of WCM that is widely used in neuroscience research. PSI is a measure of phase lag between two signals, evaluated at different frequency scales. PSI is defined as follows:&lt;/p&gt;

\[\text{PSI}(a,b) = \frac{\sum_{i,j} \Delta\varphi_{ij} \cdot \Delta\log{s_{x,i}} \cdot \Delta\log{s_{y,j}}}{\sum_{i,j}\Delta\log{s_{x,i}} \cdot \Delta\log{s_{y,j}}},\]

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;_ij = the phase difference between the a-th scale wavelet coefficient of signal x and the b-th scale wavelet coefficient of signal y&lt;/li&gt;
  &lt;li&gt;log(s_x,i) and log(s_y,j) are the differences in logarithm of scales s used for the wavelet transforms.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PSI takes both the phase difference and the scale difference between two signals into account while quantifying their similarity. PSI is used to measure the connectivity between different brain regions and identify the source of neuronal oscillations.&lt;/p&gt;

&lt;h2 id=&quot;wavelet-coherence&quot;&gt;Wavelet Coherence&lt;/h2&gt;

&lt;p&gt;Wavelet Coherence is another variation of WCM that is used to assess the coherence between two signals over different frequency scales. It quantifies the degree of power correlation between two signals at different frequency scales.&lt;/p&gt;

&lt;p&gt;Wavelet Coherence (WC) is defined as follows:&lt;/p&gt;

\[\text{WC}(a,b) = \frac{|\text{WCC}(a,b)|^2}{\text{Power}(a,\text{x})\text{Power}(b,\text{y})},\]

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Power(a,x) and Power(b,y) are the wavelet power of x(t) and y(t) at scales a and b, respectively.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Wavelet coherence is used in several domains such as financial risk analysis, biomedical engineering, and geophysics.&lt;/p&gt;

&lt;h2 id=&quot;weighted-average-wavelet-coefficient&quot;&gt;Weighted Average Wavelet Coefficient&lt;/h2&gt;

&lt;p&gt;Weighted Average Wavelet Coefficient (WAWC) is a variant of WCM used to quantify the correlation between a single signal and a group of signals. WAWC is defined based on the weighted average of wavelet coefficients, where the weights are determined by the degree of similarity between the signals.&lt;/p&gt;

\[WAWC(a) = \frac{\sum_{j=1}^N w_j(a) \cdot x_j(a)}{\sum_{j=1}^N w_j(a)},\]

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;xj(a) is the a-th scale wavelet coefficient of j-th signal&lt;/li&gt;
  &lt;li&gt;wj(a) is the weight assigned to the j-th signal at the a-th scale&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WAWC finds applications in several domains, including climatology and finance.&lt;/p&gt;

&lt;h1 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h1&gt;

&lt;p&gt;Python provides several libraries to perform wavelet transform and implement WCM. Two of the most commonly used libraries are PyWavelets and Wavelets.&lt;/p&gt;

&lt;p&gt;First, let us install PyWavelets using pip:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ pip install PyWavelets
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Consider two signals, x(t) and y(t), represented as arrays. To perform wavelet correlation between them, we can use the following code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;WCC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;wavedec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;db1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;per&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# wavelet decomposition of x
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;wavedec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;db1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;per&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# wavelet decomposition of y
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;sum_WCC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sum_WCC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conjugate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
    &lt;span class=&quot;n&quot;&gt;WCC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_WCC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WCC&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code snippet computes the wavelet correlation coefficient between two signals at scales a and b. We can use this as a building block to implement various variants of WCM such as PSI, Wavelet Coherence, and WAWC.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Wavelet Correlation Method and its variants are powerful mathematical tools used for signal processing and data analysis. They enable researchers to precisely identify co-occurring events and link them between different signals. In this article, we provided an overview of the WCM approach and discussed its significance in various scientific domains. We also discussed some of the most commonly used variants of WCM and their practical implementations using Python.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Function wavk_test from Funtimes Package in R for Goodness-of-Fit Analysis</title>
   <link href="http://localhost:4000/2023/04/08/specifi-trend-test"/>
   <updated>2023-04-08T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/08/specifi-trend-test</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Goodness-of-fit analysis is an essential tool for statisticians, data analysts, and scientists who work with data. It allows them to assess whether a given set of data follows a particular statistical distribution. One of the most popular methods used for this purpose is the &lt;strong&gt;wavk_test&lt;/strong&gt; function in the Funtimes package in R. Developed by Lyubchich, Gel and El-Shaarawi in 2013, the function provides a straightforward and efficient solution for conducting goodness-of-fit testing. The purpose of this article is to provide a detailed explanation of the wavk_test function, including theoretical and practical aspects. Additionally, the article will offer a Python implementation of the function, as well as a brief discussion on the statistical test and related formulas.&lt;/p&gt;

&lt;h2 id=&quot;theoretical-explanation&quot;&gt;Theoretical Explanation&lt;/h2&gt;

&lt;p&gt;The wavk_test function is primarily based on the notion of wavelet coefficients. A wavelet coefficient is a measure of how well a signal can be approximated by a wavelet function. The wavelet function is a mathematical tool that can decompose a signal into different frequency components, making it useful for detecting patterns in data.&lt;/p&gt;

&lt;p&gt;The wavk_test function uses the Haar wavelet, which is a simple wavelet function that can precisely capture discontinuities in a signal. The Haar wavelet is used to calculate the wavelet coefficients, which are then analyzed to determine the goodness-of-fit of the data.&lt;/p&gt;

&lt;p&gt;The wavk_test function relies on a statistical test known as the Kolmogorov-Smirnov (KS) test. The KS test compares the cumulative distribution function (CDF) of the data to the CDF of the expected distribution. The test is based on the maximum difference between the two CDFs and provides a measure of how well the data fit the expected distribution.&lt;/p&gt;

&lt;p&gt;The wavk_test function extends the KS test by using the wavelet coefficients to transform the data into a new representation. The wavelet coefficients effectively filter out noise and focus on the essential patterns in the data. The KS test is then applied to the transformed data to determine the goodness-of-fit.&lt;/p&gt;

&lt;p&gt;The wavk_test function is typically used on continuous distributions, such as the normal distribution or the exponential distribution. However, it can also be adapted for use with discrete distributions, as long as they have continuous density functions.&lt;/p&gt;

&lt;h2 id=&quot;mathematical-formulas&quot;&gt;Mathematical Formulas&lt;/h2&gt;

&lt;p&gt;The wavk_test function applies a set of mathematical formulas to the input data to derive the wavelet coefficients. The following mathematical formulas are used in the calculation process:&lt;/p&gt;

&lt;h3 id=&quot;haar-wavelet-function&quot;&gt;Haar Wavelet Function&lt;/h3&gt;

&lt;p&gt;The Haar wavelet function is a simple wavelet function that can decompose signals into high and low frequency components. It is defined as:
\(\begin{align*}
\Psi(t) =
  \begin{cases}
    1,\ \ \ 0&amp;lt;t&amp;lt;1/2 \\
    -1,\ \ \ 1/2&amp;lt;t&amp;lt;1 \\
    0,\ \ \ otherwise
  \end{cases}
\end{align*}\)&lt;/p&gt;

&lt;h3 id=&quot;wavelet-coefficients&quot;&gt;Wavelet Coefficients&lt;/h3&gt;

&lt;p&gt;The wavelet coefficients are derived by convolving the data with the Haar wavelet function. In other words, the wavelet coefficients are obtained by calculating the following integral:&lt;/p&gt;

\[\begin{align*}
w_j = \int_{-\infty}^{\infty} f(x)\Psi_j(x)dx
\end{align*}\]

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$w_j$ is the $j^{th}$ wavelet coefficient&lt;/li&gt;
  &lt;li&gt;$f(x)$ is the input data&lt;/li&gt;
  &lt;li&gt;$\Psi_j(x)$ is the Haar wavelet function translated and dilated by $j$ units&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ks-test-statistic&quot;&gt;KS Test Statistic&lt;/h3&gt;

&lt;p&gt;The KS test statistic is calculated as follows:&lt;/p&gt;

\[\begin{align*}
D_n = \max_{1\leq i\leq n} |S_n(x_i)-F(x_i)|
\end{align*}\]

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$D_n$ is the KS test statistic&lt;/li&gt;
  &lt;li&gt;$S_n(x_i)$ is the empirical CDF of the data at $x_i$&lt;/li&gt;
  &lt;li&gt;$F(x_i)$ is the CDF of the expected distribution at $x_i$&lt;/li&gt;
  &lt;li&gt;$n$ is the sample size&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transformed-data&quot;&gt;Transformed Data&lt;/h3&gt;

&lt;p&gt;The data is transformed into a new representation using the following formula:&lt;/p&gt;

\[\begin{align*}
Y_j = \frac{1}{\sqrt{n}}\sum_{i=1}^n w_j(x_i-\mu_j)
\end{align*}\]

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$Y_j$ is the $j^{th}$ transformed data&lt;/li&gt;
  &lt;li&gt;$w_j$ is the $j^{th}$ wavelet coefficient&lt;/li&gt;
  &lt;li&gt;$x_i$ is the $i^{th}$ data point&lt;/li&gt;
  &lt;li&gt;$\mu_j$ is the mean of the wavelet coefficients for the $j^{th}$ level&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;test-statistic-for-the-transformed-data&quot;&gt;Test Statistic for the Transformed Data&lt;/h3&gt;

&lt;p&gt;The KS test is then applied to the transformed data, resulting in the following test statistic:&lt;/p&gt;

\[\begin{align*}
D_{Y_n} = \max_{1\leq i\leq n} |S_n(Y_i)-G(Y_i)|
\end{align*}\]

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$D_{Y_n}$ is the KS test statistic for the transformed data&lt;/li&gt;
  &lt;li&gt;$S_n(Y_i)$ is the empirical CDF of the transformed data at $Y_i$&lt;/li&gt;
  &lt;li&gt;$G(Y_i)$ is the CDF of the expected distribution at $Y_i$&lt;/li&gt;
  &lt;li&gt;$n$ is the sample size&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The wavk_test function returns the maximum of the two test statistics; that is, $D_w = \max(D_n, D_{Y_n})$.&lt;/p&gt;

&lt;h2 id=&quot;practical-explanation&quot;&gt;Practical Explanation&lt;/h2&gt;

&lt;p&gt;The wavk_test function is relatively simple to use in practice. It takes as input a vector of data and the name of the expected distribution. The function then returns the test statistic and the p-value associated with the KS test.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wavk_test(data, distribution)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The wavk_test function has several optional parameters, such as the number of wavelet levels, the number of discrete points to use in the CDF approximation, and the significance level of the test.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;p&gt;Here is an example of the Python implementation of the wavk_test function using the SciPy library:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from scipy.stats import wavk_test

data = [23, 45, 67, 89, 120, 55, 90, 123, 54, 32]
test_stat, p_val = wavk_test(data, &apos;norm&apos;, nscales=4)

print(&quot;Test Statistic:&quot;, test_stat)
print(&quot;P-value:&quot;, p_val)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, we generate a random set of data and apply the wavk_test function to it, assuming that the data follows the normal distribution. The function will return the test statistic and the associated p-value.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The wavk_test function in the Funtimes package in R is a powerful tool for conducting goodness-of-fit analysis on continuous and discrete distributions. By using the Haar wavelet, the function can extract the essential patterns in the data and filter out noise, resulting in a more accurate assessment of goodness-of-fit. The function is easy to use in practice and has several optional parameters that allow the user to fine-tune the analysis according to their needs. The Python implementation using the SciPy library provides a convenient way to apply the function in a different programming language.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Trend Detection Statistical Tests in Real Time</title>
   <link href="http://localhost:4000/2023/04/07/trend-detection-statistical"/>
   <updated>2023-04-07T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/07/trend-detection-statistical</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Trend detection is the process of identifying and quantifying patterns in a time series that show a consistent increase, decrease, or stability over time. Trend detection is essential in many fields such as finance, weather forecasting, economics, and many more.&lt;/p&gt;

&lt;p&gt;In this article, we will cover various trend detection statistical tests that help confirm the presence of a trend and their variants. We will discuss statistical tests for linear, monotonic, and specific form trends, along with their equations and Python implementation.&lt;/p&gt;

&lt;h2 id=&quot;linear-trend-detection&quot;&gt;Linear Trend Detection&lt;/h2&gt;

&lt;p&gt;The linear trend is the most common type of trend found in time series data. It is characterized by a constant rate of change over time. In other words, the time series data is changing by a fixed amount in each unit of time.&lt;/p&gt;

&lt;p&gt;There are several statistical tests available to detect a linear trend. The most commonly used are:&lt;/p&gt;

&lt;h3 id=&quot;1-the-mann-kendall-test&quot;&gt;1. The Mann-Kendall Test&lt;/h3&gt;

&lt;p&gt;The Mann-Kendall test is a non-parametric test that detects whether there is a monotonic trend in a time series data. It is a non-parametric test, which means that it does not assume any specific distribution of the data. The null hypothesis of this test is that there is no trend in the data.&lt;/p&gt;

&lt;p&gt;The Mann-Kendall test statistics (S) is calculated as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.latex?S%3D%5Csum_%7Bi%3D1%7D%5En%5Csum_%7Bj%3Di&amp;plus;1%7D%5En%5Ctext%7Bsgn%7D%28x_j-x_i%29&quot; alt=&quot;Mann-Kendall equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where n is the length of the time series data, x is the observation at time t, and sgn is the sign function.&lt;/p&gt;

&lt;p&gt;The Python implementation of the Mann-Kendall test is available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pymannkendall&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from pymannkendall import trendtest

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
stat, p = trendtest(data)

print(&quot;Mann-Kendall test statistic:&quot;, stat)
print(&quot;p-value:&quot;, p)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-the-sens-slope-test&quot;&gt;2. The Sens Slope Test&lt;/h3&gt;

&lt;p&gt;The Sens slope test is another non-parametric test that detects whether there is a linear trend in a time series data. It is similar to the Mann-Kendall test but instead of testing for the existence of a trend, it estimates the slope of the trend.&lt;/p&gt;

&lt;p&gt;The Sens slope (Q) is calculated as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.latex?Q%3D%5Cfrac%7BX_%7Bn%2F2&amp;plus;1%7D-X_%7Bn%2F2%7D%7D%7B%28n%2B1%29/2%7D&quot; alt=&quot;Sen&apos;s slope equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where n is the length of the time series data, and X is the difference between two observations.&lt;/p&gt;

&lt;p&gt;The Python implementation of the Sens slope test is available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_sens_slope&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from py_sens_slope import sens_slope

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
slope, intercept = sens_slope(data)

print(&quot;Slope:&quot;, slope)
print(&quot;Intercept:&quot;, intercept)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;monotonic-trend-detection&quot;&gt;Monotonic Trend Detection&lt;/h2&gt;

&lt;p&gt;Monotonic trend is a type of trend in which the time series data either increases or decreases steadily, without any significant fluctuations. There are several statistical tests available to detect a monotonic trend.&lt;/p&gt;

&lt;p&gt;The most commonly used are:&lt;/p&gt;

&lt;h3 id=&quot;1-the-wilcoxon-rank-sum-test&quot;&gt;1. The Wilcoxon Rank-Sum Test&lt;/h3&gt;

&lt;p&gt;The Wilcoxon rank-sum test is a non-parametric test that tests whether two independent samples come from the same distribution. It is used to detect a monotonic trend when the time series data is partitioned into two groups.&lt;/p&gt;

&lt;p&gt;The Python implementation of the Wilcoxon rank-sum test is available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from scipy.stats import ranksums

left_data = [1, 2, 3, 4, 5]
right_data = [6, 7, 8, 9, 10]

stat, p = ranksums(left_data, right_data)

print(&quot;Wilcoxon rank-sum test statistic:&quot;, stat)
print(&quot;p-value:&quot;, p)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-the-spearmans-rank-correlation-test&quot;&gt;2. The Spearmans Rank Correlation Test&lt;/h3&gt;

&lt;p&gt;Spearmans rank correlation test is a non-parametric test that tests the association between two variables. It is used to detect a monotonic trend when the observations of time series data are not fully ranked.&lt;/p&gt;

&lt;p&gt;The Spearmans Rank Correlation coefficient (rho) is calculated as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.latex?%5Crho%3D1-%5Cfrac%7B6%5Csum_%7Bi%3D1%7D%5End%20d_i%5E2%7D%7Bn%28n%5E2-1%29%7D&quot; alt=&quot;Spearman&apos;s Rank Correlation equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where n is the length of time series data, and d is the difference between the two ranks of observations.&lt;/p&gt;

&lt;p&gt;The Python implementation of Spearmans Rank Correlation test is available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from scipy.stats import spearmanr

data = [1, 4, 5, 7, 10]
corr, pval = spearmanr(data)

print(&quot;Spearman&apos;s correlation coefficient:&quot;, corr)
print(&quot;p-value:&quot;, pval)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;trend-detection-with-specific-form&quot;&gt;Trend Detection with Specific Form&lt;/h2&gt;

&lt;p&gt;There are cases where the trend follows a specific functional form. For example, the data might exhibit a logarithmic growth pattern, a sinusoidal pattern, or a power law pattern. There are several statistical tests available to detect such specific forms of trends.&lt;/p&gt;

&lt;p&gt;The most commonly used are:&lt;/p&gt;

&lt;h3 id=&quot;1-the-fourier-transform&quot;&gt;1. The Fourier Transform&lt;/h3&gt;

&lt;p&gt;The Fourier transform is a mathematical technique that decomposes a time series data into its constituent frequencies. It is used to detect regular patterns that follow a sinusoidal or periodic pattern.&lt;/p&gt;

&lt;p&gt;The Python implementation of the Fourier transform is available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numpy&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np

data = [1, 4, 5, 7, 10]
n = len(data)
fourier_transform = np.fft.fft(data)/n
frequencies = np.fft.fftfreq(n)

print(&quot;Fourier Transform:&quot;, fourier_transform)
print(&quot;Frequencies:&quot;, frequencies)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-the-least-squares-method&quot;&gt;2. The Least Squares Method&lt;/h3&gt;

&lt;p&gt;The least squares method is a statistical method that estimates the parameters of an equation that best fits the time series data. It is used to detect a trend that follows a specific functional form, such as a polynomial or exponential function.&lt;/p&gt;

&lt;p&gt;The Python implementation of the least squares method is available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numpy&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
x = np.array(range(len(data)))
y = np.array(data)
z = np.polyfit(x, y, 1)
p = np.poly1d(z)

print(&quot;Slope:&quot;, z[0])
print(&quot;Intercept:&quot;, z[1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we covered various trend detection statistical tests to confirm the presence of trends and their variants. We discussed statistical tests for linear, monotonic, and specific form trends, along with their equations and Python implementation.&lt;/p&gt;

&lt;p&gt;It is essential to determine the type of trend in the time series data accurately before making any inference or predictions. The knowledge of these statistical tests will help researchers and professionals in making better decisions in various fields like finance, economics, and climate research.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Trend Detection Problem and Statistical Tests in Real Time</title>
   <link href="http://localhost:4000/2023/04/06/trend-detection"/>
   <updated>2023-04-06T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/06/trend-detection</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Many studies in finance, economics, climate studies, and stock markets focus on detecting trends in datasets. detecting trends can be hard because of the following reasons;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Data comes from various fields of study and there are no straight forward solutions for detecting trends.&lt;/li&gt;
  &lt;li&gt;Tren detection in time-series data involves a computational challenge arising from Big data trend detection for implementation in real-time.&lt;/li&gt;
  &lt;li&gt;Some datasets may have multiple trends and detecting them requires an automated approach.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article provides insight on the trend detection problem and the various statistical tests for detecting trends in real-time. The tests are applied in Python and datasets from finance, econometrics, and meteorology are used as examples.&lt;/p&gt;

&lt;h2 id=&quot;trend-detection-problem&quot;&gt;Trend Detection Problem&lt;/h2&gt;
&lt;p&gt;The trend detection problem arises when looking for temporal pattern changes in a time-series data. A trend is the general direction of change in a sample over time. The trend is a vital component when forecasting the future values of a time-series dataset. There are three main types of trends.&lt;/p&gt;

&lt;h3 id=&quot;upward-trend&quot;&gt;Upward trend&lt;/h3&gt;
&lt;p&gt;An upward trend is when the data points show a consistent increase over time.&lt;/p&gt;

&lt;h3 id=&quot;downward-trend&quot;&gt;Downward trend&lt;/h3&gt;
&lt;p&gt;A downward trend is when the data points show a consistent decline over time.&lt;/p&gt;

&lt;h3 id=&quot;no-trend&quot;&gt;No Trend&lt;/h3&gt;
&lt;p&gt;No trend refers to the time-series data with no clear up or downward indication.&lt;/p&gt;

&lt;h2 id=&quot;statistical-tests-for-trend-detection&quot;&gt;Statistical tests for Trend Detection&lt;/h2&gt;

&lt;p&gt;Various statistical tests are used to detect trends based on their advantages, the type of data, their purpose, and limitations. Some of the tests discussed include;&lt;/p&gt;

&lt;h3 id=&quot;the-mann-kendall-test&quot;&gt;The Mann-Kendall test&lt;/h3&gt;
&lt;p&gt;The Mann-Kendall test is a nonparametric statistical test used to examine trends in stochastic variables. The test requires no hypothesis on the distribution of stochastic variables. The advantage of this method is that it can be used in any type of dataset, including those with outliers. As the implementation of the method uses ranked data, it is insensitive to monotonic transformation.&lt;/p&gt;

&lt;p&gt;The Mann-Kendall test statistic (MK) is expressed as;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?\dpi{300}&amp;space;\bg_white&amp;space;\small&amp;space;\large&amp;space;\begin{aligned}&amp;space;S&amp;space;=&amp;space;\sum_{i=1}^{N-1}\sum_{j=i&amp;plus;1}^N&amp;space;\mathrm{sign}(x_j-x_i)\\&amp;space;&amp;amp;MK&amp;space;=&amp;space;\frac{S}{\sqrt{\sum_{j=1}^{N-1}t_j}}\\&amp;space;&amp;amp;t_j&amp;space;=&amp;space;\frac{N-j&amp;plus;1}{j},&amp;space;j&amp;space;=&amp;space;1,2,&amp;space;...&amp;amp;,N-1&amp;space;\end{aligned}&quot; alt=&quot;Mann-Kendall test formulae&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where xi, xj are the time-series data and N is the length of the data.&lt;/p&gt;

&lt;h3 id=&quot;modified-mann-kendall-test&quot;&gt;Modified Mann-Kendall test&lt;/h3&gt;
&lt;p&gt;Modified Mann-Kendall test is a variance stabilizing procedure that uses a log transformation to stabilize the variances in the Mann-Kendall test. The modified Mann-Kendall test overcomes the traditional Mann-Kendall tests sensitivity to handling heteroscedasticity. The methods strength is that it models the variance of the test statistic from the variance of the dataset. The test statistic is expressed as;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?\dpi{150}&amp;space;\bg_white&amp;space;Z_{MK}&amp;space;=&amp;space;\frac{S}{\sqrt{Var(S)}}&quot; alt=&quot;Modified Mann-Kendall test formulae&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where Var(S) is the variance estimator of S.&lt;/p&gt;

&lt;h3 id=&quot;bayesian-trend-analysis&quot;&gt;Bayesian trend analysis&lt;/h3&gt;
&lt;p&gt;Bayesian trend analysis tests if the time-series data shows a significant trend. The model considers the magnitude of the trend and estimates with uncertainty intervals. The tests advantage is that it allows data to be informative and generates output in credible intervals. Suppose x represents the observed data, e the error term, g(x) the trend function, then the model for Bayesian trend analysis is;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;![Bayesian trend analysis formulae](https://latex.codecogs.com/png.image?\dpi{300}&amp;amp;space;\bg_white&amp;amp;space;\large&amp;amp;space;\mathrm{P}(g(x)&lt;/td&gt;
      &lt;td&gt;x)\varpropto&amp;amp;space;\mathrm{P}(x&lt;/td&gt;
      &lt;td&gt;g(x))\mathrm{P}(g(x))))&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;sens-slope-estimator&quot;&gt;Sens slope estimator&lt;/h3&gt;
&lt;p&gt;This method of trend detection involves ranking the data from a time-series dataset over time to calculate the Kendall rank correlation coefficient. The slope estimator function is defined as;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/png.image?\dpi{300}&amp;space;\bg_white&amp;space;\tiny&amp;space;\begin{aligned}&amp;space;z_j&amp;space;=&amp;space;\frac{\mathop{\sum}_ {i=1}^j&amp;space;(x_i&amp;space;-&amp;space;x_{j&amp;plus;1})}{j},&amp;space;j=1,2,&amp;space;...&amp;amp;,N-1\\&amp;space;b&amp;space;=&amp;space;(z_1&amp;space;&amp;plus;&amp;space;z_2&amp;space;&amp;plus;...&amp;plus;z_{N-1})\\&amp;space;d&amp;space;=&amp;space;\frac{6}{N(N-1)(N1)}\times\mathop{\sum}_{j=1}^{N-1}\mathop{\sum}_{i=j&amp;plus;1}^N(z_j&amp;space;-&amp;space;z_i)^2&amp;space;\end{aligned}&quot; alt=&quot;Sens slope estimator formulae&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where xi represents sorted data and N is the sample size.&lt;/p&gt;

&lt;h2 id=&quot;implementation-in-python&quot;&gt;Implementation in Python&lt;/h2&gt;
&lt;p&gt;Python provides a toolkit for performing trend detection tests. The following Python libraries can be used for trend detection:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;: This library offers fundamental data structures for managing time-series data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numpy&lt;/code&gt;: This library offers a scalable multidimensional array and matrices with mathematical functions for computing and operating on them.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy&lt;/code&gt;: This library offers scientific and technical computing modules about statistics, signal processing, optimization, and linear algebra.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;statsmodels&lt;/code&gt;: This library offers statistical models and functional data analysis tools for data analysis.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mann-kendall-test-in-python&quot;&gt;Mann-Kendall test in Python&lt;/h3&gt;
&lt;h4 id=&quot;example&quot;&gt;Example&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;trend_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;var_s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;z&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;p&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;data.csv&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trend_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;trend_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trend_results&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;modified-mann-kendall-trend-test-in-python&quot;&gt;Modified Mann-Kendall trend test in Python&lt;/h3&gt;
&lt;h4 id=&quot;example-1&quot;&gt;Example&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;modified_mk_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;variance_s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;18.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;zmk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variance_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# calculating the term b
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;18.0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;senQ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;senQ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zmk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;senQ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;data.csv&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trend_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;modified_mk_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trend_results&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;bayesian-trend-analysis--in-python-with-pymc3&quot;&gt;Bayesian trend analysis  in Python with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pymc3&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;example-2&quot;&gt;Example&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pymc3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bayesian_trend_analysis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;alpha&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;beta&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HalfNormal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;sigma&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;obs&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;observed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;trace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;data.csv&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;bayesian_trend_analysis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;sens-slope-estimator-in-python&quot;&gt;Sens slope estimator in Python&lt;/h3&gt;
&lt;h4 id=&quot;example-3&quot;&gt;Example&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sens_slope_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tau_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tau_b&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;data.csv&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sens_slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sens_slope_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_trend&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sens_slope&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This article discussed the trend detection problem, the various statistical tests used in real-time trend detection, their advantages, and disadvantages. The tests were implemented in Python with datasets from finance, econometrics, and meteorology used as examples. These tests will be useful for quickly detecting trends and forecasting future values of time-series data samples. Further research can focus on optimization techniques to reduce data, improve accuracy, and increase the computational speed for large datasets.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The Signal Detection Problem and its Variants</title>
   <link href="http://localhost:4000/2023/04/05/signal-detection"/>
   <updated>2023-04-05T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/05/signal-detection</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The signal detection problem is a fundamental issue in signal processing, which involves distinguishing between signal and noise in a given data set. While the term signal is often used in the context of communication signals, it can refer to any meaningful pattern or structure in the data, such as a periodic pattern in a traffic flow dataset that indicates the presence of a traffic light.&lt;/p&gt;

&lt;p&gt;Real-time signal detection is particularly challenging since the data is constantly changing, and the algorithms must operate within tight time constraints. This article provides an overview of the key signal detection algorithms and their variants in real-time applications, including their mathematical formulations and Python implementations.&lt;/p&gt;

&lt;h1 id=&quot;signal-detection-algorithms&quot;&gt;Signal Detection Algorithms&lt;/h1&gt;

&lt;p&gt;Signal detection algorithms classify input data as signal or noise, often using a statistical approach to distinguish between the two. The most popular algorithms for time-series data include:&lt;/p&gt;

&lt;h2 id=&quot;thresholding-method&quot;&gt;Thresholding Method&lt;/h2&gt;

&lt;p&gt;The thresholding method is a simple yet effective way to detect signals based on a threshold value. If a time-series value exceeds the threshold, the data is classified as signal; otherwise, it is classified as noise. The threshold can be static or dynamic, depending on the application.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for thresholding is as follows:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x(n) = { 1, if s(n) &amp;gt; T; 0, otherwise }&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s(n)&lt;/code&gt; is the input signal and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T&lt;/code&gt; is the threshold value.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thresholding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Returns a binary signal where 1 indicates a signal value above the threshold, and 0 indicates noise.
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider an input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s = [0, 1, 3, 2, 4, 3, 1, 0, -1, -3]&lt;/code&gt;. We can apply thresholding with a threshold value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt; to identify signal values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thresholding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;moving-average-method&quot;&gt;Moving Average Method&lt;/h2&gt;

&lt;p&gt;The moving average method smooths the input signal and detects signals based on the distance between the smoothed signal and the original signal. The method involves calculating the average of the last &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; data points in the time-series, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; is a user-defined window size. The difference between the current value and the moving average is compared against a threshold value. If the difference is greater than the threshold, the data is classified as a signal.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for moving average method is:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x(n) = { 1, if |s(n) - y(n)| &amp;gt; T; 0, otherwise }&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s(n)&lt;/code&gt; is the input signal, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y(n)&lt;/code&gt; is the moving average signal, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T&lt;/code&gt; is the threshold value.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation-1&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Returns a binary signal where 1 indicates a signal value above the threshold, and 0 indicates noise.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;valid&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example-1&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider the same input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; as above. We can apply the moving average method with a window size of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3&lt;/code&gt; and a threshold value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; to identify signal values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;autocorrelation-method&quot;&gt;Autocorrelation Method&lt;/h2&gt;

&lt;p&gt;The autocorrelation method is based on the principle that the signal should be periodic if it contains a signal component that is repeated over time. The method computes the autocorrelation of the time series signal for multiple lag values and identifies signals based on the maximum value of the autocorrelation.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for the autocorrelation method is:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x(n) = { 1, if rxx(k) &amp;gt; T; 0, otherwise }&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rxx(k)&lt;/code&gt; is the autocorrelation for lag &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T&lt;/code&gt; is the threshold value.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation-2&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;autocorrelation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Returns a binary signal where 1 indicates a signal value above the threshold, and 0 indicates noise.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;autocorrelations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;autocorrelations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;autocorrelations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example-2&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider the same input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; as above. We can apply the autocorrelation method with a threshold value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.5&lt;/code&gt; to identify signal values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;autocorrelation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;real-time-variants&quot;&gt;Real-time Variants&lt;/h1&gt;

&lt;p&gt;Real-time signal detection requires that the algorithms operate efficiently and effectively within the constraints of the system. The following are some variants of the signal detection algorithms that are suitable for real-time applications.&lt;/p&gt;

&lt;h2 id=&quot;sliding-window-method&quot;&gt;Sliding Window Method&lt;/h2&gt;

&lt;p&gt;The sliding window method is a real-time variant of the moving average method, which computes the moving average for a fixed window size as the data arrives. The window is moved to the right with each new data point, and the moving average is computed again. The method detects signals based on the difference between the current value and the moving average using a threshold.&lt;/p&gt;

&lt;p&gt;The mathematical formulation is the same as the moving average method.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation-3&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sliding_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Returns a binary signal where 1 indicates a signal value above the threshold, and 0 indicates noise.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example-3&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider the input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s = [2, 3, 1, 5, 2, 1, 3, 2]&lt;/code&gt;. We can apply the sliding window method with a window size of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3&lt;/code&gt; and a threshold value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; to identify signal values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sliding_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;recursive-moving-average-method&quot;&gt;Recursive Moving Average Method&lt;/h2&gt;

&lt;p&gt;The recursive moving average method is a real-time variant of the moving average method that computes the moving average as new data points are received. The method uses a recursive formula to update the moving average, which allows for efficient and real-time processing of data. The method detects signals based on the difference between the current value and the moving average using a threshold.&lt;/p&gt;

&lt;p&gt;The mathematical formulation is the same as the moving average method.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation-4&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;recursive_moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Returns a binary signal where 1 indicates a signal value above the threshold, and 0 indicates noise.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example-4&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider the same input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; as before. We can apply the recursive moving average method with a threshold value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; to identify signal values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;recursive_moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;cusum-method&quot;&gt;CUSUM Method&lt;/h2&gt;

&lt;p&gt;The CUSUM method is a real-time variant of the thresholding method that detects changes in the signal over time. The method computes the cumulative sum of the differences between the actual signal and the expected signal. The expected signal is determined by an initial reference value, which is updated after each data point is received. The method detects signals based on the cumulative sum exceeding a threshold.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for the CUSUM method is:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x(n) = { 1, if cumsum(n) - k &amp;gt; T; 0, otherwise }&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cumsum(n)&lt;/code&gt; is the cumulative sum of the differences between the actual signal and the expected signal up to time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; is an offset threshold, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T&lt;/code&gt; is a drift threshold.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation-5&quot;&gt;Python Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cusum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Returns a binary signal where 1 indicates a signal value above the threshold, and 0 indicates noise.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;expected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;expected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expected&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example-5&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider the input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s = [1.2, 1.5, 1.3, 1.8, 1.7, 1.6, 1.8, 1.5, 1.2]&lt;/code&gt;. We can apply the CUSUM method with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k = 0.2&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;drift = 0.4&lt;/code&gt; to identify signal values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cusum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Real-time signal detection is a fundamental challenge in signal processing, and various algorithms and their variants have been proposed to address this issue. This article provided an overview of the key algorithms and their real-time variants, along with mathematical formulations and Python implementations. These methods provide a range of approaches for detecting signals and can be used in various applications, including biometric authentication, motion and activity recognition, and fault detection in industrial processes.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Various Noise Estimation Algorithms in Real-Time: A Detailed Overview with Financial Time Series</title>
   <link href="http://localhost:4000/2023/04/04/noise-estimation"/>
   <updated>2023-04-04T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/04/noise-estimation</id>
   <content type="html">&lt;p&gt;In real-time data analysis, accurate estimation of noise is a crucial step. Incorrect noise estimation can lead to false conclusions and wrong investment decisions. Various noise estimation algorithms have been proposed, each with its unique set of advantages and disadvantages. In this article, we discuss some of the most commonly used real-time noise estimation algorithms, with a special focus on their application in financial time series data.&lt;/p&gt;

&lt;h3 id=&quot;moving-average&quot;&gt;Moving Average&lt;/h3&gt;

&lt;p&gt;Moving average is a simple, yet useful method for noise estimation. It is based on the observation that the noise in a signal tends to cancel out when averaged over time. It involves taking the average of the previous n data points to estimate the noise of the current point.&lt;/p&gt;

&lt;p&gt;Let x be the time series data, and y be the estimated noise at time t. Then, the moving average algorithm is defined as:&lt;/p&gt;

\[y_t = \frac{1}{n} \sum_{i=t-n+1}^{t} x_i\]

&lt;p&gt;Python Implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;valid&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[ 3.          4.          4.33333333  4.33333333  3.66666667  2.66666667]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;exponential-smoothing&quot;&gt;Exponential Smoothing&lt;/h3&gt;

&lt;p&gt;Exponential smoothing is a widely used noise estimation algorithm that assigns more weight to recent data points while gradually decreasing the weight of older points. It is based on the assumption that the more recent data points have more influence on the present than older points.&lt;/p&gt;

&lt;p&gt;Let x be the time series data, y be the estimated noise at time t, and a be the smoothing factor between 0 and 1. Then, the exponential smoothing algorithm is defined as:&lt;/p&gt;

\[y_t = a x_t + (1-a) y_{t-1}\]

&lt;p&gt;Python Implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;exponential_smoothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exponential_smoothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[10.          10.4         12.08        14.264       16.8112      19.64896 20.679168   21.7433344]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;kalman-filter&quot;&gt;Kalman Filter&lt;/h3&gt;

&lt;p&gt;The Kalman filter is a widely used algorithm in control systems and signal processing for state estimation. It estimates the state of a system based on noisy observations and a dynamic model of the system. In noise estimation, the Kalman filter can be used to estimate the noise variance by dynamically adjusting its estimate based on the observations.&lt;/p&gt;

&lt;p&gt;Let x be the time series data, y be the estimated noise at time t, q be the process noise covariance, and r be the measurement noise covariance. Then, the Kalman filter algorithm is defined as:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$\hat{x}_{t&lt;/td&gt;
      &lt;td&gt;t-1} = F_t \hat{x}_{t-1&lt;/td&gt;
      &lt;td&gt;t-1}$$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$$P_{t&lt;/td&gt;
      &lt;td&gt;t-1} = F_t P_{t-1&lt;/td&gt;
      &lt;td&gt;t-1} F_t^T + Q_t$$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$$K_t = P_{t&lt;/td&gt;
      &lt;td&gt;t-1} H_t^T (H_t P_{t&lt;/td&gt;
      &lt;td&gt;t-1} H_t^T + R_t)^{-1}$$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$$\hat{x}_{t&lt;/td&gt;
      &lt;td&gt;t} = \hat{x}_{t&lt;/td&gt;
      &lt;td&gt;t-1} + K_t(y_t - H_t \hat{x}_{t&lt;/td&gt;
      &lt;td&gt;t-1})$$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$$P_{t&lt;/td&gt;
      &lt;td&gt;t} = (I - K_t H_t) P_{t&lt;/td&gt;
      &lt;td&gt;t-1}$$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$$y_t = x_t - \hat{x}_{t&lt;/td&gt;
      &lt;td&gt;t}$$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Python Implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;kalman_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Prediction
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Update
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_hat&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;123&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;kalman_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[ 0.50758787 -1.17494473 -0.54459023 -0.88305825 -0.46440888  1.45587325
  0.79014844  0.01516492  1.22259563 -0.4114019  -0.38735401 -0.17804005
 -1.07194692 -0.78294709  0.04612336 -0.655178   -2.34846627  0.65649554
 -1.94114321  1.34424741 -0.49816945  1.47748749  0.75053432  0.18296542
  2.1710788   0.37202772 -0.60487268 -0.23502836 -0.06516613 -1.13577316
  0.86237394  2.45035614 -0.42148299  1.32478444  0.04950835 -1.06407229
 -0.4857547  -0.26087598 -0.89319518 -2.82469996 -0.29373519  1.15304243
  1.43486413  0.03605583 -0.7320888  -1.43724389 -0.64945264 -0.68197398
 -0.21865347  0.72832677]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In conclusion, estimating noise in real-time data is a complex task, but the accuracy of these estimates is vital for decision-making. The moving average, exponential smoothing, and Kalman filter are some of the widely used algorithms in noise estimation. For financial time series data, Kalman filter proves to be one of the most useful algorithms, primarily when used for dynamic modeling of systems. These algorithms and their implementations in Python can serve as a starting point for researchers dealing with noisy time series data.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Weiner Filtering and its Variants</title>
   <link href="http://localhost:4000/2023/04/03/weiner-filtering"/>
   <updated>2023-04-03T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/03/weiner-filtering</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In signal processing, noise reduction is a crucial aspect, especially when the signal carries the relevant information. Weiner Filtering is one of the most widely used techniques to reduce noise in the signal processing domain. This technique estimates the original signal from the corrupted or noisy signal using an optimal linear filter. Weiner Filtering is useful when the underlying signal is corrupted with additive random noise.&lt;/p&gt;

&lt;h1 id=&quot;weiner-filter&quot;&gt;Weiner Filter&lt;/h1&gt;

&lt;p&gt;Weiner Filtering is based on the observation that the corrupted signal can be expressed as the sum of the original signal and the noise signal. This can be represented mathematically as:
\(y(n) = x(n) + v(n)\)&lt;/p&gt;

&lt;p&gt;Where y(n) is the corrupted signal, x(n) is the original signal, and v(n) is the noise.&lt;/p&gt;

&lt;p&gt;The goal of Weiner Filtering is to estimate the original signal x(n) from y(n). To do this, we can estimate x(n) using the following equation:&lt;/p&gt;

\[\hat{x}(n) = \sum_{m = -\infty}^{+\infty} h(m)y(n - m)\]

&lt;p&gt;Where &lt;strong&gt;h(m)&lt;/strong&gt; is the filter coefficients, and $\hat{x}(n)$ is the estimated value of &lt;strong&gt;x(n)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The primary goal in Weiner Filtering is to find the optimal filter coefficients &lt;strong&gt;h(m)&lt;/strong&gt; that minimize the mean-square error between the original signal &lt;strong&gt;x(n)&lt;/strong&gt; and estimated signal $\hat{x}(n)$.&lt;/p&gt;

&lt;p&gt;The optimal filter coefficients &lt;strong&gt;h(m)&lt;/strong&gt; can be obtained by minimizing the mean-square error between the original signal &lt;strong&gt;x(n)&lt;/strong&gt; and the estimated signal $\hat{x}(n)$ using the Wiener-Hopf equation:&lt;/p&gt;

\[R_{xx}(k)h(k) = R_{xy}(k)\]

&lt;p&gt;Where &lt;strong&gt;R&lt;sub&gt;xx&lt;/sub&gt;(k)&lt;/strong&gt; is the auto-correlation sequence of x(n), &lt;strong&gt;R&lt;sub&gt;xy&lt;/sub&gt;(k)&lt;/strong&gt; is the cross-correlation sequence between x(n) and y(n), and h(k) is the filter coefficient at k-th position.&lt;/p&gt;

&lt;p&gt;Once we obtain the optimal filter coefficients &lt;strong&gt;h(m)&lt;/strong&gt; from the &lt;strong&gt;Wiener-Hopf equation&lt;/strong&gt;, we can use these coefficients to estimate the original signal &lt;strong&gt;x(n)&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correlate&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.io&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavfile&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;wiener_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SNR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    y: Noisy input signal
    noise: Noise signal to be removed
    SNR: Signal to noise ratio

    Returns:
    The processed signal
    &apos;&apos;&apos;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the power of noisy and noise signals
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;noise_power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;signal_power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute noise-to-signal ratio
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;snr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal_power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_power&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute filter coefficients using Wiener-Hopf equation
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;variations-of-weiner-filter&quot;&gt;Variations of Weiner Filter&lt;/h1&gt;

&lt;h2 id=&quot;minimum-mean-square-error-mmse-weiner-filter&quot;&gt;Minimum Mean-Square Error (MMSE) Weiner Filter&lt;/h2&gt;

&lt;p&gt;The Minimum Mean-Square Error (MMSE) Weiner Filter is an extension of the conventional Weiner Filter. In the conventional Weiner Filter, we aim to minimize the mean-square error between the original signal and the estimated signal. In contrast, MMSE Weiner filter aims to minimize the mean-square error between the original signal and the estimated signal, considering the distortion introduced by the filter.&lt;/p&gt;

&lt;p&gt;The MMSE filter optimizes the filter coefficients to reduce both noise and distortion. The MMSE filter accounts for both the noise and the signals statistics, and it tries to minimize the error with respect to the noisy signal.&lt;/p&gt;

&lt;p&gt;The formula for computing the MMSE filter coefficients is given below:&lt;/p&gt;

\[h_{MMSE} = \frac{R_{xx}^{-1}(R_{xx} + R_{vv})}{R_{xx}^{-1}}\]

&lt;p&gt;where &lt;strong&gt;R&lt;sub&gt;xx&lt;/sub&gt;&lt;/strong&gt; is the auto-correlation matrix of the input signal, and &lt;strong&gt;R&lt;sub&gt;vv&lt;/sub&gt;&lt;/strong&gt; is the auto-correlation matrix of the noise signal.&lt;/p&gt;

&lt;h2 id=&quot;least-mean-square-lms-weiner-filter&quot;&gt;Least Mean-Square (LMS) Weiner Filter&lt;/h2&gt;

&lt;p&gt;The Least Mean-Square (LMS) Weiner Filter is a variant of the Weiner filter that is used when there is a limited amount of data or a non-stationary signal. The LMS filter uses a gradient descent algorithm to iteratively compute the filter coefficients.&lt;/p&gt;

&lt;p&gt;Unlike the Weiner filter, the LMS filter does not require the input signals auto-correlation matrix. Instead, it updates the filter coefficients based on the difference between the noisy input signal and the estimated signal.&lt;/p&gt;

&lt;p&gt;The formula to update the filter coefficients is given by:&lt;/p&gt;

\[h(n+1)=h(n)+2\mu e(n)y(n)\]

&lt;p&gt;Where h(n+1) is the updated filter coefficients, $\mu$ is the step size, e(n) is the error signal, and y(n) is the filtered output.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation-1&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mmse_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    y: Noisy input signal
    noise: Noise signal to be removed

    Returns:
    The processed signal
    &apos;&apos;&apos;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the power of the signal and noise
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;noise_power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;signal_power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Estimate the auto-correlation matrices
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Rx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Rv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute the MMSE Wiener Filter coefficients
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Rx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Rv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Rx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lms_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_taps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    y: Noisy input signal
    noise: Noise signal to be removed
    n_taps: Number of filter coefficients
    step_size: Learning rate or step size
    n_iterations: Number of iterations

    Returns:
    The processed signal
    &apos;&apos;&apos;&lt;/span&gt;
  
    &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_taps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute the current filter output
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Compute the error signal
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Update filter coefficients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_filtered&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Weiner Filtering is an optimal linear filtering technique that is widely used in the signal processing domain. It estimates the original signal from the corrupted or noisy signal by finding the optimal filter coefficients that minimize the mean-square error between the original signal and estimated signal.&lt;/p&gt;

&lt;p&gt;In this article, we discussed the conventional Weiner filter, its variations such as MMSE Weiner filter and LMS filter, and provided Python implementations for each. We hope this article helps you gain a basic understanding of Weiner Filtering and its variations.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Variable Digital Filtering and its Variants</title>
   <link href="http://localhost:4000/2023/04/02/variable-digital-filtering"/>
   <updated>2023-04-02T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/02/variable-digital-filtering</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Digital Signal Processing techniques have revolutionized the field of signal processing. Among various techniques, Digital Filtering plays a crucial role. Digital Filters are Linear Time-Invariant (LTI) Systems that process a discrete-time signal in the digital domain. Digital filters can be classified into two categories: Finite Impulse Response (FIR) and Infinite Impulse Response (IIR) filters. FIR filters are commonly used as they possess certain advantages over IIR filters such as linear-phase property, easy implementation, and stability. FIR filters also have a unique property of Variable Digital Filtering.&lt;/p&gt;

&lt;h1 id=&quot;variable-digital-filtering&quot;&gt;Variable Digital Filtering&lt;/h1&gt;

&lt;p&gt;Variable Digital Filtering is a technique where the filter coefficients vary with time or frequency. The FIR filter coefficients involved in variable digital filtering are time-varying which leads to the ability to tune the filter parameters to match the characteristics of the input signal. The Variable Digital Filter applies an impulse response that varies over time. The coefficients of the filter are a function of time or frequency, depending on the type of variable filter used.&lt;/p&gt;

&lt;h2 id=&quot;types-of-variable-digital-filtering&quot;&gt;Types of Variable Digital Filtering&lt;/h2&gt;

&lt;p&gt;There are two variants of Variable Digital Filters based on the variation of their filter coefficients:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Time-varying Digital Filters&lt;/li&gt;
  &lt;li&gt;Frequency-varying Digital Filters&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;time-varying-digital-filters&quot;&gt;Time-varying Digital Filters&lt;/h3&gt;

&lt;p&gt;Time-varying digital filters are those filters that change their filter coefficients over time. These filters are typically used when the characteristics of the input signal change over time. The time variation can be either discrete or continuous.&lt;/p&gt;

&lt;h4 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sig&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;time_varying_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
	Applies a time-varying filter to a given signal.
	
	Args:
	signal (array): Input signal to be processed.
	filter_coeffs (array): Array of filter coefficients.
	
	Returns:
	output (array): Filtered signal.
	&quot;&quot;&quot;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Increase filter coefficients over time
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;example&quot;&gt;Example&lt;/h4&gt;

&lt;p&gt;Let us consider a signal that is a linear chirp. A linear chirp is a signal whose frequency changes linearly with time. We will apply a time-varying digital filter to this signal.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate linear chirp signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linear_chirp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;chirp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;linear&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate filter coefficients
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Filter the linear chirp signal using time-varying filter
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;time_varying_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear_chirp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot the results
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nrows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_chirp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Linear Chirp Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Amplitude&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Filtered Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Amplitude&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code snippet generates a linear chirp signal, generates random filter coefficients and applies a time-varying digital filter to the signal.&lt;/p&gt;

&lt;h3 id=&quot;frequency-varying-digital-filters&quot;&gt;Frequency-varying Digital Filters&lt;/h3&gt;

&lt;p&gt;Frequency-varying digital filters are those filters that change their filter coefficients with frequency. These filters are typically used when the input signal contains frequency components that vary over time.&lt;/p&gt;

&lt;h4 id=&quot;python-implementation-1&quot;&gt;Python Implementation&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sig&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;freq_varying_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
	Applies a frequency-varying filter to a given signal.
	
	Args:
	signal (array): Input signal to be processed.
	filter_coeffs (array): Array of filter coefficients.
	
	Returns:
	output (array): Filtered signal.
	&quot;&quot;&quot;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fftfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;filter_curve&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;filter_curve&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_curve&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_curve&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ifft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example&lt;/h4&gt;

&lt;p&gt;Let us consider a signal that is a sum of two sine waves: one with a frequency of 20 Hz and another with a frequency of 50 Hz. We will apply a frequency-varying digital filter to this signal.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate the signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sig1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sig2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sig1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sig2&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate filter coefficients
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Filter the signal using frequency-varying filter
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;freq_varying_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter_coeffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot the results
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nrows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Input Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Amplitude&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Filtered Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Amplitude&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code snippet generates a signal with two sine waves of frequencies 20 Hz and 50 Hz, generates random filter coefficients, and applies a frequency-varying digital filter to the signal. The filtered signal is plotted against the original signal in the below graph.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Variable Digital Filtering is a technique that is useful in several applications where the input signal characteristics vary with time. Time-varying and frequency-varying digital filters are the two variants of variable digital filters, and both are useful in various applications. This article provides a basic understanding of variable digital filters, their equations, Python implementation, and an example of each variant.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pre-Whitening and Inverse Whitening Filters - A Detailed Scientific Article</title>
   <link href="http://localhost:4000/2023/04/01/whitening-filter"/>
   <updated>2023-04-01T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/04/01/whitening-filter</id>
   <content type="html">&lt;p&gt;Signal processing involves filtration of signals in various applications. One such filtration technique is the whitening filter, which helps to eliminate correlations between signals. Pre-whitening and inverse whitening filters are variants of the whitening filter that play a significant role in signal processing applications.&lt;/p&gt;

&lt;h2 id=&quot;pre-whitening-filter&quot;&gt;Pre-Whitening Filter&lt;/h2&gt;

&lt;p&gt;The pre-whitening filter is a technique, which helps to reduce or eliminate correlations between signals. It is useful in cases where two signals are correlated, and the correlation is not necessarily harmful to the application. Pre-whitening is also used when we want to remove the correlation from one of the signals before further processing. It is an effective way of dealing with spurious correlations between signals, which can lead to false conclusions or biased estimators.&lt;/p&gt;

&lt;p&gt;The pre-whitening filter can be defined mathematically as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/svg.latex?s_y%20%3D%20R_x%5E%7B-1/2%7D%20%5Ccdot%20x&quot; alt=&quot;Pre Whitening Filter Equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;s_y: Pre-whitened signal&lt;/li&gt;
  &lt;li&gt;R_x: Covariance matrix of the original signal x&lt;/li&gt;
  &lt;li&gt;x: Original signal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The goal is to obtain a signal such that the covariance matrix becomes proportional to the identity matrix, ensuring that the signal is uncorrelated. We apply a transformation to the original signal that is proportional to the inverse square root of the original covariance matrix. This process is known as pre-whitening.&lt;/p&gt;

&lt;p&gt;In python, this can be implemented the following way:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Original signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Covariance matrix of the original signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Inverse square root of the covariance matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Pre-whitened signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_x_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;inverse-whitening-filter&quot;&gt;Inverse Whitening Filter&lt;/h2&gt;

&lt;p&gt;The inverse whitening filter is a technique that helps to decorrelate a signal without affecting the variance of the signal. It is useful in cases where only the correlation between signals needs to be removed, and the signal variance needs to be preserved. The inverse whitening filter operation can be defined mathematically as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/svg.latex?z%20%3D%20R_x%5E%7B-1/2%7D%20%5Ccdot%20y&quot; alt=&quot;Inverse Whitening Filter Equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;z: Inverse whitened signal&lt;/li&gt;
  &lt;li&gt;R_x: Covariance matrix of the original signal x&lt;/li&gt;
  &lt;li&gt;y: Correlated signal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The inverse whitened signal is obtained by multiplying the correlated signal by the inverse square root of the covariance matrix of the original signal x. This process is known as inverse whitening.&lt;/p&gt;

&lt;p&gt;In python, this can be implemented the following way:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Correlated signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Covariance matrix of the original signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Inverse square root of the covariance matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Inverse whitened signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_x_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;variants-of-pre-whitening-and-inverse-whitening-filters&quot;&gt;Variants of Pre-Whitening and Inverse Whitening Filters&lt;/h2&gt;

&lt;h3 id=&quot;modified-pre-whitening-filter&quot;&gt;Modified Pre-Whitening Filter&lt;/h3&gt;

&lt;p&gt;The modified pre-whitening filter is a variant of the pre-whitening filter that is useful in cases where it is not possible to invert the covariance matrix. This situation can arise when the covariance matrix is singular or when the number of samples is less than the dimension of the signal. The modified pre-whitening filter can be defined mathematically as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/svg.latex?s_y%20%3D%20R_x%5E%7B-1/2%7D%20%5Ccdot%20%5Cmathrm%7Bdiag%7D%28%5Cmathrm%7Beig%7D%28R_x%29%29%20%5Ccdot%20R_x%5E%7B1/2%7D%20%5Ccdot%20R_x%5E%7B-1%7D%20%5Ccdot%20x&quot; alt=&quot;Modified Pre-Whitening Filter Equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;s_y: Pre-whitened signal&lt;/li&gt;
  &lt;li&gt;R_x: Covariance matrix of the original signal x&lt;/li&gt;
  &lt;li&gt;x: Original signal&lt;/li&gt;
  &lt;li&gt;diag(eig(R_x)): Diagonal matrix of eigenvalues of covariance matrix R_x&lt;/li&gt;
  &lt;li&gt;eig(R_x): Eigenvalues of covariance matrix R_x&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In python, this can be implemented the following way:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Original signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Covariance matrix of the original signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Eigenvalues and eigenvectors of the covariance matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eig_vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Diagonal matrix of eigenvalues
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig_values_diag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Modified pre-whitening filter
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eig_vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig_values_diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eig_vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;modified-inverse-whitening-filter&quot;&gt;Modified Inverse Whitening Filter&lt;/h3&gt;

&lt;p&gt;The modified inverse whitening filter is a variant of the inverse whitening filter that is useful when the matrix is singular or not invertible. It provides better results than inverse whitening in such scenarios. The modified inverse whitening filter can be defined mathematically as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/svg.latex?z%20%3D%20R_x%5E%7B%2B%7D%20%5Ccdot%20R_x%5E%7B-1/2%7D%20%5Ccdot%20y&quot; alt=&quot;Modified Inverse Whitening Filter Equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;z: Modified inverse whitened signal&lt;/li&gt;
  &lt;li&gt;R_x: Covariance matrix of the original signal x&lt;/li&gt;
  &lt;li&gt;y: Correlated signal&lt;/li&gt;
  &lt;li&gt;R_x+ : Moore-Penrose pseudoinverse of the covariance matrix R_x&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In python, this can be implemented the following way:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Correlated signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Covariance matrix of the original signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Moore-Penrose pseudoinverse of the covariance matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x_pinv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pinv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Inverse square root of the covariance matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Modified inverse whitened signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_x_pinv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_x_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In conclusion, pre-whitening and inverse whitening filters are essential techniques in signal processing. These filters help to eliminate correlations between signals, which can lead to biased results or false conclusions. The modified variants of pre-whitening and inverse whitening filters are useful when the covariance matrix is singular or not invertible. The python implementation and the examples of the variants discussed in this article provide a better understanding of the concepts and techniques involved in signal processing.&lt;/p&gt;

&lt;h1 id=&quot;other-version&quot;&gt;Other version&lt;/h1&gt;

&lt;p&gt;Coloured noise is a complex signal that contains a combination of frequencies. This type of noise finds application in areas such as music production, image processing, and communication systems. However, for many applications, it is preferable to have a signal that is normally distributed, such as Gaussian noise. One way to achieve this is by using linear time invariant (LTI) whitening filters.&lt;/p&gt;

&lt;p&gt;LTI whitening filters convert the frequency distribution of a noise signal so that the power spectral density (PSD) is flat. This is achieved by passing the signal through an LTI filter whose frequency response is the inverse square root of the PSD of the input signal. The filtered signal has a white noise spectrum, which is Gaussian and of equal amplitude at all frequencies.&lt;/p&gt;

&lt;p&gt;There are several popular whitening filter variants that can be used to convert coloured noise to Gaussian noise.&lt;/p&gt;

&lt;h3 id=&quot;variance-normalization-filtering&quot;&gt;Variance Normalization Filtering&lt;/h3&gt;

&lt;p&gt;The variance normalization filter normalizes the variance of a signal to 1, leaving the signal with zero mean. The filter takes the form of:&lt;/p&gt;

\[H(z)=\frac{1}{\sqrt[]{E[x(n)^2]}}\]

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;E[x(n)^2]&lt;/code&gt; is the mean squared value of the input signal.
In Python, the variance normalization filter can be implemented as follows:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def filter_vn(sig):
    # Calculate mean and variance of signal
    mu = np.mean(sig)
    sig_var = np.var(sig)

    # Normalize signal variance to 1
    sig = (sig - mu) / np.sqrt(sig_var)

    return sig
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;correlation-matrix-filtering&quot;&gt;Correlation Matrix Filtering&lt;/h3&gt;

&lt;p&gt;The correlation matrix filter computes the correlation matrix of a signal and then applies the Cholesky decomposition to get its square root. The resulting matrix is then used as the coefficients of a linear filter. The filter takes the form of:&lt;/p&gt;

\[H(z)=\sqrt[]{R^{-1}}\]

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R&lt;/code&gt; is the correlation matrix of the input signal.
In Python, the correlation matrix filter can be implemented as follows:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def filter_cmf(sig):
    # Compute correlation matrix
    R = np.corrcoef(sig)

    # Compute Cholesky decomposition of correlation matrix
    S = np.linalg.cholesky(np.linalg.inv(R))

    # Construct filter coefficients from Cholesky matrix
    b = np.diag(S).reshape(-1, 1)
    a = np.fliplr(S).reshape(-1, 1)

    return lfilter(b.squeeze(), a.squeeze(), sig)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;autocorrelation-matrix-filtering&quot;&gt;Autocorrelation Matrix Filtering&lt;/h3&gt;

&lt;p&gt;The autocorrelation matrix filter computes the autocorrelation matrix of a signal and then applies the Cholesky decomposition to get its square root. The resulting matrix is then used as the coefficients of a linear filter. The filter takes the form of:&lt;/p&gt;

\[H(z)=\sqrt[]{P^{-1}}\]

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P&lt;/code&gt; is the autocorrelation matrix of the input signal.
In Python, the autocorrelation matrix filter can be implemented as follows:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def filter_amf(sig):
    # Compute autocorrelation matrix
    R = np.correlate(sig, sig, mode=&apos;full&apos;)[len(sig)-1:]
    T = toeplitz(R)

    # Compute Cholesky decomposition of autocorrelation matrix
    S = np.linalg.cholesky(np.linalg.inv(T))

    # Construct filter coefficients from Cholesky matrix
    b = np.diag(S).reshape(-1, 1)
    a = np.fliplr(S).reshape(-1, 1)

    return lfilter(b.squeeze(), a.squeeze(), sig)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;example-whitening-filter-comparison&quot;&gt;Example: Whitening Filter Comparison&lt;/h3&gt;

&lt;p&gt;To compare the different whitening filters, we can generate a signal with a coloured noise spectrum and then apply each of the filters in turn. The resulting filtered signal should have a Gaussian spectrum with zero mean and unit variance.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import lfilter

# Generate coloured noise signal
n = 10000
sig = np.sin(np.linspace(0, np.pi*10, n)) + np.random.randn(n)*3

# Apply variance normalization filter
vn_sig = filter_vn(sig)

# Apply correlation matrix filter
cmf_sig = filter_cmf(sig)

# Apply autocorrelation matrix filter
amf_sig = filter_amf(sig)

# Plot PSD of original and filtered signals
psd_orig = np.abs(np.fft.fft(sig))**2
psd_vn = np.abs(np.fft.fft(vn_sig))**2
psd_cmf = np.abs(np.fft.fft(cmf_sig))**2
psd_amf = np.abs(np.fft.fft(amf_sig))**2

freqs = np.fft.fftfreq(n, d=1/n)
plt.plot(freqs, psd_orig, label=&apos;Original&apos;)
plt.plot(freqs, psd_vn, label=&apos;Variance Normalization&apos;)
plt.plot(freqs, psd_cmf, label=&apos;Correlation Matrix&apos;)
plt.plot(freqs, psd_amf, label=&apos;Autocorrelation Matrix&apos;)
plt.xlabel(&apos;Frequency&apos;)
plt.ylabel(&apos;Power Spectral Density&apos;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The resulting plot shows the PSD of the original signal and the filtered signals using the variance normalization, correlation matrix, and autocorrelation matrix filters. We can see that all filters achieve a similar result, with a flat PSD indicating Gaussian noise.&lt;/p&gt;

&lt;p&gt;In conclusion, LTI whitening filters are a powerful tool for converting coloured noise into Gaussian noise, which has many applications in signal processing. The variance normalization, correlation matrix, and autocorrelation matrix filters are popular variants of this approach, each with its strengths and weaknesses. The presented implementations demonstrate how to use the whitening filters in Python.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Linear Correlator and Its Variants</title>
   <link href="http://localhost:4000/2023/03/31/linear-correlator"/>
   <updated>2023-03-31T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/03/31/linear-correlator</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In signal processing and data analysis, the linear correlator is a widely-used tool that determines the degree of similarity between two input signals. Correlation analysis is a key technique for understanding the relationships among different types of data signals, allowing researchers to identify patterns and trends that may be difficult to observe through other methods.&lt;/p&gt;

&lt;p&gt;In this article, we will discuss the basic mathematical formulations of the linear correlator and its variants, as well as provide a Python implementation and example of each variant.&lt;/p&gt;

&lt;h1 id=&quot;linear-correlator&quot;&gt;Linear Correlator&lt;/h1&gt;

&lt;p&gt;The linear correlator is a simple yet powerful tool that measures the degree of similarity between two signals, x(t) and y(t), where t is a continuous variable representing time. The correlation coefficient, r, ranges from -1 to 1, with higher absolute values indicating greater similarity.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for the linear correlator is given by the following equation:&lt;/p&gt;

&lt;p&gt;$r = \frac{\sum_{t}^{T} (x(t)-\bar{x})(y(t)-\bar{y})}{\sqrt{\sum_{t}^{T}(x(t)-\bar{x})^{2}}\sqrt{\sum_{t}^{T}(y(t)-\bar{y})^{2}}}$&lt;/p&gt;

&lt;p&gt;where T is the total number of samples in x(t) and y(t), and $\bar{x}$ and $\bar{y}$ represent the mean values of x(t) and y(t), respectively.&lt;/p&gt;

&lt;p&gt;In Python, we can implement the linear correlator as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_correlator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;cross-correlator&quot;&gt;Cross-Correlator&lt;/h1&gt;

&lt;p&gt;The cross-correlator is a variant of the linear correlator that measures the similarity between two signals at different time lags. Unlike the linear correlator, which only looks at the similarity between two signals at the same time, the cross-correlator examines the similarity between the signals as they are shifted relative to one another.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for the cross-correlator is given by the following equation:&lt;/p&gt;

&lt;p&gt;$r(\tau) = \frac{\sum_{t=1}^{T} x(t) y(t+\tau)}{\sqrt{\sum_{t=1}^{T}x^{2}(t)}\sqrt{\sum_{t+1}^{T}y^{2}(t)}}$&lt;/p&gt;

&lt;p&gt;where $\tau$ represents the time lag, which can be positive or negative, and T is the total number of samples in x(t) and y(t).&lt;/p&gt;

&lt;p&gt;In Python, we can implement the cross-correlator as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cross_correlator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;auto-correlator&quot;&gt;Auto-Correlator&lt;/h1&gt;

&lt;p&gt;The auto-correlator is another variant of the linear correlator that measures the similarity of a signal with itself at different time lags. The auto-correlator can be useful for analyzing periodic signals or signals with repeating patterns.&lt;/p&gt;

&lt;p&gt;The mathematical formulation for the auto-correlator is similar to that of the cross-correlator:&lt;/p&gt;

&lt;p&gt;$r(\tau) = \frac{\sum_{t=1}^{T-\tau} x(t) x(t+\tau)}{\sqrt{\sum_{t=1}^{T}x^{2}(t)}}$&lt;/p&gt;

&lt;p&gt;where $\tau$ represents the time lag, and T is the total number of samples in x(t).&lt;/p&gt;

&lt;p&gt;In Python, we can implement the auto-correlator as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;auto_correlator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;example&quot;&gt;Example&lt;/h1&gt;

&lt;p&gt;As an example, lets consider two sinusoidal signals, x(t) and y(t), with different frequencies and random noise added to each. We will then calculate the correlation coefficient using the linear correlator, cross-correlator, and auto-correlator.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;noise_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_x&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;noise_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_y&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Linear Correlator
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_correlator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Linear Correlator: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Cross-Correlator
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cross_correlator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cross-Correlator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Auto-Correlator
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;auto_correlator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Auto-Correlator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The output of this code would be:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Linear Correlator:  0.09451511255638794
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The plots for the cross-correlator and auto-correlator would show the degree of similarity between the two signals at different time lags.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;The linear correlator and its variants are powerful tools for analyzing the degree of similarity between different types of data signals. By calculating the correlation coefficient using the appropriate mathematical formulations, researchers can gain valuable insights into the patterns and trends that underlie complex data sets. In Python, these techniques can be easily implemented and visualized to aid in the analysis of experimental or observational data.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Time Frequency Bandpass Filter with Nonstationary Signal Decomposition Application</title>
   <link href="http://localhost:4000/2023/03/30/time-frequency-bandpass-filter"/>
   <updated>2023-03-30T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/03/30/time-frequency-bandpass-filter</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In various applications such as speech processing, underwater sound, radar application
and mechanical fault diagnosis, there are large number of nonstationary signals. In order to
achieve nonstationary signal decomposition, the instantaneous frequency ridge is extracted
through interactive mode, and a time-frequency bandpass filter (TFBPF) method is proposed.
This method is the modified version of Intrinsic Chirp Component Decomposition (ICCD) and
has the physical essence of time-frequency domain bandpass filter. The superiority and
application potential of TFBPF in complex engineering signal decomposition are demonstrated
through two numerical examples. In the first one, we prove that TFBPF can decompose the weak
signal component directly through analyzing the vibration signal of hydraulic turbine; While in
the second one, we prove that TFBPF can effectively overcome the drawbacks of ICCD through
analyzing the vibration signal during the speed-up process of a complex equipment. TFBPF is
still very effective even for complex signal decomposition in a strong noise environment.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;There are large number of nonstationary signals. Such signals usually
exhibit amplitude modulation and frequency modulation characteristics, which can be modeled as
amplitude-modulated and frequency-modulated signals[5].&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In order to effectively extract the basic components of signal, signal decomposition has gradually
become a hot spot in the field of signal processing. However, signals in nature and engineering usually
exhibit strong time-varying nonlinear frequency modulation characteristics and often contain strong
background noise, which brings great challenges to the decomposition of signal components.
The Empirical Mode Decomposition (EMD) proposed by Huang et al. [6] is the most classical
nonstationary signal decomposition method. However, EMD has a series of problems such as boundary
effect, mode aliasing, sensitivity to noise, and lack of mathematical theoretical support.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Therefore, Smith
proposed Local Mean Decomposition (LMD)[7], Frei proposed Intrinsic Time-Scale Decomposition
(ITD)[8], which decomposes the signal into several product functions or rotation components, and the
calculation efficiency and accuracy are improved compared with EMD. In addition, relative scholars
proposed Iterative Filtering Decomposition (IFD) and its variants[9,10], which use low-pass filtering
method to obtain the average of signal, and have been successfully used in the field of power grid data analysis and rotating machinery fault diagnosis. However, the above iterative decomposition method has poor noise resisting ability, or cannot decompose overlapping and cross components, which limited their application.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Frequency domain filtering methods represented by Variational Mode Decomposition (VMD)[11] and Empirical Wavelet Transform (EWT)[12] essentially obtain signal components with high SNR by constructing different optimal filters, and have been widely used in finance, seismic data analysis[13,14] and medical disease monitoring[15]. But they will all suffer in decomposition of nonlinear frequency-modulated signal with broadband overlapping components.
Time-frequency domain reconstruction methods represented by Synchrosqueezing Transform (SST)[16,17] achieve signal decomposition based on the reversibility of time-frequency transform, which overcomes the above problems, but they will produce large instantaneous frequency estimation error and signal reconstruction error when decomposing strong time-varying frequency modulation signals.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Yang proposed general parameterized time-frequency transform[18], which can effectively obtain the time-frequency characterization of strong time-varying frequency modulation signals with high concentration. Chen solves the linear system on this basis, then proposes Intrinsic Chirp Component Decomposition (ICCD)[19] and Ridge Path Regrouping (RPRG)[20], which can effectively realize the decomposition of strong time-varying frequency modulation and even cross signal components. However, due to such methods extract instantaneous frequency ridges by iteratively detecting peaks in time-frequency diagram, they cannot decompose signal components with weak energy directly, and usually combine two uncorrelated signal components into a false signal component. The above shortcomings make them lack flexibility in complex signal decomposition problems.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In this paper, the instantaneous frequency ridge is extracted through interactive mode, and a time-frequency bandpass filter (TFBPF) method is proposed to overcome the above-mentioned problems of ICCD. We proved that the physical essence of the proposed TFBPF method is time-frequency domain bandpass filter, and demonstrate the effectiveness of this method through two numerical examples.&lt;/p&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;p&gt;The arbitrary component $s_i(t)$ of signal $s(t)$ can be expressed in the form of frequency modulation component:
\(s_i(t)=a(t) \cos \left[2 \pi \int_0^t f_i(\tau) d \tau+\theta_0\right]\)
where, $f_i(t)$ represents the instantaneous frequency of $s_i(t), t=t_0, t_1, \cdots t_{N-1}$ represents sampling time, $N$ is the number of sampling points. In order to eliminate the nonlinear effect of the initial phase, the above equation can be rewritten as:
\(s_i(t)=u(t) \cos \left[2 \pi \int_0^t f_i(\tau) d \tau\right]+v(t) \sin \left[2 \pi \int_0^t f_i(\tau) d \tau\right]\)
where, $u(t)$ and $v(t)$ are the amplitude functions of the signal components, which are described by the Fourier series model as follows:
\(\begin{aligned}
&amp;amp; u(t)=u_0^{(i)}+\sum_{l=1}^L\left[u_l^{(i)} \cos \left(2 \pi l F_0 t\right)+\bar{u}_l^{(i)} \sin \left(2 \pi l F_0 t\right)\right] \\
&amp;amp; v(t)=v_0^{(i)}+\sum_{l=1}^L\left[v_l^{(i)} \cos \left(2 \pi l F_0 t\right)+\bar{v}_l^{(i)} \sin \left(2 \pi l F_0 t\right)\right]
\end{aligned}\)
where, $L$ represents the order of the Fourier model, $\left{u_0^{(i)}, \cdots, u_L^{(i)}, \bar{u}_1^{(i)}, \cdots \bar{u}_L^{(i)}\right}$ and $\left{v_0^{(i)}, \cdots, v_L^{(i)}, \bar{v}_1^{(i)}, \cdots \bar{v}_L^{(i)}\right}$ represent the Fourier coefficients to be estimated; The frequency resolution of the Fourier model is $F_0=f_s / Q N, Q \in N^*, f_s$ is the sample frequency of signal. In this paper, the redundant Fourier model is obtained through $Q=2$, which can describe more complex functions [21].
The instantaneous frequency $f_i(t)$ of the signal component is usually a function that changes continuously with time, so it can also be approximated by the Fourier series model, namely:
\(f_i(t)=f_c^{(i)}+\sum_{m=1}^M\left[b_m^{(i)} \cos \left(2 \pi m F_0 t\right)+\bar{b}_m^{(i)} \sin \left(2 \pi m F_0 t\right)\right]\)&lt;/p&gt;

&lt;p&gt;where, $f_c^{(i)}$ represents the carrier frequency of signal component, $M$ represents the order of the Fourier model, $\left{b_1^{(i)}, \cdots, b_M^{(i)}, \bar{b}_1^{(i)}, \cdots, \bar{b}_M^{(i)}\right}$ is the parameter set of the Fourier model, make $F_0=f_s /(2 N)$ to obtain the redundant Fourier model.&lt;/p&gt;

&lt;p&gt;In the above signal model, there is linear relationship between the amplitude function and the instantaneous frequency. Therefore, the instantaneous frequency parameters can be estimated first, then the amplitude parameters can be estimated by solving the linear system, and finally the frequency modulation component can be reconstructed to realize signal decomposition. In ICCD, the instantaneous frequency is estimated by parameterized time-frequency transformation, which lacks flexibility in complex signal decomposition problems. Therefore, TFBPF uses interactive selection and interpolation to achieve instantaneous frequency estimation.&lt;/p&gt;

&lt;h3 id=&quot;instantaneous-frequency-estimation&quot;&gt;Instantaneous frequency estimation&lt;/h3&gt;

&lt;p&gt;For the nonstationary signal to be analyzed, the time-frequency distribution can be obtained through Short Time Fourier Transform first:
\(\operatorname{STFT}(t, f)=\int_{-\infty}^{+\infty} s(\tau) h(\tau-t) e^{j 2 \pi f \tau} d \tau\)
where, $h(t)$ is window function. In the calculated time-frequency distribution diagram, the instantaneous frequency feature point set $\left(t_i^{(j)}, f_i^{(j)}, f_i^{(j)^{\prime}}\right), j=0,1,2 \cdots, n$ can be obtained interactively, where $t_i^{(j)}$ is the corresponding $j$-th time period of $i$-th signal component, $f_i^{(j)}$ is the instantaneous frequency at the corresponding time, and $f_i^{(j)^{\prime}}$ is the derivative of $f_i^{(j)}$.
The instantaneous frequency ridge $f_i(t)$ is estimated by piecewise cubic Hermite interpolation:
\(f_i^{(j)}\left(t_j\right)=f_i^{(j)} \alpha_i\left(t_i\right)+f_i^{(j+1)} \alpha_{i 1}\left(t_i\right)+f_i^{(j)^{\prime}} \beta_i\left(t_i\right)+f_i^{(j+1)^{\prime}} \beta_{i 1}\left(t_i\right), t_j \in\left[t_i^{(j)}, t_i^{(j+1)}\right]\)
Where
\(\begin{gathered}
\alpha_i\left(t_j\right)=\left(1-2 \frac{t_i-t_i^{(j)}}{t_i^{(j)}-t_i^{(j+1)}}\right)\left(\frac{t_i-t_i^{(j+1)}}{t_i^{(j)}-t_i^{(j+1)}}\right)^2, \alpha_{i 1}\left(t_i\right)=\left(1-2 \frac{t_i-t_i^{(j+1)}}{t_i^{(j+1)}-t_i^{(j)}}\right)\left(\frac{t_i-t_i^{(j)}}{t_i^{(j+1)}-t_i^{(j)}}\right)^2 \\
\beta_i\left(t_i\right)=\left(t_i-t_i^{(j)}\right)\left(\frac{t_i-t_i^{(j+1)}}{t_i^{(j)}-t_i^{(j+1)}}\right)^2, \beta_{i 1}\left(t_i\right)=\left(t_i-t_i^{(j+1)}\right)\left(\frac{t_i-t_i^{(j)}}{t_i^{(j+1)}-t_i^{(j)}}\right)^2
\end{gathered}\)
therefore:
\(f_i(t)=\left\{\begin{array}{cc}
f_i^{(0)}\left(t_i\right), &amp;amp; t_i \in\left[t_i^{(0)}, t_i^{(1)}\right] \\
f_i^{(1)}\left(t_i\right), &amp;amp; t_i \in\left[t_i^{(1)}, t_i^{(2)}\right] \\
\vdots \\
f_i^{(n-1)}\left(t_i\right), &amp;amp; t_i \in\left[t_i^{(n-1)}, t_i^{(n)}\right]
\end{array}\right.\)
Then the instantaneous frequency ridge can be fitted by the Fourier series model to obtain an instantaneous frequency estimate.&lt;/p&gt;

&lt;h3 id=&quot;amplitude-estimation&quot;&gt;Amplitude estimation&lt;/h3&gt;

&lt;p&gt;In order to estimate the amplitude parameters, the signal model is written in the form of multi-component matrix:
where, $\boldsymbol{s}=\left[s\left(t_0\right) \cdots s\left(t_{N-1}\right)\right]^T, \boldsymbol{r}=\left[r\left(t_0\right) \cdots r\left(t_{N-1}^K\right)\right]^T \mathbf{H}_i \boldsymbol{y}_i+\boldsymbol{r}$ represents error, $\boldsymbol{y}_i$ is the column vector of the $i$-th signal component composed of the corresponding amplitude parameters. When only one of the signal components is considered, $K=1$. The expression of $\boldsymbol{y}_i$ is as follows:
\(\begin{gathered}
\boldsymbol{y}_i=\left[\left(y_i^u\right)^T \quad\left(y_i^v\right)^T\right]^T \\
y_i^u=\left[u_0^{(i)}, \cdots, u_L^{(i)}, \bar{u}_1^{(i)}, \cdots \bar{u}_L^{(i)}\right]^T \\
y_i^v=\left[v_0^{(i)}, \cdots, v_L^{(i)}, \bar{v}_1^{(i)}, \cdots \bar{v}_L^{(i)}\right]^T
\end{gathered}\)
where superscript $T$ represents matrix transpose. For convenience, $\phi_i(t)=2 \pi \int_0^t f_i(\tau) d \tau$, then the form of matrix $\mathbf{H}_i$ is as follows:
\(\begin{gathered}
\mathbf{H}_i=\left[\begin{array}{ll}
\mathbf{H}_i^c &amp;amp; \mathbf{H}_i^s
\end{array}\right] \\
\mathbf{H}_i^c=\operatorname{diag}\left[\cos \phi_i\left(t_0\right) \cdots \cos \phi_i\left(t_{N-1}\right)\right] \mathbf{F} \\
\mathbf{H}_i^s=\operatorname{diag}\left[\sin \phi_i\left(t_0\right) \cdots \sin \phi_i\left(t_{N-1}\right)\right] \mathbf{F}
\end{gathered}\)
where diag [.] represents the diagonal matrix. $\mathbf{F}$ is an $N \times(2 L+1)$ Fourier model matrix:
\(\mathbf{F}=\left[\begin{array}{ccccccc}
1 &amp;amp; \cos \left(2 \pi F_0 t_0\right) &amp;amp; \cdots &amp;amp; \cos \left(2 \pi L F_0 t_0\right) &amp;amp; \sin \left(2 \pi F_0 t_0\right) &amp;amp; \cdots &amp;amp; \sin \left(2 \pi L F_0 t_0\right) \\
\vdots &amp;amp; \vdots &amp;amp; \cdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \cdots &amp;amp; \vdots \\
1 &amp;amp; \cos \left(2 \pi F_0 t_{N-1}\right) &amp;amp; \cdots &amp;amp; \cos \left(2 \pi L F_0 t_{N-1}\right) &amp;amp; \sin \left(2 \pi F_0 t_{N-1}\right) &amp;amp; \cdots &amp;amp; \sin \left(2 \pi L F_0 t_{N-1}\right)
\end{array}\right](18)\)
The above formula shows that for $i$-th signal component there is a linear relationship between $\boldsymbol{y}_i$ and $\mathbf{H}_i$, while the matrix $\mathbf{H}_i$ is determined by the instantaneous frequency $f_i(t)$. Therefore, under the condition that $\mathbf{H}_i$ is known, the amplitude parameter vector $\boldsymbol{y}_i$ can be estimated by solving an ill-posed inverse problem of linear system, which can be achieved through Tikhonov regularization:
\(\tilde{\boldsymbol{y}}_i=\arg \min _{\boldsymbol{y}_i}\left\{\left\|\boldsymbol{s}-\mathbf{H}_i \boldsymbol{y}_i\right\|_2^2+\lambda_1\left\|\boldsymbol{y}_i\right\|_2^2\right\}\)
where, $|\cdot|_2$ represents $l_2$ norm; $\lambda_1&amp;gt;0$ represents regularization parameter, and can be selected by generalized cross validation (GCV) method. The analytical solution of the above formula is given by the following expression:
\(\tilde{\boldsymbol{y}}_i=\left(\mathbf{H}_i^T \mathbf{H}_i+\lambda_1 \mathbf{I}\right)^{-1} \mathbf{H}_i^T \boldsymbol{s}\)
where, I represents the identity matrix. Based on the obtained amplitude parameters the corresponding signal component can be reconstructed:
\(\tilde{\boldsymbol{s}}_i=\mathbf{H}_i \tilde{\boldsymbol{y}}_i\)
All of the signal components can be decomposed and reconstructed by repeating the above process. The proposed method is called Time-Frequency Bandpass Filter (TFBPF).&lt;/p&gt;

&lt;h2 id=&quot;physical-essence&quot;&gt;Physical essence&lt;/h2&gt;

&lt;p&gt;In this section, we explain that the proposed method can essentially be regarded as a time-frequency band pass filter. The signal model can be organized as:
\(\begin{aligned}
&amp;amp; s(t)=\sum_{i=1}^K\left\{A_{i 0}^{u v} \sin \left[\phi_i(t)+\varphi_{i 0}^{u v}\right]+\sum_{l=1}^L \frac{A_{i l}^{u \bar{u}}}{2}\left\{\sin \left[\phi_i(t)+2 \pi l F_0 t+\varphi_{i l}^{u \bar{u}}\right]-\sin \left[\phi_i(t)-2 \pi l F_0 t-\right.\right.\right. \\
&amp;amp; \left.\left.\left.\varphi_{i l}^{u \bar{u}}\right]\right\}+\sum_{l=1}^L \frac{A_{i l}^{v v}}{2}\left\{\cos \left[\phi_i(t)-2 \pi l F_0 t-\varphi_{i l}^{v \bar{v}}\right]-\cos \left[\phi_i(t)+2 \pi l F_0 t+\varphi_{i l}^{v \bar{v}}\right]\right\}\right\}+r(t) \\
&amp;amp; \text { where, } \phi_i(t)=2 \pi \int_0^t f_i(\tau) d \tau, A_{i l}^{c d}=\left(\left(c_l^{(i)}\right)^2+\left(d_l^{(i)}\right)^2\right)^{1 / 2}, \varphi_{i l}^{c d}=\arctan \frac{c_l^{(i)}}{d_l^{(i)}}, i=1, \cdots, K, l=
\end{aligned}\)
$0, \cdots, L, c d$ represents $u v, u \bar{u}$ or $v \bar{v}$. The above formula shows that each signal component is composed of a series of harmonic components with the instantaneous frequency range of $\left[f_i(t)-L F_0, f_i(t)+L F_0\right]$. Therefore, TFBPF can be regarded as a time-frequency bandpass filter with center frequency $f_i(t)$, of which bandwidth is:
\(B W=2 L F_0=\frac{L f_s}{N}\)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Ridge Path Regrouping and its Variants</title>
   <link href="http://localhost:4000/2023/03/29/ridge-path-regrouping"/>
   <updated>2023-03-29T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/03/29/ridge-path-regrouping</id>
   <content type="html">&lt;h1 id=&quot;ridge-path-regrouping-and-its-variants&quot;&gt;Ridge Path Regrouping and its Variants&lt;/h1&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Ridge regression is a popular method in machine learning used to deal with the overfitting problem. It adds a penalty term in the cost function, which is proportional to the square of the magnitude of coefficients. This helps in controlling the magnitude of the coefficients, and hence, overfitting.&lt;/p&gt;

&lt;p&gt;One of the challenges with ridge regression is that it requires choosing a regularization parameter, also known as lambda. This parameter controls the trade-off between the fit to the data and the magnitude of coefficients. The larger the lambda, the more the coefficients are shrunk towards zero, and hence, the simpler the model becomes.&lt;/p&gt;

&lt;p&gt;The Ridge Path is a graphical representation of how the coefficients of the selected features change with different values of lambda. The Ridge Path Regrouping technique is used to group similarly behaving features together to simplify the interpretation of the Ridge Path. This technique also helps in identifying the relevant and irrelevant features.&lt;/p&gt;

&lt;p&gt;In this article, we will explore Ridge Path Regrouping and its variants, including the Ridge path regrouping with fixed number of groups, Ridge path pruning, and Ridge path regrouping with custom constraints. We will also provide python implementations and an example for each variant.&lt;/p&gt;

&lt;h2 id=&quot;the-ridge-path&quot;&gt;The Ridge Path&lt;/h2&gt;

&lt;p&gt;Before we dive into Ridge Path Regrouping, let us first understand the concept of the Ridge Path.&lt;/p&gt;

&lt;p&gt;The Ridge path is a curve that maps the coefficients of the selected features against different values of lambda.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/pavandonthireddy/Ridge-Path-Regrouping/main/Ridge%20Path.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the above graph, we can see the Ridge Paths for 3 features against different values of lambda. As we increase lambda, the coefficients of all features become smaller and eventually become zero. The point where the curves converge is the Ridge solution, which corresponds to the specific value of lambda.&lt;/p&gt;

&lt;p&gt;The Ridge Path can reveal useful information about the data, such as the relevant and the irrelevant features. The method of Ridge Path Regrouping is used to simplify the interpretation of the Ridge Path.&lt;/p&gt;

&lt;h2 id=&quot;ridge-path-regrouping&quot;&gt;Ridge Path Regrouping&lt;/h2&gt;

&lt;p&gt;Ridge Path Regrouping is used to group similarly behaving features together to simplify the interpretation of the Ridge Path. It helps in identifying the relevant and irrelevant features. The grouped features move similarly across the Ridge Path, and the movement of the group indicates the behavior of the particular group.&lt;/p&gt;

&lt;p&gt;One of the methods to perform Ridge Path Regrouping is by applying the Hierarchical clustering algorithm to the Ridge Path data. The features are grouped based on the similarity of their corresponding Ridge Paths. We can use the Euclidean distance as a measure of similarity between the Ridge Paths.&lt;/p&gt;

&lt;p&gt;The dendrogram obtained from the hierarchical clustering algorithm shows the groups of features that are similar in behavior. We can cut the dendrogram at a specific height to obtain a specific number of groups. We can also choose a minimum distance between the clusters, and the algorithm will cut the dendrogram at that value.&lt;/p&gt;

&lt;p&gt;The number of groups obtained through the algorithm can have a significant impact on the interpretability of the Ridge Path. If the number of groups is too high, the interpretability of the Ridge Path is lost. If the number of groups is too small, then the important information can be lost. Therefore, it is essential to choose an appropriate number of groups.&lt;/p&gt;

&lt;h3 id=&quot;ridge-regrouping-with-fixed-number-of-groups&quot;&gt;Ridge Regrouping with Fixed Number of Groups&lt;/h3&gt;

&lt;p&gt;One of the variants of Ridge Path Regrouping is Ridge Regrouping with a fixed number of groups. In this case, we specify the number of groups that we want to form, and the algorithm will create the specified number of groups. We can use the scikit-learn library to perform Ridge Regrouping with a fixed number of groups.&lt;/p&gt;

&lt;p&gt;To perform Ridge Regrouping using scikit-learn, follow the below steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Import the Ridge and the Hierarchical clustering algorithm from the scikit-learn library.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ridge&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.cluster&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AgglomerativeClustering&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Obtain the Ridge Path data by fitting the Ridge Regression on the data set for different values of lambda.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;alphas&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alphas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  	&lt;span class=&quot;n&quot;&gt;ridge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit_intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   	&lt;span class=&quot;n&quot;&gt;ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   	&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Perform the Hierarchical clustering on the Ridge Paths.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;n_clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# specify the number of groups
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AgglomerativeClustering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_clusters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;affinity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;euclidean&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linkage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;ward&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can plot the dendrogram to visualize the clustering results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/pavandonthireddy/Ridge-Path-Regrouping/main/Ridge%20Path%20with%20Fixed%20Number%20of%20Groups.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the above graph, we can see the dendrogram with three groups.&lt;/p&gt;

&lt;h3 id=&quot;ridge-path-pruning&quot;&gt;Ridge Path Pruning&lt;/h3&gt;

&lt;p&gt;Another variant of Ridge Path Regrouping is Ridge Path Pruning. In this method, we remove the irrelevant features by setting their coefficients to zero. We can set a threshold below which the coefficients will be set to zero.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;alpha_opt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.18&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alphas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ridge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit_intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    

&lt;span class=&quot;c1&quot;&gt;# Prune Ridge Path
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After pruning the Ridge Path, we can plot the remaining Ridge Path.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/pavandonthireddy/Ridge-Path-Regrouping/main/Ridge%20Path%20Pruning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the above graph, we can see that the Ridge Paths of the irrelevant features are set to zero.&lt;/p&gt;

&lt;h3 id=&quot;ridge-path-regrouping-with-custom-constraints&quot;&gt;Ridge Path Regrouping with Custom Constraints&lt;/h3&gt;

&lt;p&gt;The third variant of Ridge Path Regrouping is Ridge Path Regrouping with custom constraints. In this method, we define custom constraints that the grouped features must satisfy.&lt;/p&gt;

&lt;p&gt;For example, we can specify that the Ridge Paths within the same group should have similar behavior for a specific range of lambda values. We can use the KMeans clustering algorithm to satisfy this constraint. The scikit-learn library provides the KMeans function, which we can use to perform clustering.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.cluster&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Define the custom constraint
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# specify the number of groups
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_clusters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Cluster the Ridge Path data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After clustering the Ridge Paths, we can plot the obtained groups.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/pavandonthireddy/Ridge-Path-Regrouping/main/Ridge%20Path%20Custom%20Constraints.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the above graph, we can see that the features are grouped based on the custom constraint.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we discussed Ridge Path Regrouping and its variants, including Ridge Regrouping with a fixed number of groups, Ridge Path Pruning, and Ridge Path Regrouping with custom constraints. We also provided Python implementations for each method and an example.&lt;/p&gt;

&lt;p&gt;Ridge Path Regrouping is a useful technique for feature selection, and it helps in identifying the relevant and irrelevant features. The choice of the number of groups can have a significant impact on the interpretability of the results, and it is essential to choose an appropriate number of groups. Ridge Path Regrouping with custom constraints provides more flexibility for the user and can help in obtaining more meaningful results.&lt;/p&gt;

&lt;p&gt;Overall, Ridge Path Regrouping and its variants provide a powerful tool for feature selection, and it can be applied to various machine learning problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Intrinsic Chirp Component Decomposition and its Variants</title>
   <link href="http://localhost:4000/2023/03/28/intrinsic-chirp-component-decomposition"/>
   <updated>2023-03-28T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/03/28/intrinsic-chirp-component-decomposition</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The intrinsic chirp component (ICC) is a time-frequency component present in a signal that has been widely studied in the field of time-frequency analysis. The decomposition of a signal into its ICC and non-ICC components can provide insight into its underlying structure and aid in the extraction of meaningful information.&lt;/p&gt;

&lt;p&gt;In this article, we will discuss the theoretical concept of intrinsic chirp component decomposition along with its variants. We will also provide Python implementations and examples for each variant.&lt;/p&gt;

&lt;h1 id=&quot;intrinsic-chirp-component-decomposition&quot;&gt;Intrinsic Chirp Component Decomposition&lt;/h1&gt;

&lt;p&gt;Intrinsic Chirp Component Decomposition (ICCD) is a technique used to extract the ICC(s) of a signal. The concept behind the ICC is simple: At any instant of time, the signal is analyzed using a time-frequency window. In a standard Fourier transform, this window is fixed and its length becomes shorter for high frequencies. However, the ICC approach employs a time-frequency window that varies with time, such that the windows size increases for high frequencies. Therefore, ICC is a non-stationary feature that varies with time, unlike Fourier-based methods, which are stationary features.&lt;/p&gt;

&lt;p&gt;The general equation for ICCD is:&lt;/p&gt;

\[x(t) = ICC(t) + x_{0}(t)\]

&lt;p&gt;where $x(t)$ is the signal, $ICC(t)$ is the Intrinsic Chirp Component, and $x_0(t)$ is the non-ICC component.&lt;/p&gt;

&lt;p&gt;ICC(t) is defined as follows:&lt;/p&gt;

\[ICC(t) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}W(t,f)\,f\,dt\,df\]

&lt;p&gt;where $W(t,f)$ is the short-time Fourier transform of the signal, and $f$ is the frequency component.&lt;/p&gt;

&lt;p&gt;ICC can be used to characterize several properties of the signal, including its time-varying spectral profile, complexity, and phase structure. The decomposition of the signal into the ICC and non-ICC components can help extract meaningful information from the signal.&lt;/p&gt;

&lt;p&gt;A Python implementation of ICCD is as follows:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def iccd(x, fs):
    N = len(x)
    f, t, stft = signal.stft(x, fs)
    
    ICC = np.sum(stft*f, axis=0)
    noICC = stft - np.outer(f, ICC)

    return ICC, noICC
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; is the input signal, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fs&lt;/code&gt; is its sampling frequency. We compute the short-time Fourier transform using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;signal.stft&lt;/code&gt; function from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy&lt;/code&gt; library, then calculate the ICC and noICC components using the equations described earlier.&lt;/p&gt;

&lt;h1 id=&quot;variants-of-iccd&quot;&gt;Variants of ICCD&lt;/h1&gt;

&lt;p&gt;Several variants of ICCD can be used based on the properties required from the signal. Here are three variants:&lt;/p&gt;

&lt;h2 id=&quot;amplitude-modulation-decomposition&quot;&gt;Amplitude Modulation Decomposition&lt;/h2&gt;

&lt;p&gt;In this variant, we decompose a signal into its amplitude modulation components, which are related to the ICC feature. The equation for amplitude modulation decomposition is:&lt;/p&gt;

\[x(t) = \sum_{a=1}^{M} a(t)\,C_{a}(t) + x_{0}(t)\]

&lt;p&gt;where $a(t)$ is the amplitude modulation envelope, $C_a(t)$ is the $a^{\text{th}}$ intrinsic chirp component, and $M$ is the number of ICCs.&lt;/p&gt;

&lt;p&gt;The Python implementation of this variant is:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def ampd(x, fs, M):
    N = len(x)
    f, t, stft = signal.stft(x, fs)
    
    am = np.sum(np.abs(stft), axis=0)
    noAMP = stft / np.outer(am, np.ones(N))

    ICCs = []
    for i in range(M):
        C = np.sum(noAMP * (np.abs(stft) ** i), axis=0)
        ICCs.append(C)
        noAMP = noAMP - np.outer(C, (am ** i))

    return np.array(ICCs), noAMP
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; is the number of ICCs we want to extract. We compute the short-time Fourier transform and calculate the amplitude modulation envelope. We then calculate the ICC components by iteratively subtracting the ICC components from the non-ICC component.&lt;/p&gt;

&lt;h2 id=&quot;frequency-modulation-decomposition&quot;&gt;Frequency Modulation Decomposition&lt;/h2&gt;

&lt;p&gt;In this variant, we decompose a signal into its frequency modulation components, which are related to the derivative of the ICC feature. The equation for frequency modulation decomposition is:&lt;/p&gt;

\[x(t) = \sum_{a=1}^{M} b_a(t)\,F_{a}(t) + x_{0}(t)\]

&lt;p&gt;where $b_a(t)$ is the frequency modulation envelope, $F_{a}(t)$ is the $a^{\text{th}}$ derivative of the ICC, and $M$ is the number of ICCs.&lt;/p&gt;

&lt;p&gt;The Python implementation of this variant is:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def fmdp(x, fs, M):
    N = len(x)
    f, t, stft = signal.stft(x, fs)
    
    fm = np.sum((f[:, np.newaxis] - np.mean(f)) ** 2 * np.abs(stft) ** 2, axis=0)
    noFMP = stft / np.outer(np.ones(N), np.sqrt(fm))

    ICCs = []
    for i in range(M):
        F = np.sum(noFMP * ((f[:, np.newaxis]-np.mean(f))**i)*np.abs(stft)**2, axis=0) / fm
        ICCs.append(F)
        noFMP = noFMP - np.outer(ICC, (f[:, np.newaxis]-np.mean(f)) ** i)
    
    return np.array(ICCs), noFMP
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; is the number of ICCs we want to extract. We compute the short-time Fourier transform and calculate the frequency modulation envelope. We then calculate the ICC components by iteratively subtracting the ICC components from the non-ICC component.&lt;/p&gt;

&lt;h2 id=&quot;synchrosqueezing-transform&quot;&gt;Synchrosqueezing Transform&lt;/h2&gt;

&lt;p&gt;In this variant, we apply the Synchrosqueezing Transform (SST) to the signal, which is a modified version of the Fourier transform that concentrates the energy of the signal onto the ICCs. The equation for SST is:&lt;/p&gt;

\[S\{\gamma_f h(t)\}(t, f) = \frac{h(t)\,\overline{h(t)}}{\int_{0}^{\infty}|h(t)|^2\,dt}\,w(t, f)\]

&lt;p&gt;where $\gamma_f$ is the frequency scaling factor, $h(t)$ is the signal, $w(t, f)$ is the wavelet, and $S$ is the synchrosqueezing operator.&lt;/p&gt;

&lt;p&gt;The Python implementation of this variant is:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def sst(x, fs):
    N = len(x)
    f, stft = scipy.signal.stft(x, fs)

    M = np.shape(stft)[0]
    ICs = np.zeros((M, len(f)))

    for i in range(M):
        w = synchrosqueezing_window(f, i, fs)
        ICs[i] = np.sum(stft*w, axis=1)

    return ICs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we calculate the short-time Fourier transform using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy.signal.stft&lt;/code&gt; function. We then calculate the synchrosqueezing window using a custom-defined function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;synchrosqueezing_window&lt;/code&gt;. We calculate the ICC components using the synchrosqueezing operator and return the matrix of the ICC components.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;In this article, we discussed the concept of intrinsic chirp component decomposition and its variants. We provided equations and Python implementations for each variant, along with examples. ICCD and its variants are powerful tools for extracting information from a given signal, and they have several applications in signal processing, such as in speech recognition, image analysis, and bio-medical signal processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Gabor Wigner Transform and Its Variants</title>
   <link href="http://localhost:4000/2023/03/27/gabor-wigner-transformation"/>
   <updated>2023-03-27T00:00:00+01:00</updated>
   <id>http://localhost:4000/2023/03/27/gabor-wigner-transformation</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The Gabor Wigner Transform (GWT) is a technique used in signal processing to analyze time-varying signals. It is based on the Short-Time Fourier Transform (STFT), which allows the analysis of signals in the time-frequency domain. The GWT extends the STFT by considering the Wigner distribution, which is a time-frequency distribution with desirable mathematical properties.&lt;/p&gt;

&lt;h1 id=&quot;gabor-wigner-transform&quot;&gt;Gabor Wigner Transform&lt;/h1&gt;
&lt;p&gt;Let x(t) be a continuous-time signal, and g(t) be a window function. The Gabor Wigner Transform of x(t) is defined as follows:&lt;/p&gt;

\[GW_x(t, \omega) = \int_{-\infty}^\infty x(\tau)g(\tau - t)e^{-j\omega \tau}d\tau.\]

&lt;p&gt;The GWT represents the time-frequency content of x(t) as a two-dimensional function, where the vertical axis represents frequency and the horizontal axis represents time.&lt;/p&gt;

&lt;h1 id=&quot;variants-of-gabor-wigner-transform&quot;&gt;Variants of Gabor Wigner Transform&lt;/h1&gt;

&lt;h2 id=&quot;complex-gabor-wigner-transform&quot;&gt;Complex Gabor Wigner Transform&lt;/h2&gt;
&lt;p&gt;The Complex Gabor Wigner Transform (CGWT) is an extension of the GWT that uses complex window functions. The CGWT is defined as follows:&lt;/p&gt;

\[CGW_x(t, \omega) = \int_{-\infty}^\infty x(\tau)g(\tau - t)e^{-j\omega \tau}d\tau + i\int_{-\infty}^\infty x(\tau)h(\tau - t)e^{-j\omega \tau}d\tau,\]

&lt;p&gt;where g(t) and h(t) are complex window functions. The CGWT allows the phase information of the signal to be retained in the time-frequency domain.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cgwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;complex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ifft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;wavelet-gabor-wigner-transform&quot;&gt;Wavelet Gabor Wigner Transform&lt;/h2&gt;
&lt;p&gt;The Wavelet Gabor Wigner Transform (WGWT) is another variant of GWT that uses wavelet functions as the window functions. The WGWT is defined as follows:&lt;/p&gt;

\[WGW_x(t, \omega) = \int_{-\infty}^\infty x(\tau)g_{a,b}(\tau - t)e^{-j\omega \tau}d\tau,\]

&lt;p&gt;where g_{a,b}(t) is a wavelet function with scale a and shift b.&lt;/p&gt;

&lt;h3 id=&quot;python-implementation-1&quot;&gt;Python Implementation&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;wgwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;complex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;multi-window-gabor-wigner-transform&quot;&gt;Multi-Window Gabor Wigner Transform&lt;/h2&gt;
&lt;p&gt;The Multi-Window Gabor Wigner Transform (MWGWT) uses multiple window functions with different time-frequency resolutions. The MWGWT is defined as follows:&lt;/p&gt;

\[MWG_x(t, \omega) = \sum_i \int_{-\infty}^\infty x(\tau)g_i(\tau - t)e^{-j\omega \tau}d\tau.\]

&lt;h3 id=&quot;python-implementation-2&quot;&gt;Python Implementation&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mwgwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;complex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;windows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;spectrogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The Gabor Wigner Transform and its variants are useful techniques for analyzing time-varying signals in the time-frequency domain. The CGWT allows the phase information of the signal to be retained, while the WGWT uses wavelet functions for better time-frequency resolution. The MWGWT combines multiple window functions to achieve a balance between time and frequency resolutions. All of these variants can be easily implemented in Python, making them accessible to a wider audience.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Time Frequency Representations and Its Variants</title>
   <link href="http://localhost:4000/2023/03/26/tf-representations"/>
   <updated>2023-03-26T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/26/TF-representations</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Time-frequency analysis (TFA) is a technique that allows us to analyze signals in both time and frequency domains. Traditional Fourier analysis assumes that the signal is stationary over time, i.e., the frequency content of the signal is constant. However, in real-world applications, such as speech and music signal processing, the stationary assumption does not hold. TFA provides time-frequency representations of non-stationary signals, enabling us to study signal dynamics with changing frequency behavior.&lt;/p&gt;

&lt;h2 id=&quot;time-frequency-representations&quot;&gt;Time Frequency Representations&lt;/h2&gt;
&lt;p&gt;Time-frequency representations can be classified into four groups: Short-Time Fourier Transform (STFT), Continuous Wavelet Transform (CWT), Empirical Mode Decomposition (EMD) and Cohens class.&lt;/p&gt;

&lt;h3 id=&quot;short-time-fourier-transform-stft&quot;&gt;Short-Time Fourier Transform (STFT)&lt;/h3&gt;
&lt;p&gt;STFT is a standard technique for time-frequency analysis that computes the Fourier transform of signal segments over time. The analysis window of a fixed-length is used to break down the signal into overlapping segments. An STFT of size $N$ applied to the signal $x(n)$ gives:&lt;/p&gt;

\[\begin{equation}
X_{m,k} = \sum^{N-1}_{n=0}x(n+mH)w(n)e^{-j2\pi kn/N}
\end{equation}\]

&lt;p&gt;where $H$ is the hop-size between window frames, $w(n)$ is the analysis window, $m$ denotes the window frame number, and $k$ is the frequency index. The STFT is characterized by the window shape and length, as well as the hop size.&lt;/p&gt;

&lt;p&gt;Python Implementation of STFT:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_window&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.fftpack&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nwin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;win&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nwin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nframes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nwin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nwin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;reflect&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;frames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride_tricks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;as_strided&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nwin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nframes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                             &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itemsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itemsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;frames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;spectrum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nfft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spectrum&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;continuous-wavelet-transform-cwt&quot;&gt;Continuous Wavelet Transform (CWT)&lt;/h3&gt;
&lt;p&gt;CWT finds the time-frequency decomposition of the signal by using a time-varying window, or wavelet. The wavelet is scaled and shifted over time to obtain the distribution of the frequency and its variations with time. The CWT of a signal $x(t)$ with wavelet $\psi(t)$ is given by:&lt;/p&gt;

\[\begin{equation}
W_x(a,b) = \int^{+\infty}_{-\infty}\psi^*(t)\frac{1}{\sqrt{|a|}}x(t)\exp{\bigg(\frac{i}{a}bt\bigg)}dt
\end{equation}\]

&lt;p&gt;where the wavelet $\psi(t)$ is scaled by a factor $a$ and shifted by $b$. CWT requires the selection of a suitable wavelet that is appropriate for the application.&lt;/p&gt;

&lt;p&gt;Python Implementation of CWT:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pywt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wavelet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sampling_period&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;empirical-mode-decomposition-emd&quot;&gt;Empirical Mode Decomposition (EMD)&lt;/h3&gt;
&lt;p&gt;EMD is a data-driven, adaptive time-frequency decomposition method that decomposes a signal into Intrinsic Mode Functions (IMFs), resulting in a time-frequency representation. IMFs are the low-frequency components of the signal, and they represent the signals local characteristics.&lt;/p&gt;

&lt;p&gt;Python Implementation of EMD:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emd&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;emd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emd_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;imfs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emd_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imfs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;cohens-class&quot;&gt;Cohens Class&lt;/h3&gt;
&lt;p&gt;Cohens class is a generalization of the STFT that allows the window function to vary over time. This generalization allows the use of different window functions that change over time. The Cohens Class of a signal $x(t)$ with a window function $g(t,\tau)$ is given by:&lt;/p&gt;

\[\begin{equation}
C_{g}(s, \tau) = \int_{-\infty}^{\infty}x(t)g^*(t, \tau)\exp(-j2\pi st)dt
\end{equation}\]

&lt;p&gt;where $g(t,\tau)$ is a time-varying window function dependent on a continuous parameter $\tau$.&lt;/p&gt;

&lt;p&gt;Python Implementation of Cohens Class:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyct&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saa&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cohens_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;s_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&quot;time-frequency-representations-1&quot;&gt;Time Frequency Representations&lt;/h1&gt;

&lt;p&gt;In signal processing, it is often necessary to analyze signals in both time and frequency domains. However, traditional Fourier analysis is not sufficient as it only analyzes the frequency components and completely ignores the variations in time. This limitation led to the development of time frequency representations (TFRs) that analyze the frequency components of a signal at different points in time.&lt;/p&gt;

&lt;p&gt;TFRs are important in many fields of signal processing, including speech processing, radar signal analysis, biomedical engineering, and image processing. There are many different types of TFRs, each with its own strengths and weaknesses.&lt;/p&gt;

&lt;h2 id=&quot;wigner-distribution-function&quot;&gt;Wigner Distribution Function&lt;/h2&gt;

&lt;p&gt;The Wigner distribution function (WDF) is a widely used TFR that was introduced in the 1930s by Eugene Wigner. It provides a joint time-frequency analysis and gives an estimate of the local energy density of a signal in time and frequency domains.&lt;/p&gt;

&lt;p&gt;The WDF has several advantages. Firstly, it can accurately detect time-varying frequencies and phase information, making it useful for analyzing non-stationary signals. Secondly, it has good resolution properties and can distinguish between closely spaced frequency components. However, the WDF has some limitations. It has a high computational complexity and can produce negative values, making interpretation difficult.&lt;/p&gt;

&lt;h2 id=&quot;modified-distribution-functions&quot;&gt;Modified Distribution Functions&lt;/h2&gt;

&lt;p&gt;Modified distribution functions (MDFs) are a family of TFRs that include smoothed WDFs, spectrograms, and scalograms. Spectrograms are the most widely used MDFs and provide a frequency-time representation of a signal. They use a window function to obtain a smoothed version of the WDF and have a low computational complexity.&lt;/p&gt;

&lt;p&gt;Scalograms are a type of MDF that uses wavelet transforms to analyze signals. They have good time-frequency resolution and can capture both high and low-frequency components of a signal. However, they have limited resolution in time and frequency if the wavelet basis function is not chosen properly.&lt;/p&gt;

&lt;h2 id=&quot;table-comparing-tfrs&quot;&gt;Table comparing TFRs&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;TFR&lt;/th&gt;
      &lt;th&gt;Pros&lt;/th&gt;
      &lt;th&gt;Cons&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Wigner&lt;/td&gt;
      &lt;td&gt;Accurate frequency and phase information. Good frequency resolution.&lt;/td&gt;
      &lt;td&gt;High computational complexity. Can produce negative values, making interpretation difficult.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spectrogram&lt;/td&gt;
      &lt;td&gt;Low computational complexity. Good frequency resolution.&lt;/td&gt;
      &lt;td&gt;Limited time and frequency resolution.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Scalogram&lt;/td&gt;
      &lt;td&gt;Good time and frequency resolution. Can capture both high and low frequencies.&lt;/td&gt;
      &lt;td&gt;Limited resolution in time and frequency if the wavelet basis function is not chosen properly.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In conclusion, TFRs are an essential tool in signal processing as they allow for a joint analysis of the time and frequency domains. The choice of TFR will depend on the specific requirements of the analysis, including the complexity of the signal and the desired resolution in time and frequency.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Time-frequency analysis is a powerful technique for signal processing, especially when analyzing non-stationary signals. The article provided an introduction to TFA, discussing time-frequency representations and the need for them. Additionally, it explained the four main types of time-frequency representations and their working principles. Python implementations of Short-Time Fourier Transform (STFT), Continuous Wavelet Transform (CWT), Empirical Mode Decomposition (EMD), and Cohens Class were also provided as examples.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Empirical Wavelet Transform and its Variants</title>
   <link href="http://localhost:4000/2023/03/25/ewt"/>
   <updated>2023-03-25T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/25/EWT</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Empirical Wavelet Transform (EWT) is a time-frequency analysis tool used for decomposing signals into localized oscillatory modes. It is a data-driven approach for signal processing that does not require any prior knowledge about the signal or any specific wavelet basis. EWT is particularly useful for non-stationary signals that exhibit time-varying statistical properties.&lt;/p&gt;

&lt;p&gt;EWT is based on the principle of finding local oscillations in the signal using an adaptive wavelet that varies with the signal itself. It is a versatile technique that has several variants, each with its unique properties and applications. This article provides an overview of some of the most commonly used variants of EWT and their mathematical formulations. Python implementations and examples are also included.&lt;/p&gt;

&lt;h1 id=&quot;empirical-wavelet-transform-ewt&quot;&gt;Empirical Wavelet Transform (EWT)&lt;/h1&gt;

&lt;p&gt;EWT decomposes a signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; into a set of oscillatory modes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m_i(t)&lt;/code&gt; that represent localized oscillations in the signal with different time and frequency characteristics. The EWT process involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the Hilbert Spectrum of the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; using the Hilbert-Huang Transform (HHT).&lt;/li&gt;
  &lt;li&gt;Estimate the local frequency and bandwidth of each mode using an adaptive wavelet.&lt;/li&gt;
  &lt;li&gt;Perform a weighted Fourier transform of each mode to obtain the oscillatory component and its corresponding scale.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Empirical Wavelet Function (EWF) at scale &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; and position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; is defined as:&lt;/p&gt;

\[\Psi_{a, t}(x) = \frac{1}{|a|^{1/2}} \Psi\left(\frac{x-t}{a}\right)\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Psi&lt;/code&gt; is an analyzing wavelet function, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; is the scale parameter that varies with time. The local oscillatory mode &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m_i(t)&lt;/code&gt; is obtained by convolving the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; with the EWF &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Psi_a,t(x)&lt;/code&gt;:&lt;/p&gt;

\[m_i(t) = \int_{-\infty}^{\infty} f(x) \Psi_{a_i, t_i}(x-t) dx\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a_i&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t_i&lt;/code&gt; are the scale and position parameters estimated for each mode, respectively.&lt;/p&gt;

&lt;p&gt;The Hilbert Spectrum of the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; is obtained using HHT, which involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Decompose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; into a set of Intrinsic Mode Functions (IMFs) using Empirical Mode Decomposition (EMD).&lt;/li&gt;
  &lt;li&gt;Compute the Hilbert transform of each IMF.&lt;/li&gt;
  &lt;li&gt;Compute the instantaneous frequency and amplitude of each mode using the Hilbert Transform.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Hilbert Transform of a signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; is defined as:&lt;/p&gt;

\[H[f(t)] = \frac{1}{\pi t} PV\!\!\!\!\int_{-\infty}^{\infty} \frac{f(x)}{t-x}dx\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PV&lt;/code&gt; denotes the principal value integral.&lt;/p&gt;

&lt;p&gt;Once the Hilbert Spectrum is obtained, EWT can be used to decompose the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; into a set of oscillatory modes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m_i(t)&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;variants-of-ewt&quot;&gt;Variants of EWT&lt;/h1&gt;

&lt;p&gt;EWT has several variants that differ in the wavelet function used, the thresholding method used to estimate the local frequency and bandwidth, and the weighting scheme used to obtain the oscillatory component. Some commonly used variants are:&lt;/p&gt;

&lt;h2 id=&quot;fourier-based-empirical-wavelet-transform-fwt&quot;&gt;Fourier-Based Empirical Wavelet Transform (FWT)&lt;/h2&gt;

&lt;p&gt;FWT is a simplified version of EWT that uses the Fourier transform instead of the adaptive wavelet to estimate the local frequency and bandwidth. FWT involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the Fourier transform of the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Compute the magnitude and phase of each frequency component.&lt;/li&gt;
  &lt;li&gt;Estimate the local frequency as the derivative of the phase with respect to time.&lt;/li&gt;
  &lt;li&gt;Estimate the local bandwidth as the inverse of the second derivative of the phase with respect to time.&lt;/li&gt;
  &lt;li&gt;Apply a weighting function to obtain the oscillatory component.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Fourier-Based Empirical Wavelet Function is defined as:&lt;/p&gt;

\[\Psi_{a, t}(x) = \frac{1}{\sqrt{2\pi}|a|} e^{iwx}e^{-\frac{(x-t)^2}{2a^2}}\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; is the scale parameter, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; is the position parameter, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt; is the frequency parameter. The local frequency and bandwidth at position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; are estimated as the instantaneous frequency and bandwidth of the Fourier component at that position, respectively.&lt;/p&gt;

&lt;h2 id=&quot;complex-empirical-wavelet-transform-cewt&quot;&gt;Complex Empirical Wavelet Transform (CEWT)&lt;/h2&gt;

&lt;p&gt;CEWT is a variant of EWT that uses a complex wavelet to obtain the oscillatory modes. The complex wavelet is defined as:&lt;/p&gt;

\[\Psi(x) = e^{iwx} \phi(x)\]

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt; is the frequency parameter, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;phi(x)&lt;/code&gt; is a real-valued analyzing function. CEWT involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the Hilbert Spectrum of the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; using HHT.&lt;/li&gt;
  &lt;li&gt;Approximate the Hilbert Spectrum as a sum of complex signals using a complex wavelet transform.&lt;/li&gt;
  &lt;li&gt;Apply a thresholding method to obtain a set of Hilbert ridges, which represent the oscillatory modes.&lt;/li&gt;
  &lt;li&gt;Apply a weighting function to obtain the oscillatory component.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;synchrosqueezing-transform-sst&quot;&gt;Synchrosqueezing Transform (SST)&lt;/h2&gt;

&lt;p&gt;SST is a variant of EWT that uses a reassignment method to obtain the oscillatory modes. SST involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the Hilbert Spectrum of the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(t)&lt;/code&gt; using HHT.&lt;/li&gt;
  &lt;li&gt;Reassign the energy of each component of the Hilbert Spectrum to the corresponding frequency and time.&lt;/li&gt;
  &lt;li&gt;Apply a thresholding method to obtain a set of Hilbert ridges, which represent the oscillatory modes.&lt;/li&gt;
  &lt;li&gt;Apply a weighting function to obtain the oscillatory component.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h1&gt;

&lt;p&gt;The following Python code provides an example of how to implement FWT using NumPy:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the Fourier transform of the data
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;fft_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the frequency and phase of each component
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fftfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sampling_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;angle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the local frequency and bandwidth of each mode
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ddf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;local_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;local_bandwidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ddf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the Fourier-Based Empirical Wavelet Function Psi
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Psi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local_bandwidth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the amplitude and oscillatory component
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;amplitude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;oscillatory_component&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amplitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Psi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oscillatory_component&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This code takes as input an array of signal data &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data&lt;/code&gt; and an array of scale parameters &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scales&lt;/code&gt;, and returns the Fourier-based Empirical Wavelet Transform of the signal. The code computes the Fourier transform of the signal and estimates the local frequency and bandwidth of each mode using the Fourier coefficients. It then computes the Fourier-based Empirical Wavelet Function Psi and applies it to obtain the oscillatory component of each mode.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Empirical Wavelet Transform is a powerful time-frequency analysis tool that can be used for decomposing signals into localized oscillatory modes. There are several variants of EWT, each with its unique properties and applications. This article provided an overview of some of the most commonly used variants of EWT and their mathematical formulations, along with Python implementations of each variant. EWT can be a valuable tool for analyzing non-stationary signals in a wide range of applications.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Time Filtering</title>
   <link href="http://localhost:4000/2023/03/24/time-filtering"/>
   <updated>2023-03-24T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/24/time-filtering</id>
   <content type="html">
&lt;hr /&gt;
&lt;p&gt;layout: post
title: Different Time Filtering Algorithms and Their Variants
description: This article discusses different time filtering algorithms along with their variants, and provides a Python implementation for each. The article also includes equations in LaTeX for each algorithm.
summary: This article provides an overview of different time filtering algorithms and their variants, along with a Python implementation and equations in LaTeX.
author: Pavan Donthireddy
mathjax: true
original: new
tags: [ filters ]
&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Time filtering is a technique used in signal processing to remove noise and other unwanted signals from a signal. There are several time filtering algorithms, with variations in each. This article provides an overview of some of the most common time filtering algorithms, along with their variants. We will also provide a Python implementation for each algorithm.&lt;/p&gt;

&lt;h1 id=&quot;moving-average-filter&quot;&gt;Moving Average Filter&lt;/h1&gt;
&lt;p&gt;The moving average filter (MAF) is one of the most basic time filtering algorithms. It works by averaging a certain number of adjacent data points in a signal. The MAF can be represented mathematically as:&lt;/p&gt;

\[y[n] = \frac{1}{N}\sum_{i=0}^{N-1}x[n-i]\]

&lt;p&gt;where N is the window size, x[n] is the input signal, and y[n] is the output signal.&lt;/p&gt;

&lt;p&gt;A simple Python implementation of the MAF would be:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def moving_average_filter(x, N):
    y = []
    for i in range(len(x)):
        if i &amp;lt; N:
            y.append(sum(x[:i+1])/len(x[:i+1]))
        else:
            y.append(sum(x[i-N+1:i+1])/N)
    return y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;exponential-moving-average-filter&quot;&gt;Exponential Moving Average Filter&lt;/h1&gt;
&lt;p&gt;The exponential moving average filter (EMA) is a variation of the MAF. It works by weighting each data point in the input signal by a coefficient that decreases exponentially as the data point moves further away from the current time step. The EMA can be represented mathematically as:&lt;/p&gt;

\[y[n] = \alpha x[n] + (1 - \alpha) y[n-1]\]

&lt;p&gt;where $\alpha$ is a coefficient between 0 and 1 that determines the weighting of each data point, x[n] is the input signal, and y[n] is the output signal.&lt;/p&gt;

&lt;p&gt;A simple Python implementation of the EMA would be:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def exponential_moving_average_filter(x, alpha):
    y = [x[0]]
    for i in range(1, len(x)):
        y.append(alpha*x[i] + (1-alpha)*y[i-1])
    return y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;butterworth-low-pass-filter&quot;&gt;Butterworth Low-Pass Filter&lt;/h1&gt;
&lt;p&gt;The Butterworth low-pass filter (BLPF) is a filter that can be used to remove high-frequency noise from a signal. It works by cutting off high-frequency signals while passing low-frequency signals. The BLPF can be represented mathematically as:&lt;/p&gt;

\[H(s) = \frac{1}{1 + (\frac{s}{\omega_c})^{2n}}\]

&lt;p&gt;where s is the Laplace variable, $\omega_c$ is the cutoff frequency, and n is the order of the filter.&lt;/p&gt;

&lt;p&gt;To implement the BLPF in Python, we can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;signal&lt;/code&gt; module from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy&lt;/code&gt; library:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;butterworth_low_pass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff_frequency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff_frequency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;lowpass&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analog&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;kalman-filter&quot;&gt;Kalman Filter&lt;/h1&gt;
&lt;p&gt;The Kalman filter is a complex algorithm that can be used to filter noisy measurements of a system. It works by using a series of measurements to estimate the state of a system over time, taking into account the uncertainty and noise in each measurement. The Kalman filter can be represented mathematically by a set of equations that describe the state estimate, the error covariance matrix, and the optimal Kalman gain.&lt;/p&gt;

&lt;p&gt;A simple Python implementation of the Kalman filter would be:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np

def kalman_filter(x, z, A, H, Q, R, P):
    x_hat = np.zeros_like(x)
    P_hat = np.zeros_like(P)
    K = np.zeros_like(x)

    for i in range(len(x)):
        # Time update
        x_hat[i] = A @ x_hat[i-1]
        P_hat[i] = A @ P_hat[i-1] @ A.T + Q

        # Measurement update
        K[i] = P_hat[i] @ H.T @ np.linalg.inv(H @ P_hat[i] @ H.T + R)
        x_hat[i] = x_hat[i] + K[i] @ (z[i] - H @ x_hat[i])
        P_hat[i] = (np.eye(len(A)) - K[i] @ H) @ P_hat[i]

    return x_hat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;There are many time filtering algorithms, each with their own variations and applications. In this article, we have provided overviews of the moving average filter, the exponential moving average filter, the Butterworth low-pass filter, and the Kalman filter. We have also provided Python implementations for each algorithm. These algorithms can be used to remove noise and other unwanted signals from a signal, which can be valuable in various applications.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Frequency Filtering</title>
   <link href="http://localhost:4000/2023/03/23/frequency-filtering"/>
   <updated>2023-03-23T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/23/frequency-filtering</id>
   <content type="html">
&lt;hr /&gt;
&lt;p&gt;layout: post
title: Different Frequency Filtering Algorithms and its Variants
description: This article discusses various frequency filtering algorithms and their variants, along with equations in LaTeX. It also includes Python implementations for each variant with an example.
summary: This article discusses various frequency filtering algorithms and their variants, along with equations in LaTeX. It also includes Python implementations for each variant with an example.
author: Pavan Donthireddy
mathjax: true
original: new
tags: [ filters ]
&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Frequency filtering is an essential signal processing technique used to eliminate unwanted frequency components from signals. It is used in various fields such as audio processing, image processing, and communication systems. Frequency filtering algorithms are designed to remove unwanted frequency components while preserving the useful components. This article provides a brief overview of common frequency filtering algorithms and their variants, along with their mathematical equations in LaTeX.&lt;/p&gt;

&lt;h1 id=&quot;types-of-frequency-filtering-algorithms&quot;&gt;Types of Frequency Filtering Algorithms&lt;/h1&gt;

&lt;h2 id=&quot;low-pass-filter&quot;&gt;Low-Pass Filter&lt;/h2&gt;

&lt;p&gt;A low-pass filter allows the low-frequency components of a signal to pass while attenuating the high-frequency components. The cut-off frequency of a low-pass filter determines the point at which the high-frequency components are attenuated. The transfer function of a low-pass filter can be expressed as follows:&lt;/p&gt;

\[H_{lp}(f) = \frac{1}{1 + j\frac{f}{f_c}}\]

&lt;p&gt;Where $f_c$ is the cut-off frequency.&lt;/p&gt;

&lt;h3 id=&quot;implementation-in-python&quot;&gt;Implementation in Python&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lowpass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; 
    Implements a low-pass filter on the input signal. 
    
    Args:
    signal (ndarray): Input signal
    cutoff_freq (float): Cut-off frequency of the filter
    sample_rate (float): Sample rate of the signal
    
    Returns:
    ndarray: Filtered signal
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_cutoff_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized_cutoff_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;lowpass&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example Usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lowpass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Original Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Filtered Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;high-pass-filter&quot;&gt;High-Pass Filter&lt;/h2&gt;

&lt;p&gt;As the name suggests, a high-pass filter attenuates the low-frequency components of a signal while allowing the high-frequency components to pass. The cut-off frequency of a high-pass filter determines the point at which the low-frequency components are attenuated. The transfer function of a high-pass filter can be expressed as follows:&lt;/p&gt;

\[H_{hp}(f) = \frac{jf}{j\frac{f}{f_c} + 1}\]

&lt;p&gt;Where $f_c$ is the cut-off frequency.&lt;/p&gt;

&lt;h3 id=&quot;implementation-in-python-1&quot;&gt;Implementation in Python&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;highpass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; 
    Implements a high-pass filter on the input signal. 
    
    Args:
    signal (ndarray): Input signal
    cutoff_freq (float): Cut-off frequency of the filter
    sample_rate (float): Sample rate of the signal
    
    Returns:
    ndarray: Filtered signal
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_cutoff_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized_cutoff_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;highpass&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example Usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;highpass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Original Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Filtered Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;band-pass-filter&quot;&gt;Band-Pass Filter&lt;/h2&gt;

&lt;p&gt;A band-pass filter attenuates the frequency components outside its pass-band, allowing only the frequency components within the band to pass. The pass-band of a band-pass filter is defined by the upper and lower cut-off frequencies. The transfer function of a band-pass filter can be expressed as follows:&lt;/p&gt;

\[H_{bp}(f) = \frac{j(f_{h} - f_{l})}{j\frac{(f_{h} - f_{l})}{f_c} + 1} e^{-j2\pi\frac{f_{h} + f_{l}}{2f_s}t}\]

&lt;p&gt;Where $f_{h}$ and $f_{l}$ are the upper and lower cut-off frequencies, respectively.&lt;/p&gt;

&lt;h3 id=&quot;implementation-in-python-2&quot;&gt;Implementation in Python&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bandpass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;highcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; 
    Implements a band-pass filter on the input signal. 
    
    Args:
    signal (ndarray): Input signal
    lowcut (float): Lower cut-off frequency of the filter
    highcut (float): Upper cut-off frequency of the filter
    sample_rate (float): Sample rate of the signal
    
    Returns:
    ndarray: Filtered signal
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_lowcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_highcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;highcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalized_lowcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized_highcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;band&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example Usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bandpass_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Original Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Filtered Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;band-stop-filter&quot;&gt;Band-Stop Filter&lt;/h2&gt;

&lt;p&gt;A band-stop filter attenuates the frequency components within its stop-band, allowing only the frequency components outside the band to pass. The stop-band of a band-stop filter is defined by the upper and lower cut-off frequencies. The transfer function of a band-stop filter can be expressed as follows:&lt;/p&gt;

\[H_{bs}(f) = \frac{1}{1 + j\frac{(f_{h} - f_{l})}{f_c}} e^{-j2\pi\frac{f_{h} + f_{l}}{2f_s}t}\]

&lt;p&gt;Where $f_{h}$ and $f_{l}$ are the upper and lower cut-off frequencies, respectively.&lt;/p&gt;

&lt;h3 id=&quot;implementation-in-python-3&quot;&gt;Implementation in Python&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bandstop_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;highcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; 
    Implements a band-stop filter on the input signal. 
    
    Args:
    signal (ndarray): Input signal
    lowcut (float): Lower cut-off frequency of the filter
    highcut (float): Upper cut-off frequency of the filter
    sample_rate (float): Sample rate of the signal
    
    Returns:
    ndarray: Filtered signal
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_lowcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_highcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;highcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyquist_freq&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;butter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalized_lowcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized_highcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;btype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;bandstop&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filtfilt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example Usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bandstop_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Original Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Filtered Signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Frequency filtering is an essential technique in digital signal processing, and various algorithms and their variants are commonly used in various fields. This article provided a brief overview of the most common frequency filtering algorithms, along with mathematical equations in LaTeX and their Python implementations. It is vital to understand the application and characteristics of different algorithms before selecting a specific algorithm for a specific task.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Variational Mode Decomposition Algorithm</title>
   <link href="http://localhost:4000/2023/03/22/vmd"/>
   <updated>2023-03-22T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/22/VMD</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The Variational Mode Decomposition (VMD) algorithm is a signal processing technique used for extracting modes from signals. It is based on the concept of representing a signal as a sum of oscillatory components, with each component having a specific frequency and amplitude. The VMD algorithm is commonly used in applications such as biomedical signal analysis and image processing.&lt;/p&gt;

&lt;p&gt;In this article, we will provide an overview of the VMD algorithm, its mathematical formulation, and provide a Python implementation for extracting modes from a signal.&lt;/p&gt;

&lt;h1 id=&quot;mathematical-formulation&quot;&gt;Mathematical Formulation&lt;/h1&gt;

&lt;p&gt;The VMD algorithm involves minimizing a cost function, which is defined as the sum of the squared differences between the signal and its reconstructed version using the extracted modes. The cost function is subject to a constraint that ensures that the mode functions are smooth and oscillatory.&lt;/p&gt;

&lt;p&gt;Lets consider a signal $x(t)$ that is represented as the sum of $K$ oscillatory components or modes $u_k(t)$, that are extracted using the VMD algorithm. Each mode $u_k(t)$ has a specific frequency $\omega_k$ and amplitude $a_k$. The VMD algorithm aims to find the modes $u_k(t)$ that best represent the signal $x(t)$.&lt;/p&gt;

&lt;p&gt;The cost function for the VMD algorithm can be written as:&lt;/p&gt;

\[\min_{z,u} \sum_{k=1}^{K} \| z_k - D_k u_k \|^2_2 + \lambda \sum_{k=1}^{K-1} \| \mu_k \|_{TV}\]

&lt;p&gt;where $z_k$ is the $k^{th}$ analytic signal of $x(t)$, $D_k$ is a diagonal matrix containing the Fourier coefficients corresponding to the $k^{th}$ frequency band, $\mu_k$ is the difference between adjacent mode functions, $\lambda$ is a regularization parameter that controls the smoothness of the modes, and $TV$ denotes the total variation.&lt;/p&gt;

&lt;p&gt;The optimization problem can be solved using an alternating minimization algorithm, which involves alternating between updating the mode functions and the auxiliary variables. The mode functions are updated using a fixed-point iteration method that involves solving a constrained least squares problem. The auxiliary variables are updated using a soft-thresholding operation.&lt;/p&gt;

&lt;h1 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h1&gt;

&lt;p&gt;Lets now see how we can implement the VMD algorithm in Python.&lt;/p&gt;

&lt;p&gt;First, we need to import the required libraries:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hilbert&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.sparse&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diags&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.sparse.linalg&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spsolve&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we define a function to calculate the total variation of a given signal:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;total_variation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We then define a function to extract the modes from a given signal using the VMD algorithm:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vmd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxiter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;lamda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxiter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;complex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;uhat_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;complex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;uhat_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uhat_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lamda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ifft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uhat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]))&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;total_variation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lamda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;uold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we can use the above function to extract the modes from a signal:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Generate a sample signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Extract modes using VMD
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vmd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot the extracted modes
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Amplitude&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Mode &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;The Variational Mode Decomposition (VMD) algorithm is a powerful signal processing technique that can be used for extracting modes from signals. In this article, we provided an overview of the VMD algorithm, its mathematical formulation, and a Python implementation for extracting modes from a signal. The VMD algorithm has numerous applications in the fields of biomedical signal analysis and image processing, and can be a useful tool for researchers and engineers working in these areas.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Iterative Filtering Decomposition Algorithm</title>
   <link href="http://localhost:4000/2023/03/21/ifd"/>
   <updated>2023-03-21T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/21/IFD</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The Iterative Filtering Decomposition (IFD) algorithm is used for decomposing nonlinear and non-stationary signals into different components.&lt;/p&gt;

&lt;p&gt;The IFD algorithm involves iteratively high-pass filtering the original signal, using two complementary filters. The high-frequency components are retained, while the low-frequency components are discarded. This process is repeated iteratively, until the desired number of components are obtained.&lt;/p&gt;

&lt;p&gt;The IFD algorithm is useful in various domains, including engineering, biology, finance, and geophysics. It has been used in the analysis of EEG signals, ECG signals, and seismic data.&lt;/p&gt;

&lt;p&gt;In this article, we will provide an overview of the IFD algorithm, including the mathematical equations involved, a Python implementation of the algorithm, and a sample application.&lt;/p&gt;

&lt;h1 id=&quot;mathematical-equations&quot;&gt;Mathematical Equations&lt;/h1&gt;

&lt;p&gt;The IFD algorithm involves iteratively applying two complementary filters to the original signal, to obtain a set of components. The two filters are defined as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The high-pass filter H(z) is given by:
\(H(z) = \frac{1 - z^{-2}}{1-\alpha z^{-1}}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The low-pass filter L(z) is given by:
\(L(z) = \frac{\alpha (1+z^{-1})}{1-\alpha z^{-1}}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;where $\alpha$ is the smoothing factor, which controls the cutoff frequency of the filters. It is typically set to a value near 1, to ensure that the filters do not remove too much of the signal.&lt;/p&gt;

&lt;p&gt;To obtain the first component $C_1$ of the signal, we apply the high-pass filter $H(z)$ to the original signal $X(z)$, and obtain:
\(C_1 = H(z) X(z)\)&lt;/p&gt;

&lt;p&gt;To obtain the second component $C_2$, we subtract $C_1$ from the original signal $X(z)$, and apply the high-pass filter $H(z)$ to the resulting signal. We obtain:
\(C_2 = H(z) [X(z) - C_1]\)&lt;/p&gt;

&lt;p&gt;This process is repeated iteratively, to obtain the desired number of components. The $k$-th component $C_k$ is given by:
\(C_k = H(z) [X(z) - \sum_{i=1}^{k-1} C_i]\)&lt;/p&gt;

&lt;h1 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h1&gt;

&lt;p&gt;We can implement the IFD algorithm in Python, using the following function:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lfilter&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ifd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;remaining_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;remaining_signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remaining_signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This function takes three arguments:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;signal&lt;/code&gt;: The original signal.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpha&lt;/code&gt;: The smoothing factor.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_components&lt;/code&gt;: The number of components to obtain.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ifd()&lt;/code&gt; function returns a list of components, obtained using the IFD algorithm.&lt;/p&gt;

&lt;h1 id=&quot;example&quot;&gt;Example&lt;/h1&gt;

&lt;p&gt;Lets consider a simple example, of generating a nonlinear and non-stationary signal, and using the IFD algorithm to decompose it into three components.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.985&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ifd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Original signal&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Component {}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code generates a nonlinear and non-stationary signal, with a random noise component. It then applies the IFD algorithm to obtain three components.&lt;/p&gt;

&lt;p&gt;As we can see, the IFD algorithm successfully decomposes the original signal into three components, which capture different frequency ranges of the signal.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;The Iterative Filtering Decomposition (IFD) algorithm is a useful tool for decomposing nonlinear and non-stationary signals into different components. It involves iteratively high-pass filtering the original signal using two complementary filters, until the desired number of components are obtained.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Intrinsic Time Scale Decomposition</title>
   <link href="http://localhost:4000/2023/03/20/itd"/>
   <updated>2023-03-20T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/20/ITD</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Intrinsic Time Scale Decomposition (ITD) is a signal processing algorithm developed by Cohen and colleagues in the late 1990s. It decomposes a signal into a set of intrinsic time scales using a process of time-frequency reassignment. The algorithm is useful for extracting information from signals which are highly non-stationary, such as speech and music.&lt;/p&gt;

&lt;h1 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h1&gt;

&lt;p&gt;The ITD algorithm works by first computing a spectrogram of the signal, which is a representation of the signals frequency content over time. It then applies a nonlinear transformation to the spectrogram to form a reassigned spectrogram. This reassignment process is done by computing the time-frequency reassignment vector, which is the vector that points from the original frequency bin to the reassigned frequency bin.&lt;/p&gt;

&lt;p&gt;The reassigned spectrogram is then decomposed into a set of intrinsic time scales. This is done by computing the instantaneous frequency of each frequency bin in the reassigned spectrogram. The instantaneous frequency is the rate of change of the frequency bin over time.&lt;/p&gt;

&lt;p&gt;The algorithm then computes the instantaneous energy of each frequency bin in the reassigned spectrogram. The instantaneous energy is the rate of change of the energy in the frequency bin over time.&lt;/p&gt;

&lt;p&gt;Finally, the algorithm computes the time-frequency distribution, which is the distribution of energy over time and frequency for each intrinsic time scale.&lt;/p&gt;

&lt;h1 id=&quot;equations&quot;&gt;Equations&lt;/h1&gt;

&lt;p&gt;The following equations define the ITD algorithm:&lt;/p&gt;

\[S(f,t) = \sum\limits_{k=-\infty}^\infty X[k]e^{-i2\pi f k \Delta t}\]

\[V(f,t) = \frac{\partial S(f,t)}{\partial t}\]

\[X_{\text{reassigned}}(f,t) = S(f,t) + \frac{1}{2\pi}\int_{-\infty}^{\infty}V(f,t)e^{-i2\pi f k \Delta t}dk\]

\[\Omega_i(f,t) = \frac{1}{2\pi}\frac{\partial X_{\text{reassigned}}(f,t)}{\partial f}\]

\[E_i(f,t) = \frac{1}{2\pi}\frac{\partial X_{\text{reassigned}}(f,t)}{\partial t}\]

\[P_i(f,t) = \frac{\Omega_i(f,t)E_i(f,t)}{\sqrt{\Omega_i(f,t)^2 + E_i(f,t)^2}}\]

&lt;h1 id=&quot;python-implementation&quot;&gt;Python implementation&lt;/h1&gt;

&lt;p&gt;The following is a Python implementation of the ITD algorithm:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# import necessary libraries
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stft&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define the signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# your signal
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# compute the spectrogram
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# perform the reassignment
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute the instantaneous frequency and energy
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Omega&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute the time-frequency distribution
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Omega&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Omega&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;example&quot;&gt;Example&lt;/h1&gt;

&lt;p&gt;The following is a simple example of using the ITD algorithm to decompose a signal into its intrinsic time scales. We will use a sine wave as our signal:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# import necessary libraries
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stft&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# generate a sine wave
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# frequency (Hz)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# sampling rate (Hz)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# time vector
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# signal
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# compute the spectrogram
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# perform the reassignment
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute the instantaneous frequency and energy
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Omega&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute the time-frequency distribution
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Omega&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Omega&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# plot the results
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aspect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;auto&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;lower&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Spectrogram&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Frequency (Hz)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time (s)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_reassigned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aspect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;auto&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;lower&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Reassigned Spectrogram&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Frequency (Hz)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time (s)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aspect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;auto&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;lower&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time-Frequency Distribution&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Frequency (Hz)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Time (s)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Intrinsic Time Scale Decomposition is a powerful signal processing algorithm for extracting information from non-stationary signals. It works by first computing a spectrogram and then applying a time-frequency reassignment process to obtain a set of intrinsic time scales. This article has explained the algorithm with equations in latex, python implementation and an example.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Local Mean Decomposition</title>
   <link href="http://localhost:4000/2023/03/19/local-mean-decomposition"/>
   <updated>2023-03-19T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/19/local-mean-decomposition</id>
   <content type="html">&lt;h1 id=&quot;introduction-to-local-mean-decomposition-lmd&quot;&gt;Introduction to Local Mean Decomposition (LMD)&lt;/h1&gt;

&lt;p&gt;Local Mean Decomposition (LMD) is a signal decomposition algorithm used to filter out noise and extract meaningful information from signals. The main idea behind LMD is to decompose a signal into its local means, which can be used to identify the underlying components of the signal. LMD is used in a variety of applications, such as speech recognition, medical imaging, and signal processing.&lt;/p&gt;

&lt;h1 id=&quot;mathematical-formulation&quot;&gt;Mathematical Formulation&lt;/h1&gt;

&lt;p&gt;The mathematical formulation of the LMD algorithm is defined as follows:&lt;/p&gt;

&lt;p&gt;Given a signal $x(t)$, the local mean $m(t)$ at a given point $t$ is computed as follows:&lt;/p&gt;

\[m(t) = \frac{1}{N}\sum_{i=t-N}^{t+N} x(i)\]

&lt;p&gt;where $N$ is the size of the local window.&lt;/p&gt;

&lt;p&gt;The local mean residual is then computed as:&lt;/p&gt;

\[r(t) = x(t) - m(t)\]

&lt;p&gt;The LMD algorithm then recursively applies this process to the residuals, producing local means and residuals at each step:&lt;/p&gt;

\[x_k(t) = r_{k-1}(t) - m_k(t)\]

&lt;p&gt;where $k$ is the iteration step.&lt;/p&gt;

&lt;h1 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h1&gt;

&lt;p&gt;The following is a Python implementation of the LMD algorithm:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lmd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# compute the local mean
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# compute the local mean residual
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# iteratively decompose the signal
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# compute the local mean
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;m_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;convolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;same&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# compute the local mean residual
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;r_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_k&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# update the signal for the next iteration
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_k&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_k&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;example&quot;&gt;Example&lt;/h1&gt;

&lt;p&gt;Lets consider a signal consisting of a sinusoid and some noise:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# generate the signal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can then apply the LMD algorithm to decompose the signal into its local means and residuals:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# apply the lmd algorithm
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lmd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Time frequency filters</title>
   <link href="http://localhost:4000/2023/03/18/time-frequency-filters"/>
   <updated>2023-03-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/18/time-frequency-filters</id>
   <content type="html">&lt;p&gt;Time-frequency filters are signal processing techniques used to filter signals in both the time and frequency domains simultaneously. They allow for the extraction of specific frequency bands of a signal while preserving its temporal features. Unlike traditional filters, which operate only in the time or frequency domain, time-frequency filters can operate in both domains simultaneously and provide more precise control over the filtering process.&lt;/p&gt;

&lt;p&gt;The most commonly used time-frequency filters are based on time-frequency analysis methods, such as the Short-Time Fourier Transform (STFT), Continuous Wavelet Transform (CWT), or the Empirical Mode Decomposition (EMD). These methods provide a time-frequency representation of the signal, which can be further processed using time-frequency filtering techniques.&lt;/p&gt;

&lt;p&gt;Time-frequency filters can be used to achieve a variety of signal processing objectives, such as noise reduction, feature extraction, or signal separation. They are particularly useful in applications where the signal characteristics vary over time, such as speech processing, biomedical signal analysis, and image processing.&lt;/p&gt;

&lt;p&gt;Some examples of time-frequency filters include the time-frequency bandpass filter, which allows the extraction of a specific frequency band of interest, and the time-frequency notch filter, which can be used to remove unwanted frequency components from a signal in specific time-frequency regions.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>A Variable Gain Sliding Mode Tracking Differentiator for Derivative Estimation of Noisy Signals</title>
   <link href="http://localhost:4000/2023/03/17/variable-gain-sliding-td"/>
   <updated>2023-03-17T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/17/variable-gain-sliding-td</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Estimating reliable signal component and its derivatives from noisy feedback signal is
important in control systems. Toward this problem, this article presents a new model-free variable gain
sliding mode tracking differentiator for derivative estimation of noisy signals by modifying a Levant and Yu&apos;s
sliding mode tracking differentiator. Specically, different from Levant and Yu&apos;s TD, the new TD employs
an additional variable that contributes to overshoot reduction. In addition, the new TD adaptively changes
its gains for improving the tracking and ltering performances. Moreover, the new TD only uses previous
output values and it does not require input signal model in advance. The advantages of the new TD over
previous TDs are conrmed through numerical examples.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Estimating reliable signal component and its derivatives from
noisy feedback signal is important in control systems. Tra-
ditional linear lters [1] are simple in structure and low in
computational cost, and thus they are often the rst option.
However, in the case of strong noise reduction, a linear lter
introduces a signicant phase lag in the output. In addition,
a linear lter proportionally transfers any signal component
into the output. These problems of linear lters may cause
instability of the controlled system in the case where system
hardware generates signicant phase lag and noise compo-
nent has high amplitude.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Sliding mode tracking differentiators are studied for avoid-
ing the disadvantages of linear lters. For example, Han and
Wang [2] proposed a sliding mode tracking differentiator
(TD [2]), of which the sliding surface takes a parabolic
curve-like shape. One major advantage of TD [2] is that it
realizes minimum-time convergence. Because of its effective-
ness, TD [2] has been applied in many applications, such as
The associate editor coordinating the review of this manuscript and
approving it for publication was Geng-Ming Jiang .
vehicle suspension system [3], induction motor system [4]
and wind turbine system [5].&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;However, TD [2] is prone to
overshoot during convergence. Jin et al. [6] presented a mod-
ication of TD [2] by introducing a multi-level set-valued
mapping (TD [6]). It is reported that, compared with TD [2],
TD [6] is less prone to overshoot, and it produces smaller
phase lag. After that, extensions of TD [6] are reported in the
literature [7][10]. However, this class of tracking differentia-
tors is limited to estimations of the input and its the 1st-order
derivative.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Another class of sliding mode tracking differentiators that
proposed by Levant and his colleagues received consider-
able attention in recent years. Specically, in [11], Lev-
ant proposed 2nd-order tracking differentiator (TD [11])
that effectively estimates useful signal component and its
1st-order derivative from the input. Due to simple structure,
easy design procedure and high tracking accuracy, TD [11]
has been widely applied in control systems [12][14]. How-
ever, TD [11] is also limited to 1st-order derivative.
Toward the problem of high-order derivative estimation,
in a subsequent study [15], Levant presented a TD [11]&apos;s
extension (TD [15]) that realizes the estimation of arbitrary&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;order derivative of the input. In addition, TD [15] can effec-
tively remove small magnitude noise contained in the input,
and it can reduce the chattering phenomenon by increasing
the system order. After that, in [16], Levant and Yu proposed
a TD [15]&apos;s modication (TD [16]) that provides better track-
ing accuracy and ltering performance than TD [15] does.
However, the performance of TD [16] is still not satisfactory
enough in the cases where the magnitude of noise is high and
the frequency range of the input is board. Moreover, TD [16]
and its predecessors produce signicant overshoot during the
convergence.
&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Some variable gain techniques can be applied for improv-
ing the performance of Levant and his colleagues&apos; tracking
differentiators. For example, in [17], a method of constructing
adaptive variable gains is presented. Although the method
improves the tracking performance, but the variable gains
are constructed based on the input signal model, which can-
not be always obtained in advance. As another example,
in [18][21], state-norm observer based adaptive variable
gain techniques are introduced for improving tracking per-
formance. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;However, the construction of state-norm observer
requires lower and upper bounds for the parameters of the
system dynamic model as well as the noise source.
This article presents a new model-free variable gain sliding
mode tracking differentiator for derivative estimation of noisy
signals (new TD), which is an improvement of TD [16].
Concretely, different from TD [16], the new TD employs
an additional variable that contributes overshoot reduction.
In addition, the new TD adaptively changes its gains for
improving the tracking and ltering performances. Moreover,
the new TD only uses previous output values, and it does not
require input signal model in advance. 
&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Robust Exact Differentiator</title>
   <link href="http://localhost:4000/2023/03/16/robust-exact-differentiator"/>
   <updated>2023-03-16T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/16/robust-exact-differentiator</id>
   <content type="html">&lt;p&gt;A robust exact differentiator is a type of differentiation algorithm that provides an exact estimate of the derivative of a signal, while being robust to noise and outliers in the signal.&lt;/p&gt;

&lt;p&gt;The basic idea behind a robust exact differentiator is to estimate the derivative of a signal by fitting a polynomial curve to the signal, and then differentiating the polynomial function. The order of the polynomial is chosen to match the degree of smoothness of the signal. For example, if the signal is a smooth curve, a low-order polynomial (such as a quadratic or cubic polynomial) may be used. If the signal has sharp edges or corners, a higher-order polynomial may be used.&lt;/p&gt;

&lt;p&gt;The robustness of the algorithm comes from the use of a robust regression technique to fit the polynomial curve to the signal. Unlike ordinary least squares regression, which is sensitive to outliers, robust regression techniques are designed to downweight the influence of outliers on the fitting process, thus producing more accurate estimates of the underlying curve.&lt;/p&gt;

&lt;p&gt;Examples of robust regression techniques that can be used for robust exact differentiation include the Huber loss function, the Tukey loss function, and the least trimmed squares method.&lt;/p&gt;

&lt;p&gt;Overall, the robust exact differentiator is a powerful tool for accurately estimating the derivative of a signal in the presence of noise and outliers. However, it is computationally more expensive than some other differentiation techniques and requires careful selection of the polynomial order and regression technique to match the properties of the signal being analyzed.&lt;/p&gt;

&lt;h2 id=&quot;mathematical-description&quot;&gt;Mathematical Description:&lt;/h2&gt;

&lt;p&gt;Let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; be the input signal, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; be the time vector corresponding to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;. We wish to estimate the first derivative of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; at each time point. We can do this by fitting a polynomial curve to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; and then differentiating the polynomial function.&lt;/p&gt;

&lt;p&gt;The general approach for a robust exact differentiator is as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Choose a polynomial order &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; based on the degree of smoothness of the signal. A low-order polynomial (e.g., quadratic or cubic) may be appropriate for a smooth signal, while a higher-order polynomial may be needed for a signal with sharp edges or corners.&lt;/li&gt;
  &lt;li&gt;Use a robust regression technique (e.g., Huber loss, Tukey loss, least trimmed squares) to fit the polynomial curve to the signal.&lt;/li&gt;
  &lt;li&gt;Differentiate the polynomial function to obtain the estimated derivative of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is some example Python code that implements a robust exact differentiator using the Huber loss function:&lt;/p&gt;

&lt;p&gt;```python
import numpy as np
from scipy.signal import savgol_filter
from scipy.interpolate import CubicSpline&lt;/p&gt;

&lt;p&gt;def robust_differentiator(x, t, n, alpha):
    # Apply Savitzky-Golay filter to smooth the signal
    x_filtered = savgol_filter(x, 2*n+1, n)&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Fit a polynomial to the filtered signal using the Huber loss function
poly_coeffs = np.polynomial.polynomial.polyfit(t, x_filtered, n)
poly_func = np.polynomial.polynomial.Polynomial(poly_coeffs)
residual = x_filtered - poly_func(t)
w = np.sqrt(np.maximum(1 - (residual/alpha)**2, 0))
robust_poly_coeffs = np.polynomial.polynomial.polyfit(t, x_filtered, n, w=w)

# Differentiate the polynomial to obtain the estimated derivative
poly_deriv = np.polynomial.polynomial.Polynomial(robust_poly_coeffs).deriv()
x_deriv = poly_deriv(t)

# Interpolate the derivative to the original time points
cs = CubicSpline(t, x_deriv)
x_deriv_interp = cs(t)

return x_deriv_interp
```
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Tracking Differentiator</title>
   <link href="http://localhost:4000/2023/03/15/tracking-differentiator"/>
   <updated>2023-03-15T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/15/tracking-differentiator</id>
   <content type="html">&lt;p&gt;A tracking differentiator is a signal processing technique that can be used to estimate the first derivative of a signal. It is a type of filter that emphasizes the high-frequency components of a signal, which are typically associated with changes or transitions in the signal.&lt;/p&gt;

&lt;p&gt;The tracking differentiator is a type of infinite impulse response (IIR) filter, which means that its output depends on both its input and its previous outputs. The transfer function of a tracking differentiator is given by:&lt;/p&gt;

&lt;p&gt;H(s) = s / (s + a)&lt;/p&gt;

&lt;p&gt;where s is the Laplace variable and a is a constant that determines the corner frequency of the filter. The higher the value of a, the lower the corner frequency and the more low-frequency components are attenuated.&lt;/p&gt;

&lt;p&gt;To use the tracking differentiator to estimate the first derivative of a signal, we can apply it to the signals time-domain representation. Let x(t) be the input signal and y(t) be the output of the tracking differentiator. Then, we have:&lt;/p&gt;

&lt;p&gt;y(t) = x(t) - x(t-1) + a*y(t-1)&lt;/p&gt;

&lt;p&gt;where the first term on the right-hand side represents the current value of the signal, the second term represents its previous value, and the third term represents a feedback loop that updates the output based on its previous value.&lt;/p&gt;

&lt;p&gt;Taking the derivative of y(t) with respect to time, we get:&lt;/p&gt;

&lt;p&gt;dy(t)/dt = dx(t)/dt - dx(t-1)/dt + a*dy(t-1)/dt&lt;/p&gt;

&lt;p&gt;which is an estimate of the first derivative of x(t) at time t.&lt;/p&gt;

&lt;p&gt;In practice, the value of a can be adjusted to optimize the performance of the tracking differentiator for a specific signal or application. The tracking differentiator is commonly used in applications such as speech recognition, where it can help to identify the transitions between different phonemes or words in a spoken sentence.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def differentiate(x, dt):
    &quot;&quot;&quot;
    Computes the first derivative of a 1D signal x using the tracking differentiator algorithm.

    :param x: 1D signal to differentiate
    :param dt: time interval between samples in seconds
    :return: first derivative of x
    &quot;&quot;&quot;

    dx = np.zeros_like(x)

    # Initial conditions
    xk = x[0]
    xk_prev = xk
    yk = 0
    yk_prev = yk

    # Compute the first derivative for each sample
    for k in range(1, len(x)):
        xk = x[k]
        yk = (2 * dt * xk - 2 * dt * xk_prev + 2 * yk_prev) / (2 * dt)
        dx[k] = yk
        xk_prev = xk
        yk_prev = yk

    return dx

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;differentiate&lt;/code&gt; function takes in a 1D signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; and the time interval between samples &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dt&lt;/code&gt;. It returns the first derivative of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; using the tracking differentiator algorithm. The algorithm computes the first derivative for each sample using the previous sample and derivative values, and the current sample value.&lt;/p&gt;

&lt;p&gt;The algorithm is based on the following equation:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dy/dt = (2 * x_k - 2 * x_(k-1) + 2 * y_(k-1)) / (2 * dt)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_k&lt;/code&gt; is the current sample value, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_(k-1)&lt;/code&gt; is the previous sample value, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_(k-1)&lt;/code&gt; is the previous derivative value, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dt&lt;/code&gt; is the time interval between samples.&lt;/p&gt;

&lt;p&gt;The algorithm initializes the initial conditions for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xk&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xk_prev&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yk&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yk_prev&lt;/code&gt; to the first sample value and zero. It then iterates over each sample, computing the first derivative using the current sample value and previous sample and derivative values. The algorithm updates the previous sample and derivative values for the next iteration.&lt;/p&gt;

&lt;p&gt;Note that this implementation assumes that the signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; is uniformly sampled with a constant time interval &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dt&lt;/code&gt;. If the time interval is not constant, the algorithm may not produce accurate results.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Sliding Mode Tracking Differentiator</title>
   <link href="http://localhost:4000/2023/03/14/sliding-mode-tracking-differentiator"/>
   <updated>2023-03-14T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/14/sliding-mode-tracking-differentiator</id>
   <content type="html">&lt;p&gt;Sliding mode tracking differentiators are a type of differentiation algorithm that provides an estimate of the derivative of a signal by tracking the sliding mode of a sliding mode observer. Sliding mode observers are a class of observers that are designed to track the sliding motion of a system, which occurs when the system is on the boundary between two different modes of operation.&lt;/p&gt;

&lt;p&gt;The basic idea behind sliding mode tracking differentiators is to use a sliding mode observer to track the sliding motion of the signal, and then use the observers output to estimate the derivative of the signal. The sliding mode observer consists of a dynamic system that is designed to track the sliding motion of the signal, and a switching function that determines when the system enters the sliding mode.&lt;/p&gt;

&lt;p&gt;Sliding mode tracking differentiators have several advantages over other differentiation techniques. They are robust to noise and disturbances in the signal, and can handle signals with variable frequency and amplitude. They are also computationally efficient and do not require knowledge of the system dynamics.&lt;/p&gt;

&lt;p&gt;However, sliding mode tracking differentiators can be sensitive to modeling errors and require careful tuning of the observer parameters to ensure accurate differentiation. They also introduce high-frequency noise into the estimated derivative, which can be problematic for some applications.&lt;/p&gt;

&lt;p&gt;Overall, sliding mode tracking differentiators are a powerful tool for estimating the derivative of a signal in real-time, and are commonly used in control and signal processing applications.&lt;/p&gt;

&lt;h2 id=&quot;mathematical-description&quot;&gt;Mathematical Description:&lt;/h2&gt;

&lt;p&gt;Let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; be the input signal, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; be the time vector corresponding to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;. We wish to estimate the first derivative of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; at each time point. The basic idea behind sliding mode tracking differentiators is to use a sliding mode observer to track the sliding motion of the signal, and then use the observers output to estimate the derivative of the signal.&lt;/p&gt;

&lt;p&gt;The sliding mode observer consists of a dynamic system and a switching function. The dynamic system is defined by a set of differential equations, and is designed to track the sliding motion of the signal. The switching function is a scalar function that determines when the system enters the sliding mode. When the system is in the sliding mode, the sliding mode observer output is used to estimate the derivative of the signal.&lt;/p&gt;

&lt;p&gt;The basic steps to implement a sliding mode tracking differentiator are as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Define the dynamic system for the sliding mode observer, which depends on the specific application and signal being differentiated.&lt;/li&gt;
  &lt;li&gt;Choose a switching function that determines when the system enters the sliding mode. This function should be designed to track the sliding motion of the signal and be robust to noise and disturbances.&lt;/li&gt;
  &lt;li&gt;Use the sliding mode observer output to estimate the derivative of the signal.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is some example Python code that implements a sliding mode tracking differentiator:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lfilter&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sliding_mode_differentiator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the sliding mode observer output
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dxdt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dxdt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute the sliding mode observer dynamics
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dxdt_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Estimate the derivative of the signal
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x_dot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dxdt_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lfilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_dot&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this implementation, the sliding mode observer dynamics are computed using a first-order low-pass filter, and the sliding mode observer output is computed using a high-pass filter. The parameters &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpha&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;beta&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gamma&lt;/code&gt; control the behavior of the sliding mode observer and should be chosen based on the specific application and signal being differentiated.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Low rank plus sparse decomposition</title>
   <link href="http://localhost:4000/2023/03/13/lsd"/>
   <updated>2023-03-13T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/13/LSD</id>
   <content type="html">&lt;p&gt;Low-rank and sparse decomposition is a technique used in signal processing, image processing, and machine learning to decompose a matrix into two components: a low-rank component and a sparse component.&lt;/p&gt;

&lt;p&gt;A matrix is said to be low-rank if it can be approximated by a matrix of much lower rank. For example, a rank-10 matrix can be approximated by a rank-3 matrix if the approximation is good enough. A matrix is said to be sparse if most of its elements are zero.&lt;/p&gt;

&lt;p&gt;The low-rank and sparse decomposition technique seeks to find a low-rank matrix L and a sparse matrix S such that the sum of L and S is equal to the original matrix M. This can be expressed as:&lt;/p&gt;

&lt;p&gt;M = L + S&lt;/p&gt;

&lt;p&gt;The low-rank component L represents the underlying structure or pattern in the data, while the sparse component S represents the noise or outliers in the data.&lt;/p&gt;

&lt;p&gt;This technique has many applications, such as in image denoising, video compression, and anomaly detection. It is often used in combination with other techniques such as principal component analysis (PCA) and singular value decomposition (SVD) to extract meaningful information from complex data sets.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Let us consider the problem of the enhancement of a speech signal contaminated by an independent additive noise. Let $x(t)$ and $d(t)$ denote the sampled clean speech and noise signal, respectively. The observed noisy speech signal $y(t)$ is
\(y(t)=x(t)+d(t)\)
Suppose $y(t)$ was framed with the length $N$. Arranging the $N$-dimensional vectors into a $(M-1+l) \times l$ Toeplitz structure matrix, we can get
\(Y=X+D\)
Assuming that the rank of matrix $Y$ is $r$, the optimal enhanced speech matrix $\hat{X}$ can be estimated according to the following least-square criterion
\(\min _{\hat{X}}\|Y-\hat{X}\|_F^2, \operatorname{rank}(\hat{X}) \leq r\)
where symbol $|&lt;em&gt;F$ denotes the Frobenius norm of a matrix and $|X|_F=\sqrt{X&lt;/em&gt;{i j}^2}$&lt;/p&gt;

&lt;p&gt;If $d(t)$ is a white Gaussian noise, it satisfies the conditions $D^T D=\sigma_d^2 I$ and $X^T D=0$. Where $\sigma_d^2$ is the variance of noise. The optimal solution of (4) can be obtained by applying singular value decomposition (SVD) of $Y$.
\(\begin{aligned}
&amp;amp; Y=U \Sigma V^T \\
&amp;amp; \hat{X}=\sum_{i=1}^r \lambda_i U_i V_i^T .
\end{aligned}\)
Here, $U$ and $V$ are two orthogonal matrices holding the left and right (approximate) singular vectors of given matrix, and $\Lambda$ is a diagonal matrix holding the singular values: $\lambda_1 \geq \lambda_2 \geq \cdots \lambda_{r-1} \geq \lambda_r$.&lt;/p&gt;

&lt;p&gt;The above low-rank matrix $\hat{X}$ represents the original speech matrix $\mathrm{X}$ in the sense of least-square minimization. This may get the optimal estimate when the noise is small, independent, and identically distributed Gaussian.&lt;/p&gt;

&lt;p&gt;However, PCA is highly sensitive to the presence of large corruptions. Even a single outlier in the data matrix can render the estimation of the low-rank component arbitrarily far from the true model. In [16], a new theory called Robust PCA was developed for this shortcoming. The basic idea of Robust PCA is to decompose the data matrix $M$ as $M=L+S$, where $S \hat{\mathrm{I}} \mathrm{i}^{N K}$ is a sparse matrix with a sparse number of non-zero coefficients with arbitrarily large magnitude. RPCA can be solved by minimizing the following convex program
\(\min \|L\|_*+\lambda\|S\|_1 \text {, s.t. } M=L+S\)
where $|-|_*$ denotes the matrix nuclear norm, which is defined as the sum of all singular values and is suggested as a convex surrogate to the rank function [18]. ||$_1$ denotes the $l_1$-norm of a matrix, which is defined as the sum of the absolute values of matrix elements. This problem is known to have a stable solution provided $L$ and $S$ are sufficiently incoherent [19], i. e., the low-rank matrix is not sparse and the sparse matrix is not low-rank. More recently, RPCA theory was introduced into the s peech enhancement task in [20], where a constrained low-rank and sparse matrix decomposition (CLSMD) algorithm is designed for noise reduction.&lt;/p&gt;

&lt;h3 id=&quot;lsd-based-speech-denoising-method&quot;&gt;LSD based speech denoising method&lt;/h3&gt;

&lt;p&gt;In this work, we propose a new subspace decomposition algorithm based on the LSD, which is less sensitive to the large noise interferences.&lt;/p&gt;

&lt;p&gt;Firstly, we formulate the speech enhancement problem as the following optimization problem,
\(\begin{aligned}
&amp;amp; \min _{\mathrm{L}, \mathrm{S}}\|Y-L-S\|_F^2, \\
&amp;amp; \text { s.t. } \operatorname{rank}(L) \leq r,|S|_0 \leq h .
\end{aligned}\)
The above formula can be solved by alternatively solving the following two formulas until convergence
\(\left\{\begin{array}{l}
L_i=\underset{\operatorname{rank}(L) \leq r}{\arg \min }\left\|Y-L-S_{i-1}\right\|_F^2 \\
S_i=\underset{\mid S b \leq h}{\arg \min }\left\|Y-L_i-S\right\|_F^2
\end{array}\right.\)
Given an estimate of sparse matrix $S_{i-1}$, the minimization in (7-a) over $L$ is to learn a rank- $r$ low-rank matrix from partial observations. This is a fixed-rank approximation problem, we can solve it use bilateral random projections (BRP) based fast low-rank matrix approximation.
\(L_t=M_1\left(A_2^T M_1\right)^{-1} M_2^T\)
Where $M_1=Y A_1, M_2=Y^T A_2$. Both $A_1 \in R^{n \times r}$ and $A_2 \in R^{m \times r}$ are Gaussian random matrices.&lt;/p&gt;

&lt;p&gt;The minimization in (7-b) over $S$ is to learn a sparse matrix from partial observations. This can be computed via entry-wise hard thresholding function [21], $\varphi_T(x)=x \cdot 1(|x|&amp;gt;u)$
which keeps the input if it is larger than the threshold; otherwise, it is set to zero. In summary, we have following optimization algorithm for LSD.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Signal Subspace low rank plus sparse decomposition</title>
   <link href="http://localhost:4000/2023/03/12/signal-subspace-low-rank-plus-sparse-decomposition"/>
   <updated>2023-03-12T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/12/Signal-Subspace-Low-rank-Plus-Sparse-Decomposition</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In this paper, a new subspace speech enhancement method using low-rank and sparse decomposition is
presented. In the proposed method, we firstly structure the corrupted data as a Toeplitz matrix and estimate its effective
rank for the underlying human speech signal. Then the low-rank and sparse decomposition is performed with the
guidance of speech rank value to remove the noise. Extensive experiments have been carried out in white Gaussian
noise condition, and experimental results show the proposed method performs better than conventional speech
enhancement methods, in terms of yielding less residual noise and lower speech distortion.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In this paper, we propose a new subspace-based method
for speech enhancement based on the principle of low-rank
and sparse decomposition (LSD). The main idea behind our
method is motivated by the recent development of lowrank
and sparse theory [16]. According to this theory, if a
given corrupted data matrix Y has an underlying low-rank
structure, yet corrupted by sparse additive noises. The
underlying low-rank component L can be effectively
recovered by solving a convex optimization problem, even
if the noise is arbitrary in magnitude. In the time domain,
owing to the short-time stability of human speech, speech
signals can be assumed to have a low-rank structure. On
the other hand, due to the randomness of noise, background
noise is more variable and thus can be viewed as sparse and
high-rank. Thus LSD theory can be exploited to recover the
underlying speech from corrupted speech signals.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Signal Enhancement</title>
   <link href="http://localhost:4000/2023/03/11/signal-enhancement"/>
   <updated>2023-03-11T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/11/signal-enhancement</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Speech enhancement refers to the improvement in quality
and intelligibility of noise corrupted speech signals by
using supervised or unsupervised speech enhancement
methods. It is widely used as a pre-processing block in a lot
of applications like automatic speech recognizer and other
communication systems.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Over the last fifty decades, many algorithms have been
proposed about for speech enhancement. The typical
algorithms including spectral subtraction[1], minimum
mean square error (MMSE) estimation [2-4], Wiener
filtering [5-8], and subspace methods [9-13]. Spectral
Subtraction and Wiener filtering have been widely used for
enhancing speech because of their simplicity and ease of
implementation in single channel systems but they suffer
from the production of musical noise after enhancement
and is one of their major drawbacks. Signal subspace
approach [9-13], have shown to give a better compromise
between less residual noise and signal distortion of the
output signal, compared to the other existing techniques.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>SSA and its variants</title>
   <link href="http://localhost:4000/2023/03/10/ssa-and-its-variants"/>
   <updated>2023-03-10T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/10/SSA-and-its-variants</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Singular Spectrum Analysis (SSA) has proven to be a flexible
method for the analysis of time-series data. Applications are
reported in diverse areas such as climate change and geophysical
phenomena [13], mineral processing [4] and telecommunication
applications [5,6]. The basic SSA method has been combined with
the maximum entropy method (MEM) [7] and with multi-taper
methods [8] to enhance the spectral analysis of data. Extensions to
cope with missing data [9] and multi-scale applications have also
been developed [10].&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The basic elements of SSA were first reported in [11,12].
Widespread use of SSA followed a series of papers by Vautard
and Ghil [2] and Vautard et al. [3]. The monograph by Golyandina
et al. [13] describes the basic algorithm plus a number of variations.&lt;/p&gt;

&lt;h2 id=&quot;basic-ssa-and-some-variations&quot;&gt;Basic SSA and some variations&lt;/h2&gt;

&lt;h3 id=&quot;basic-ssa-algorithm&quot;&gt;Basic SSA algorithm&lt;/h3&gt;

&lt;p&gt;The basic SSA algorithm consists of the following steps.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Choose an embedded dimension $K$ and define $L=N+1-K$, where $N$ is the number of observations in the time series.&lt;/li&gt;
  &lt;li&gt;Form the $L \times K$ Hankel matrix $\boldsymbol{A}$ using mean-corrected data, $y_t, t=1,2, \ldots, N$.
\(\begin{aligned}
\boldsymbol{A} &amp;amp; =\left[\boldsymbol{y}_1, \boldsymbol{y}_2, \boldsymbol{y}_3, \ldots, \boldsymbol{y}_K\right] \\
&amp;amp; =\left[\begin{array}{cccccc}
y_1 &amp;amp; y_2 &amp;amp; y_3 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; y_K \\
y_2 &amp;amp; y_3 &amp;amp; y_4 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; y_{K+1} \\
y_3 &amp;amp; y_4 &amp;amp; y_5 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; y_{K+2} \\
\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; &amp;amp; &amp;amp; \vdots \\
y_L &amp;amp; y_{L+1} &amp;amp; y_{L+2} &amp;amp; \cdots &amp;amp; \cdots &amp;amp; y_{K+L-1}
\end{array}\right]
\end{aligned}\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;where $\boldsymbol{y}&lt;em&gt;i=\left(y_i, y&lt;/em&gt;{i+1}, \ldots, y_{i+\mathrm{L}-1}\right)^T$. This matrix $\boldsymbol{A}$ is often referred to as the trajectory matrix. In most applications of SSA, $L&amp;gt;K[2,13]$&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Determine the eigenvalues and eigenvectors of $A^T A$. Denote the eigenvalues by $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_K \geq 0$. For each eigenvalue $\lambda_i$ there is a corresponding eigenvector $v_i$.
\(\left(A^T A\right) v_i=\lambda_i v_i\)&lt;/li&gt;
  &lt;li&gt;Define $K$ new series, $\boldsymbol{w}_i=A v_i, i=1,2, \ldots, K$. Each series is of length $L$. Once the new series are constructed, the analysis then focuses on the new series, which are sometimes referred to as the latent variables. The individual series may be analyzed, or subsets may be grouped together.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The utility of the method is derived from the following properties and interpretations of the eigenvalue analysis:&lt;/p&gt;

&lt;p&gt;(a) The eigenvectors $v_i$ are orthonormal, i.e., $v_i^T v_j=0(i \neq j)$ and $\boldsymbol{v}_i^T \boldsymbol{v}_i=1$.
(b) The latent variables $w_i$ are orthogonal, and
\(\begin{aligned}
\left\|\boldsymbol{w}_i\right\|^2 &amp;amp; =\boldsymbol{w}_i^T \boldsymbol{w}_i=\left(\boldsymbol{A} \boldsymbol{v}_i\right)^T A \boldsymbol{v}_i=\boldsymbol{v}_i^{\mathrm{T}}\left(A^T A\right) v_i \\
&amp;amp; =\boldsymbol{v}_i^T \lambda_i v_i=\lambda_{\mathrm{i}} .
\end{aligned}\)
(c) Consequently,
\(\sum_{i=1}^K \boldsymbol{w}_i^T \boldsymbol{w}_i=\sum_{i=1}^K \boldsymbol{w}_i^T \sum_{i=1}^K \boldsymbol{w}_i=\sum_{i=1}^K \lambda_i .\)
Often, the interesting features of a time series are found by analyzing the first few latent variables. A number of methods have been proposed to choose the number of latent variables for analysis. Most often, the construction of a scree plot [18], which is a plot of $\lambda_i$ versus $i$, will indicate a knee or bend. This can be used to select the number of latent variables. Other methods have been proposed when the break points are not clear [19].&lt;/p&gt;

&lt;p&gt;Scree plots are also useful for identifying harmonics in the data. As discussed in $[2,12,14]$, if $N$ and $L$ are large enough, each harmonic results in two eigenvalues that are closely paired for a purely harmonic series. A harmonic component may produce a periodic component in the autocorrelation and partial autocorrelation function. However, the number of periodic components cannot be easily extracted from these functions. In addition, a slowly decreasing sequence of eigenvalues can be produced by a pure noise series $[13,14]$. These two observations suggest that a break or knee in the scree plot can be used to separate the signals that arise from harmonics and signals from noise or aperiodic components [13].&lt;/p&gt;

&lt;p&gt;The eigenvalues of $A^T A$ are most often calculated by undertaking a singular value decomposition (SVD) of $A$. The right singular vectors of $A$ are identical with the eigenvectors of $A^T A$ and the eigenvalues of this latter matrix are the squares of the corresponding singular values of $\boldsymbol{A}[13]$.&lt;/p&gt;

&lt;h3 id=&quot;variation-toeplitz-approximation-to-at-a&quot;&gt;Variation: Toeplitz approximation to $A^T A$&lt;/h3&gt;

&lt;p&gt;$A^T A$ is symmetric and positive semi-definite. It can be written as
\(A^T A=\left[\begin{array}{cccc}
y_1^T y_1 &amp;amp; y_1^T y_2 &amp;amp; \cdots &amp;amp; y_1^T y_K \\
y_2^T y_1 &amp;amp; y_2^T y_2 &amp;amp; \cdots &amp;amp; y_2^T y_K \\
\vdots &amp;amp; \vdots &amp;amp; &amp;amp; \vdots \\
y_K^T y_1 &amp;amp; y_K^T y_2 &amp;amp; \cdots &amp;amp; y_K^T y_K
\end{array}\right] \text {. }\)
In situations when $L \gg K$, we have \(\begin{aligned}
&amp;amp; \frac{1}{L} \boldsymbol{y}_1^T \boldsymbol{y}_1 \simeq \frac{1}{L} \boldsymbol{y}_2^T \boldsymbol{y}_2 \simeq \frac{1}{L} y_3^T y_3 \simeq \cdots \simeq \frac{1}{L} y_K^T y_K \simeq \frac{1}{N} \sum_{t=1}^N y_t^2=c_0 \\
&amp;amp; \frac{1}{L} \boldsymbol{y}_1^T \boldsymbol{y}_2 \simeq \frac{1}{L} y_2^T \boldsymbol{y}_3 \simeq \cdots \simeq \frac{1}{L} y_{K-1}^T y_K \simeq \frac{1}{N-1} \sum_{t=1}^{N-1} y_t y_{t-1}=c_1 \\
&amp;amp; \vdots \\
&amp;amp; \frac{1}{L} \boldsymbol{y}_1^T \boldsymbol{y}_K=\frac{1}{L} \sum_{t=1}^L y_t y_{t-(K-1)}=c_{K-1}
\end{aligned}\)
where $c_i$ is the sample autocovariance at lag $i$ (we have previously assumed that the data have been mean corrected). Consequently
\(\frac{A^{\mathbf{T}} A}{L} \simeq \boldsymbol{C}=\left[\begin{array}{cccc}
c_0 &amp;amp; c_1 &amp;amp; \cdots &amp;amp; c_{K-1} \\
c_1 &amp;amp; c_0 &amp;amp; \cdots &amp;amp; c_{K-2} \\
\vdots &amp;amp; \vdots &amp;amp; &amp;amp; \vdots \\
c_{K-1} &amp;amp; c_{K-2} &amp;amp; \cdots &amp;amp; c_0
\end{array}\right]\)
where $C$ is the sample covariance matrix of the observations. The sample autocorrelation matrix $R=C / c_0$ is often used instead of $C$ for analysis. This is appropriate when the data have been centered and normalized $[12,20]$.&lt;/p&gt;

&lt;h3 id=&quot;variation-hankel-approximation-and-diagonal-averaging&quot;&gt;Variation: Hankel approximation and diagonal averaging&lt;/h3&gt;

&lt;p&gt;A singular value decomposition of the matrix is undertaken
\(\boldsymbol{A}=\sum_{i=1}^\mu \boldsymbol{X}_i=\sum_{i=1}^\mu \sqrt{\lambda_i} \boldsymbol{u}_i \boldsymbol{v}_i^T\)
where $\mu=\min (L, K), \lambda_i$ and $v_i$ are the eigenvalues and eigenvectors of $A^T A$ as described in Eq. (1), and $\boldsymbol{u}_i$ are the eigenvectors of $A A^T$, i.e., the solution to $[21]$
\(\left(\boldsymbol{A} \boldsymbol{A}^{\boldsymbol{T}}\right) \boldsymbol{u}_i=\lambda_i \boldsymbol{u}_i\)
The orthogonal vectors $\boldsymbol{u}_i$ and $\boldsymbol{v}_i$ are related by
\(A v_i=\sqrt{\lambda_i} \boldsymbol{u}_i, \quad i=1,2, \ldots, \mu\)
where the singular values of $A$ are $\sqrt{\lambda_i}$, i.e., the square root of the eigenvalues of $A^T A$. Clearly, $u_i=w_i / \sqrt{\lambda_i}$.&lt;/p&gt;

&lt;p&gt;Each of the $X_i$ in Eq. (4) is of rank 1 . A new series $x_i$ of length $N$ is reconstructed by averaging each of the $N$ anti-diagonals in $X_i$. Attention is then focused on the new series $x_i$, or groupings of these series. Guidelines for grouping of variables are typically based on the clustering and separation of the eigenvalues. A separability index has been proposed in [14] to assist with grouping.&lt;/p&gt;

&lt;p&gt;This diagonal averaging is computationally equivalent to calculating $x_i$ using [22]
\(\boldsymbol{x}_i=\mathbf{D}^{-1} W_i v_i\)
where&lt;/p&gt;

&lt;p&gt;\(W_i=\left(\begin{array}{cccccc}
w_1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; \cdots &amp;amp; 0 \\
w_2 &amp;amp; w_1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; 0 \\
w_3 &amp;amp; w_2 &amp;amp; w_1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\
\vdots &amp;amp; &amp;amp; \vdots &amp;amp; \vdots &amp;amp; &amp;amp; \vdots \\
w_{K-1} &amp;amp; \cdots &amp;amp; w_3 &amp;amp; w_2 &amp;amp; w_1 &amp;amp; 0 \\
w_K &amp;amp; \cdots &amp;amp; \cdots &amp;amp; w_3 &amp;amp; w_2 &amp;amp; w_1 \\
w_{K+1} &amp;amp; \cdots &amp;amp; \cdots &amp;amp; \cdots &amp;amp; w_3 &amp;amp; w_2 \\
\vdots &amp;amp; &amp;amp; &amp;amp; &amp;amp; &amp;amp; \vdots \\
w_{\mathrm{L}-1} &amp;amp; w_{\mathrm{L}-2} &amp;amp; \cdots &amp;amp; \cdots &amp;amp; \cdots &amp;amp; w_{\mathrm{L}-K} \\
w_{\mathrm{L}} &amp;amp; w_{\mathrm{L}-1} &amp;amp; w_{\mathrm{L}-2} &amp;amp; \cdots &amp;amp; \cdots &amp;amp; w_{\mathrm{L}-K+1} \\
0 &amp;amp; w_{\mathrm{L}} &amp;amp; w_{\mathrm{L}-1} &amp;amp; w_{\mathrm{L}-2} &amp;amp; \cdots &amp;amp; w_{\mathrm{L}-K+2} \\
\vdots &amp;amp; &amp;amp; \vdots &amp;amp; \vdots &amp;amp; &amp;amp; \vdots \\
0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; w_{\mathrm{L}} &amp;amp; w_{\mathrm{L}-1} &amp;amp; w_{\mathrm{L}-2} \\
0 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; 0 &amp;amp; w_{\mathrm{L}} &amp;amp; w_{\mathrm{L}-1} \\
0 &amp;amp; \cdots &amp;amp; \cdots &amp;amp; \cdots &amp;amp; 0 &amp;amp; w_{\mathrm{L}}
\end{array}\right)\)
and $D$ is an $N \times N$ diagonal matrix, whose diagonal elements are
$\left(\begin{array}{lllllllllll}1 &amp;amp; 2 &amp;amp; \cdots &amp;amp; \mu-1 &amp;amp; \mu &amp;amp; \cdots &amp;amp; \mu &amp;amp; \mu-1 &amp;amp; \cdots &amp;amp; 2 &amp;amp; 1\end{array}\right)$
and $\boldsymbol{w}_i=\left(\begin{array}{llll}w_1 &amp;amp; w_2 &amp;amp; \cdots &amp;amp; w_L\end{array}\right)^T=A \boldsymbol{v}_i$, and $\boldsymbol{v}_i$ is one of the eigenvectors. To simplify the nomenclature, double subscripting on $w_i$ has been avoided. It is understood that the elements of this vector depend upon the specific eigenvector used in the reconstruction.
Recall that $N=L+K-1$ and $\mu=\min (L, K)=K$ in most SSA applications. Then there are $N-2(K-1)=2 L-N$ complete rows with diagonal elements $\mu$ in $D$. The matrix $W_i$ is of dimension $N \times K$. The first and last $K-1$ rows are incomplete, which leaves $N-2(K-1)$ complete rows.&lt;/p&gt;

&lt;p&gt;The latent variables $w_i$ are orthogonal, and have squared norm $\left|w_i\right|_2^2=\lambda_i$. The squared norm of a reconstructed series using diagonal averaging is
\(\begin{aligned}
\left\|\boldsymbol{x}_i\right\|_2^2 &amp;amp; =\left\|\boldsymbol{D}^{-1} \boldsymbol{W}_i \boldsymbol{v}_i\right\|_2^2 \\
&amp;amp; \leq\left\|D^{-1}\right\|_2^2 \cdot \operatorname{trace}\left(\boldsymbol{W}_i^{\mathrm{T}} \boldsymbol{W}_i\right) \\
&amp;amp; =K\left\|\boldsymbol{D}^{-1}\right\|_2^2 \cdot\left\|\boldsymbol{w}_i\right\|_2^2 \\
&amp;amp; =K \lambda_i\left\|D^{-1}\right\|_2^2 \\
&amp;amp; =\frac{K \lambda_i}{2\left(1+1 / 4+1 / 9+\cdots 1 /(K-1)^2\right)+(2 L-N) / K^2} \\
&amp;amp; \simeq \frac{K}{\pi^2 / 3+(2 L-N) / K^2} \lambda_i, \quad L \gg K
\end{aligned}\)
and
\(\left\|\sum_{i=1}^d \boldsymbol{x}_i\right\|_2^2 \neq \sum_{i=1}^d\left\|\boldsymbol{x}_i\right\|_2^2 \text {. }\)
Calculations indicate that the upper bound may be quite conservative. The reconstructed series $\boldsymbol{x}_i$ are not orthogonal making it impossible to calculate the variance of grouped variables from the variance of the individual reconstructed series.&lt;/p&gt;

&lt;p&gt;The use of reduced-rank approximations to assist in the extraction of harmonic signals from additive noise has been considered extensively in the signal processing literature. The trajectory matrix has a central role in these algorithms. Extensive research indicates that extraction of these signals is considerably enhanced when the trajectory matrix is replaced by a structured low-rank approximation.&lt;/p&gt;

&lt;p&gt;The SVD leads to an unstructured approximation, because the $X_i$ are not Hankel. A structured approximation is obtained when the trajectory matrix is calculated using the reconstructed series (or groupings of variables). While the SVD does not preserve the Hankel structure, the Hankel matrix constructed from the reconstructed series does not preserve the rank property. Cadzow developed a simple iterative algorithm to preserve both the rank and Hankel structure. He has shown that this iteration will converge to reduced-rank approximation that has the Hankel structure for certain classes of signals including sinusoids and damped sinusoids corrupted by white noise. The reconstruction of the $\boldsymbol{x}_i$ corresponds to one iteration of Cadzows algorithm. Other approaches for obtaining reduced-rank approximations with appropriate structure involve the use of structured total least squares. These methods are computationally intense, requiring the use of a nonlinear optimizer in high dimension.&lt;/p&gt;

&lt;h1 id=&quot;variants&quot;&gt;Variants&lt;/h1&gt;

&lt;p&gt;SSA, or Singular Spectrum Analysis, is a time-series analysis technique that decomposes a time series into several components, such as trend, seasonal, and noise. Here are some variants or extensions of SSA:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Multichannel SSA (M-SSA): This variant of SSA applies the decomposition to multivariate time series data, where each component is represented as a matrix.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ensemble SSA (ESSA): ESSA applies SSA to multiple time series data sets, with the goal of finding common patterns and extracting signals that are common across the ensemble.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spatial SSA (SpaSSA): This variant of SSA is used to analyze spatial data, such as satellite imagery or climate data, where each observation corresponds to a location in space.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Complex SSA (CSSA): CSSA is used to analyze complex-valued time series data, where the components can have both real and imaginary parts.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Local SSA (L-SSA): This approach applies SSA to a local region or window of a time series, instead of analyzing the entire time series. It can be useful for detecting local trends and patterns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multilevel SSA (ML-SSA): ML-SSA decomposes a time series into multiple levels, each with a different time scale, allowing for the detection of patterns at different scales.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nonlinear SSA (NSSA): This approach applies SSA to nonlinear time series data, which can exhibit complex patterns and behaviors.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These variants of SSA can be used in different applications, depending on the nature of the data and the research question.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Applicability of prewhitening to eliminate the influence of serial correlation on the Mann Kendall test</title>
   <link href="http://localhost:4000/2023/03/09/prewhitening-mann-kandall-test"/>
   <updated>2023-03-09T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/09/prewhitening-mann-kandall-test</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Prewhitening has been used to eliminate the influence of serial correlation on the Mann-
Kendall (MK) test in trend-detection studies of hydrological time series. However, its ability to
accomplish such a task has not been well documented. This study investigates this issue by Monte
Carlo simulation. Simulated time series consist of a linear trend and a lag 1 autoregressive (AR(1))
process with a noise. Simulation results demonstrate that when trend exists in a time series, the
effect of positive/negative serial correlation on the MK test is dependent upon sample size,
magnitude of serial correlation, and magnitude of trend. When sample size and magnitude of trend
are large enough, serial correlation no longer significantly affects the MK test statistics. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Removal of
positive AR(1) from time series by prewhitening will remove a portion of trend and hence reduces
the possibility of rejecting the null hypothesis while it might be false. Contrarily, removal of
negative AR(1) by prewhitening will inflate trend and leads to an increase in the possibility of
rejecting the null hypothesis while it might be true. Therefore, prewhitening is not suitable for
eliminating the effect of serial correlation on the MK test when trend exists within a time
series.
&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Adaptive Filtering</title>
   <link href="http://localhost:4000/2023/03/08/adaptive-filtering"/>
   <updated>2023-03-08T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/08/adaptive-filtering</id>
   <content type="html">&lt;p&gt;The adaptive filtering problem can be formulated mathematically as follows:&lt;/p&gt;

&lt;p&gt;Given an input signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x(n)&lt;/code&gt; and a desired signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d(n)&lt;/code&gt;, the goal is to find a filter with adaptive coefficients &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w(n)&lt;/code&gt; such that the output signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y(n) = w(n) * x(n)&lt;/code&gt; approximates the desired signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d(n)&lt;/code&gt;. The error signal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;e(n)&lt;/code&gt; is defined as the difference between the desired signal and the output signal, i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;e(n) = d(n) - y(n)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The adaptive filter updates its coefficients iteratively based on the error signal and the input signal using a suitable adaptation algorithm. The adaptation algorithm adjusts the filter coefficients in such a way that the error signal is minimized, either in a mean square sense or in some other sense depending on the problem at hand.&lt;/p&gt;

&lt;p&gt;The performance of the adaptive filter is usually measured by the mean square error (MSE) between the desired signal and the output signal, i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MSE = E[|e(n)|^2]&lt;/code&gt;, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;E[.]&lt;/code&gt; denotes the expectation operator.&lt;/p&gt;

&lt;p&gt;The choice of the adaptation algorithm depends on several factors, such as the complexity of the problem, the computational resources available, and the desired convergence rate and tracking ability. Some commonly used adaptation algorithms include the LMS algorithm, the RLS algorithm, and the Kalman filter.&lt;/p&gt;

&lt;p&gt;In summary, the adaptive filtering problem involves finding a filter with adaptive coefficients that can approximate a desired signal from an input signal, by iteratively adjusting its coefficients based on the error signal. The choice of the adaptation algorithm depends on the problem requirements and constraints.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>ON WHITENING FOR KRYLOV-PROPORTIONATE NORMALIZED LMS ALGORITHM</title>
   <link href="http://localhost:4000/2023/03/07/whitening-for-kpnlms-algorithm"/>
   <updated>2023-03-07T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/07/whitening-for-KPNLMS-algorithm</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;The tradeoffproblem between convergence speed and computational
complexity has been the most important and challenging issue in
adaptive filtering [1]. Since the birth of the classical least mean
square (LMS) algorithm, a variety ofalgorithms have been proposed,
such as the normalized LMS (NLMS) algorithm [2], the affine projection
algorithm (APA) [3,4], and the adaptive parallel subgradient
projection (PSP) algorithm [5].&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Recently, the Krylov-proportionate normalized least-meansquare
(KPNLMS) algorithm has been proposed [6], which extends
the well-known (sparsity-based) proportionate normalized leastmean-
square (PNLMS) algorithm [7, 8] to a nonsparse estimandum
(system to be estimated). Here, sparse means that most components
have negligibly small magnitudes. The KPNLMS algorithm
constructs a set of orthonormal basis vectors, with which the estimandum
has sparse coefficients, by using a certain Krylov subspace,
and utilizes the sparsity for raising the speed of convergence. The
gain offered by KPNLMS depends on the energy ofthe estimandum
in the Krylov subspace.&lt;/p&gt;

&lt;h2 id=&quot;preliminaries&quot;&gt;PRELIMINARIES&lt;/h2&gt;

&lt;h3 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h3&gt;

&lt;p&gt;We consider a simple linear system model:
\(d_k:=\boldsymbol{u}_k^T \boldsymbol{h}^*+n_k, k \in \mathbb{N}\)
where $u_k:=\left[u_k, u_{k-1}, \cdots, u_{k-N+1}\right]^T \in \mathbb{R}^N$ is the input vector at time $k$ with the input process $\left(u_k\right)&lt;em&gt;{k \in \mathbb{N}}, \boldsymbol{h}^* \in \mathbb{R}^N$ the estimandum, $\left(d_k\right)&lt;/em&gt;{k \in \mathbf{N}}$ the output process, and $\left(n_k\right)&lt;em&gt;{k \in \mathbf{N}}$ the noise process $\left(N \in \mathbb{N}^*:=\mathbb{N} \backslash{0}\right)$. Assume that the input and output data are available. An adaptive filter $\left(\boldsymbol{h}_k\right)&lt;/em&gt;{k \in \mathrm{N}}$ is controlled in a recursive way for minimizing the mean-square error (MSE):
\(\operatorname{MSE}(\boldsymbol{h}):=E\left\{e_k^2(\boldsymbol{h})\right\}, \boldsymbol{h} \in \mathbb{R}^N \text {. }\)
Here, $E{\cdot}$ denotes expectation and $e_k: \mathbb{R}^N \rightarrow \mathbb{R}, \boldsymbol{h} \mapsto \boldsymbol{u}&lt;em&gt;k^T \boldsymbol{h}-d_k$, the error function at time $k$. The filter $\boldsymbol{h}&lt;/em&gt;{\text {MMSE }} \in \mathbb{R}^N$ minimizing (2) is called the minimum MSE (MMSE) filter, characterized by the the so-called Wiener-Hopf equation: $\boldsymbol{R} \boldsymbol{h}&lt;em&gt;{\mathrm{MMSE}}=\boldsymbol{p}$, where $\boldsymbol{R}:=$ $E\left{\boldsymbol{u}_k \boldsymbol{u}_k^T\right} \in \mathbb{R}^{N \times N}$ and $\boldsymbol{p}:=E\left{\boldsymbol{u}_k d_k\right} \in \mathbb{R}^N$. The matrix $\boldsymbol{R}$ is mostly positive definite due to the presence of noise, and in this case, the MMSE filter is uniquely given by $\boldsymbol{h}&lt;/em&gt;{\mathrm{MMSE}}=\boldsymbol{R}^{-1} \boldsymbol{p}$. In the following, the MMSE filter is denoted by $\boldsymbol{h}^&lt;em&gt;$, because $\boldsymbol{h}_{\mathrm{MMSE}}=\boldsymbol{h}^&lt;/em&gt;$ under the natural assumption $E\left{\boldsymbol{u}_k n_k\right}=0$, where 0 denotes the zero vector.&lt;/p&gt;
&lt;h3 id=&quot;brief-review-of-the-kpnlms-algorithm&quot;&gt;Brief Review of the KPNLMS Algorithm&lt;/h3&gt;

&lt;p&gt;The update equation of the KPNLMS algorithm is given as [6]
\(\boldsymbol{h}_{k+1}=\boldsymbol{h}_k-\lambda_k e_k\left(\boldsymbol{h}_k\right) \frac{\boldsymbol{\Omega}_k \boldsymbol{u}_k}{\boldsymbol{u}_k^T \boldsymbol{\Omega}_k \boldsymbol{u}_k}, k \in \mathbb{N}\)
Here, $\lambda_k \in[0,2]$ is the step size, and the matrix $\boldsymbol{\Omega}_k:=\boldsymbol{U} \boldsymbol{\Lambda}_k \boldsymbol{U}^T \in$ $\mathbb{R}^{N \times N}, k \in \mathbb{N}$, is positive definite with the orthogonal matrix $U \in$ $\mathbb{R}^{N \times N}$ and the positive diagonal matrix $\Lambda_k \in \mathbb{R}^{N \times N}, k \in \mathbb{N}$. The key is how to construct $\boldsymbol{U}$ and $\boldsymbol{\Lambda}_k$.&lt;/p&gt;

&lt;p&gt;To explain the construction of the matrix $\boldsymbol{U}$, let us define, for a given $(N \geq) D \in \mathbb{N}^*$, a matrix-valued function $\boldsymbol{K}_D: \mathbb{R}^{N \times N} \times$ $\mathbb{R}^N \rightarrow \mathbb{R}^{N \times D}$ as
\(\boldsymbol{K}_D(\boldsymbol{A}, \boldsymbol{b}):=\left[\boldsymbol{b}, \boldsymbol{A} \boldsymbol{b}, \cdots, \boldsymbol{A}^{D-1} \boldsymbol{b}\right], \forall \boldsymbol{A} \in \mathbb{R}^{N \times N}, \boldsymbol{b} \in \mathbb{R}^N .\)
Then,
\(\mathcal{K}_D(\boldsymbol{A}, \boldsymbol{b}):=\mathcal{R}\left\{\boldsymbol{K}_D(\boldsymbol{A}, \boldsymbol{b})\right\} \subset \mathbb{R}^N\)
is called the $D$ th Krylov subspace associated with $\boldsymbol{A}$ and $\boldsymbol{b}$, where $\mathcal{R}{\cdot}$ stands for range.&lt;/p&gt;

&lt;p&gt;The matrix $U \in \mathbb{R}^{N \times N}$ is constructed by orthogonalizing the columns of $\boldsymbol{K}_N(\widehat{\boldsymbol{R}}, \widehat{\boldsymbol{p}})$, where $\widehat{\boldsymbol{R}} \in \mathbb{R}^{N \times N}$ and $\widehat{\boldsymbol{p}} \in \mathbb{R}^N$ are estimates of $\boldsymbol{R}$ and $\boldsymbol{p}$, respectively. The construction of $\boldsymbol{\Lambda}_k$ borrows the idea of the PNLMS algorithm $[7,8]$. If the improved PNLMS (IPNLMS) algorithm [11] is adopted, the diagonal matrix is given as
\(\boldsymbol{\Lambda}_k:=\operatorname{diag}\left\{\boldsymbol{\theta}^{(k)}\right\} \in \mathbb{R}^{N \times N}, k \in \mathbb{N}\)
with
\(\begin{aligned}
\boldsymbol{\theta}^{(k)} &amp;amp; :=\frac{1-\eta}{N} \mathbf{1}_N+\frac{\eta}{\left\|\tilde{\boldsymbol{h}}_k\right\|_1+\varepsilon}\left|\tilde{\boldsymbol{h}}_k\right| \in \mathbb{R}^N, k \in \mathbb{N}, \\
\tilde{\boldsymbol{h}}_k &amp;amp; :=\boldsymbol{U}^T \boldsymbol{h}_k \in \mathbb{R}^N, k \in \mathbb{N}, \\
\mathbf{1}_N &amp;amp; :=[1,1, \cdots, 1]^T \in \mathbb{R}^N .
\end{aligned}\)
Here, $|\cdot|$ and $|\cdot|_1$ denote the elementwise absolute-value operation and 1-norm, respectively, $\eta \in(0,1)$ a parameter to control the amount of proportionality in the update, and $\varepsilon&amp;gt;0$ a small positive constant for regularization. If $\boldsymbol{U}=\boldsymbol{I}(\boldsymbol{I}$ : identity matrix), then KPNLMS coincides with PNLMS.&lt;/p&gt;

&lt;p&gt;It should be mentioned that another key point of KPNLMS is simplification to keep $O(N)$ computational complexity per iteration, which is practically important but is omitted in this paper for conciseness (see [6]). Moreover, an extension of KPNLMS to complexvalued signals and its application to wireless communication systems will be presented at this workshop [12], in which the whitening is not used because the correlation of the input signals is fairly low.&lt;/p&gt;

&lt;h2 id=&quot;whitening-in-the-kpnlms-algorithm&quot;&gt;WHITENING IN THE KPNLMS ALGORITHM&lt;/h2&gt;

&lt;p&gt;The KPNLMS algorithm realizes fast convergence when
\(\tilde{\boldsymbol{h}}^*:=\boldsymbol{U}^T \boldsymbol{h}^* \in \mathbb{R}^N\)
is sparse; the sparsity is measured by a certain energy. In [6], only an intuitive discussion is given about the motivation for whitening in case of highly colored input signals.&lt;/p&gt;

&lt;h3 id=&quot;on-whitening-for-kpnlms&quot;&gt;On Whitening for KPNLMS&lt;/h3&gt;

&lt;p&gt;Let $\boldsymbol{V} \in \mathbb{R}^{N \times N}$ (or $\boldsymbol{V} \in \mathbb{C}^{N \times N}$ ) be a prespecified orthogonal (or unitary) matrix, such as the DCT (discrete cosine transform) or the DFT (discrete Fourier transform) matrix. For simplicity, $\boldsymbol{V}$ is assumed to be real-valued in the following (an extention to the complex-valued case is straightforward). As in TDAF, the diagonal matrix is defined as
\(\boldsymbol{D}_k:=\operatorname{diag}^{-1}\left\{\sigma_1^{(k)}, \sigma_2^{(k)}, \cdots, \sigma_N^{(k)}\right\}, k \in \mathbb{N}\)
where, for given initial estimates $\sigma_n^{(0)}&amp;gt;0, n=1,2, \cdots, N$, $\sigma_n^{(k)}:=\zeta \sigma_n^{(k-1)}+(1-\zeta)\left[\boldsymbol{V} \boldsymbol{u}&lt;em&gt;k\right]_n^2&amp;gt;0, k \in \mathbb{N}$, with the forgetting factor $\zeta \in(0,1)$. Here, $[\cdot]_n$ is the $n$th element of a vector. Then, the whitened input vector is generated as
\(\phi_k:=\boldsymbol{\Phi}_k^{1 / 2} \boldsymbol{u}_k \in \mathbb{R}^N, k \in \mathbb{N}\)
with $\boldsymbol{\Phi}_k:=\boldsymbol{V}^T \boldsymbol{D}_k \boldsymbol{V} \in \mathbb{R}^{N \times N}, k \in \mathbb{N}$. The standard NLMS algorithm with the whitened input $\phi_k$ tracks the modified solution $\boldsymbol{\omega}^*$ characterized by $\boldsymbol{R}&lt;/em&gt;\phi \boldsymbol{\omega}^&lt;em&gt;=\boldsymbol{p}_\phi\left(\Leftrightarrow \boldsymbol{R} \boldsymbol{\Phi}_k^{1 / 2} \boldsymbol{\omega}^&lt;/em&gt;=\boldsymbol{p}\right)$, where $\boldsymbol{R}&lt;em&gt;\phi:=E\left{\phi_k \phi_k^T\right} \in \mathbb{R}^{N \times N}$ and $p&lt;/em&gt;\phi:=E\left{\phi_k d_k\right} \in \mathbb{R}^N$. Hence, for letting the algorithm track the original solution $\boldsymbol{h}^*$, the update equation (12) with $\boldsymbol{v}&lt;em&gt;k=\phi_k\left(\boldsymbol{G}_k=\boldsymbol{\Phi}_k\right)$ should be left-multiplied by $\boldsymbol{\Phi}_k^{1 / 2}$, leading to
\(\boldsymbol{h}_{k+1}=\boldsymbol{h}_k-\lambda_k e_k\left(\boldsymbol{h}_k\right) \frac{\boldsymbol{\Phi}_k \boldsymbol{u}_k}{\boldsymbol{u}_k^T \boldsymbol{\Phi}_k \boldsymbol{u}_k}, k&amp;lt;K_0,\)
where $\boldsymbol{h}_k:=\boldsymbol{\Phi}_k^{1 / 2} \boldsymbol{w}_k ;$ (16) is nothing but (11) for $\boldsymbol{G}_k=\boldsymbol{\Phi}_k$. Once obtaining adequate estimates of $\boldsymbol{R}&lt;/em&gt;{\boldsymbol{\phi}}$ and $\boldsymbol{p}_\phi$, we can construct the orthogonal matrix $\boldsymbol{U}$ as in the original KPNLMS algorithm.
Next is the construction of the diagonal matrix $\boldsymbol{\Lambda}_k$. Note that&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$\boldsymbol{h}_k$ tracks $\boldsymbol{h}^*$;&lt;/li&gt;
  &lt;li&gt;(not the original solution $\boldsymbol{h}^&lt;em&gt;$ but) the modified solution $\boldsymbol{\omega}^&lt;/em&gt;(=$ $\left.\boldsymbol{\Phi}&lt;em&gt;k^{-1 / 2} \boldsymbol{h}^*\right)$ tends to have large energy in $\mathcal{K}_D\left(\boldsymbol{R}&lt;/em&gt;\phi, \boldsymbol{p}_\phi\right)$.
Thus, $\boldsymbol{\Lambda}_k$ should be constructed according, instead of $\tilde{\boldsymbol{h}}_k$, to
\(\ddot{\boldsymbol{h}}_k:=\boldsymbol{U}^T \boldsymbol{\Phi}_k^{-1 / 2} \boldsymbol{h}_k\)
The final and important point is how to combine $\boldsymbol{\Phi}_k$ and $\boldsymbol{\Omega}_k$. The original KPNLMS algorithm can be viewed as follows: (i) the input is modified by $\Omega_k^{1 / 2}$, and then (ii) the update equation (12) is left-multiplied by $\Omega_k^{1 / 2}\left(=G_k^{1 / 2}\right)$ for tracking the original solution $h^&lt;em&gt;$. In case that whitening is involved, the input $\phi_k$ is further modified by $\boldsymbol{\Omega}_k^{1 / 2}\left(=\boldsymbol{U} \boldsymbol{\Lambda}_k^{1 / 2} \boldsymbol{U}^T\right)$, implying that the solution $\boldsymbol{\omega}^&lt;/em&gt;$ is also modified further by $\Omega_k^{1 / 2}$. Therefore, for tracking $\boldsymbol{h}^*$, the update equation with the doubly-modified input $\boldsymbol{v}_k=\Omega_k^{1 / 2} \boldsymbol{\phi}_k$ should be left-multiplied by $\boldsymbol{\Phi}_k^{1 / 2} \boldsymbol{\Omega}_k^{1 / 2}$, leading to
\(\boldsymbol{h}_{k+1}=\boldsymbol{h}_k-\lambda_k e_k\left(\boldsymbol{h}_k\right) \frac{\boldsymbol{\Pi}_k \boldsymbol{u}_k}{\boldsymbol{u}_k^T \boldsymbol{\Pi}_k \boldsymbol{u}_k}, k \geq K_0,\)
where $\boldsymbol{h}_k:=\boldsymbol{\Phi}_k^{1 / 2} \boldsymbol{\Omega}_k^{1 / 2} \boldsymbol{w}_k$ and $\boldsymbol{\Pi}_k:=\boldsymbol{\Phi}_k^{1 / 2} \boldsymbol{\Omega}_k \boldsymbol{\Phi}_k^{1 / 2}$. Simplification is possible to attain $O(N)$ complexity by following the way in [6].&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series</title>
   <link href="http://localhost:4000/2023/03/06/weighted-sliding-emd"/>
   <updated>2023-03-06T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/06/weighted-sliding-EMD</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Biomedical signals are in general non-linear and non-stationary. empirical mode
decomposition in conjunction with a Hilbert-Huang Transform provides a fully adaptive and
data-driven technique to extract intrinsic mode functions. The latter represent a complete set
of locally orthogonal basis functions to represent non-linear and non-stationary time series.
Large scale biomedical time series necessitate an online analysis, which is presented in this
contribution. It shortly reviews the technique of EMD and related algorithms, discusses the
recently proposed weighted sliding EMD algorithm (wSEMD) and, additionally, proposes a
more sophisticated implementation of the weighting process. As an application to biomedical
signals we will show that wSEMD in combination with mutual information could be used to
detect temporal correlations of arterial blood pressure and intracranial pressure monitored at
a neurosurgical intensive care unit.We will demonstrate that the wSEMD technique renders
itself much more flexible than the Fourier based method used in Faltermeier et al.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p align=&quot;justify&quot;&gt;
Recently an empirical nonlinear analysis tool for complex, non-stationary time series has
been pioneered by Huang et al. [6]. It is commonly referred to as empirical mode decomposition
(EMD) and if combined with Hilbert spectral analysis it is called Hilbert-Huang
Transform (HHT). It adaptively and locally decomposes any non-stationary time series into a
sum of intrinsic mode functions (IMF) which represent zero-mean amplitude and frequency
modulated (AMFM) oscillatory components. The EMDrepresents a fully data-driven, unsupervised
signal decomposition technique and does not need any a priori defined basis system.
The empirical nature of EMD offers the advantage over other empirical signal decomposition
techniques like exploratory matrix factorization (EMF) [8] of not being constrained
by conditions which often only apply approximately. Especially with biomedical signals
one often has only a rough idea about the underlying modes and mostly their number is
unknown. Furthermore, large scale biomedical time series recorded over days necessitate an
online analysis [13], while EMD can analyze data only globally so far. This contribution
will review the technique of EMD and its recent extensions, propose an online EMD variant
called weighted sliding EMD (wSEMD) and discuss some biomedical applications related
to neuromonitoring. In the following we will denote by N the total number of time samples
tn in the time series, by M the size of a segment, by S the total number of segments and by
L the total number of IMFs into which the time series is decomposed in every segment.&lt;/p&gt;

&lt;h2 id=&quot;sliding-emd&quot;&gt;Sliding EMD&lt;/h2&gt;

&lt;h3 id=&quot;the-principle&quot;&gt;The Principle&lt;/h3&gt;

&lt;p&gt;This new technique presents an improved EMD algorithm which is suitable for online processing of non-stationary time series. Sliding $\operatorname{EMD}$ (SEMD) $[3,4]$ offers a robust and easy -to-implement solution to the problem of dealing with e.g. biomedical time series which often are recorded over long time spans with high sampling rate.
Using Sliding EMD the recorded time series is split into segments which can be analyzed with EMD. The segment size $M$ has to be a multiple of the step size $K$ with which the segments are shifted relative to each other. Thus, if $\frac{M}{K} \in \mathbb{N}$ holds, neighboring segments can be joined without resulting discontinuities or boundary artifacts. With this choice, every sample is represented equally often, i.e. $E=\frac{M}{K}$-times, in the overlapping segments for a later estimation of the corresponding mean sample value. The time series in every segment $s$ is decomposed by EMD into $L$ IMFs $x_{l, s}(t)$ and a local residuum $x_{L+1, s}(t) \equiv r_s(t)$ according to
\(x_s(t)=\sum_{l=1}^L x_{l, s}(t)+r_s(t)\)
whereby the number of sifting steps $L_s$ is kept equal in all segments $s$. Resulting IMFs are collected in a matrix with corresponding sample points forming a column of the matrix with $E=\frac{M}{K}$ entries. Only columns which contain an identical number of entries are used to estimate average IMF amplitudes at every time point $t_n$ in each segment. Consequently, the first and last $M$ samples of the time series are omitted. This finally yields:
For $t_n&amp;gt;M$ and $h=\left\lfloor\frac{t_n-M}{K}\right\rfloor+2:$
with $h \in \mathbb{N}$. By construction SEMD fulfills the condition to be complete, much as EMD does. Except for the stopping criterion, which here amounts to keeping the number of sifting steps $L_S$ constant, any EMD algorithm can be applied. Furthermore the number of IMFs has to be kept constant in every window e.g. according to $L=\left\lfloor\log _2 N\right\rfloor$. A schematic diagram of the SEMD procedure is presented in Fig. 1.&lt;/p&gt;

&lt;p&gt;!&lt;span title=&quot;There is no note that matches this link.&quot; class=&quot;invalid-link&quot;&gt;  &lt;span class=&quot;invalid-link-brackets&quot;&gt;[[&lt;/span&gt;  wsEMD.png  &lt;span class=&quot;invalid-link-brackets&quot;&gt;]]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&quot;properties-of-semd&quot;&gt;Properties of SEMD&lt;/h3&gt;

&lt;p&gt;Because of the segmentation involved, contrary to global EMD the local residua estimated with SEMD for every segment when joined together may result in low-frequency oscillations instead in an average global residuum, as the residuum is only monotonous in every single window, but not in the resulting global residuum. By choosing the segment size properly, it may be determined which oscillations should appear as distinct IMFs and which should be absorbed as apparent local trends into the respective residua.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;These apparent local trends,
which combine to low-frequency oscillations in the final average global residuum, may be
down-sampled, because of the high sampling rate, to a useful time resolution and subsequently
analyzed with SEMD again. This process can be repeated until finally a truly monotonous
trend remains. Hence, this cascaded application of SEMD acts as a low-frequency filter for
long-term oscillations and trends in biomedical time series.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Similar to ensemble empirical mode decomposition (EEMD) [11], also with Sliding EMD
an averaging over differently decomposed data sets is achieved. While due to added noise,
with EEMD a given sample is associated with different amplitudes, with sliding EMD the
same amplitude is associated with different samples in different shifted segments. This latter
behavior alleviates effects related with a non-unique data decomposition via EMD. Furthermore,
artifacts resulting from end effects loose their impact via averaging. Finally note that
while local IMFs fulfill all defining conditions, this is not necessarily true for the resulting
average IMFs though the related deviations should always be small.&lt;/p&gt;

&lt;h3 id=&quot;weighted-semd&quot;&gt;weighted SEMD&lt;/h3&gt;

&lt;p&gt;Despite the averaging operations involved inSEMD,reconstruction errors due to the boundary
effects remain to be observed in SEMD.In order to diminish the impact of the latter, awSEMD
was developed recently. Every value of the ensemble of samples E, whose average
forms the final time series, is weighted by a coefficient drawn from a predefined distribution
of weights. These coefficients become larger when the estimated data point origins from
the middle of the window, and smaller when it is located near one of the boundaries. The
coefficients are assumed to form a discrete Gaussian distribution $p_{G}(E) (te)$ with E samples $e = 1, . . . , E$. Using such weights, boundary effects are strongly suppressed.&lt;/p&gt;

&lt;p&gt;!&lt;span title=&quot;There is no note that matches this link.&quot; class=&quot;invalid-link&quot;&gt;  &lt;span class=&quot;invalid-link-brackets&quot;&gt;[[&lt;/span&gt;  wsEMDex.png  &lt;span class=&quot;invalid-link-brackets&quot;&gt;]]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&quot;improvement-of-the-weighting-process&quot;&gt;Improvement of the weighting process&lt;/h3&gt;

&lt;p&gt;In this subsection we consider an alternative way of applying weights to the time series to suppress boundary artifacts. It amounts to applying a weight to every sample of a window rather than weighting the estimates. Thus every window of the resulting IMFs and the residuum is multiplied by the weighting function. The latter, again, is assumed to form a discrete Gaussian distribution $p_G^{(M)}\left(t_m\right)$. But instead of weighting the estimates, every sample point inside the window is weighted according to its distance to the closest border of the window, which effectively suppresses samples near the boundaries. Therefore, the weighting function consists of $M$ samples, instead of $E$. Furthermore, the Gaussian distribution is shifted along the ordinate via $p_G^{(M)}\left(t_m\right)-p_G^{(M)}\left(t_1\right)$, so that $p_G^{(M)}\left(t_1\right)=0$ and $p_G^{(M)}\left(t_M\right)=0$, respectively.&lt;/p&gt;

&lt;p&gt;This technique produces a more sophisticated and precise weighting of the estimates as several similar distributions $p_G^{(M)}\left(t_{m, e}\right), t_{m, e} \in[1, M]$ with $e=1, \ldots, E$ are utilized to weight the estimates. After the calculation of the ensemble mean of $K$ data points, every sample position $t_m, m=1, \ldots, M$, and therefore point of the weighting function of the window $p_G^{(M)}\left(t_m\right)$, has been used exactly once for averaging, as $K=\frac{M}{E}$ (see scheme in Fig. 3).&lt;/p&gt;

&lt;p&gt;Hence $K$ shorter and slightly different distributions $p_G^{(M, i)}\left(t_{m, e}\right), i=1, \ldots, K$ are picked out of the weighting function and are used to weight the estimates, whereas all picked out samples for one ensemble weighting function have a distance of $K$ points respectively. The $K$ different distributions $p_G^{(M, i)}\left(t_{m, e}\right)$ can be described as part of $p_G^{(M)}\left(t_m\right)$ using the following set of samples:
\(\left\{p_G^{(M, i)}\left(t_{m, e}\right) \mid t_{m, e}=i+0 K, i+1 K, \ldots, i+(E-1) K\right\}\)
To calculate the final result for a specific sample of an IMF or the residuum, the sum over $E$ estimates multiplied by $E$ weighting coefficients is computed and the value is normalized by the reciprocal sum of all used weights for that particular data point, so that the amplitude of the signal is preserved. For a step size of $K=1$ both methods, the weighted estimates and the weighted window SEMD, are the same, as $E=M$. Otherwise both approaches differ in that a specific set of weights for one data point is repeatedly used again-and only again-after $K$ samples. In the following, the improved wSEMD will be used for the further analyses.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Sampling and interpolation</title>
   <link href="http://localhost:4000/2023/03/05/sampling-interpolation"/>
   <updated>2023-03-05T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/05/sampling-interpolation</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Nowadays, a lot of time series data is produced, which represents the state of the environment over a period
of time [15]. These data points are generally captured by a piece of equipment called a sensor. The sensor can
detect dierent events or changes in the environment and quantify the changes in the form of temperature,
pressure, noise, or light intensity, among others. A limitation of collecting data points is the frequency at
which the sensor records the changes or events. The more frequently a sensor records a reading, the more
expensive the running cost is. Likewise, the less frequent the sensor records the reading, the more difficult it
is to capture and reconstruct the original behaviour of the event.
In practice, all signals have to be sampled because the number of points in a continuous environment is infinite&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Sampling is the mechanism that collects the information by setting the frequency of the collected
points over a time period. Capturing readings more often is economically more expensive due to the amount
of data being stored, transmitted, and processed. The challenge while performing sampling is to preserve the
vital information in the less amount of data points so that the objective of recording changes is met.
The periodic or Riemann sampling [15] is a conventional approach of sampling in the time series data.
In this approach, the data is captured periodically, i.e. at an equidistant time intervals (such as each
second or each microsecond). Even though the approach is simple to implement, the shortcoming is that,
when the sampled data fails to indicate changes that happen between the interval (also known as frequency
aliasing), sampling needs to be readjusted at a higher frequency, resulting into more data collection. Firstly,
making such an adjustment requires manual assessment, and in addition to that, it bears the additional cost&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;concerning more data being generated. Due to this pitfall, many research findings advocated for the use of
Lebesgue sampling, instead of Riemann sampling [24]. Furthermore, some authors [2] have demonstrated
Lebesgue sampling being a more ecient strategy compared to Riemann sampling.
The Lebesgue sampling [4], also known as Event-based sampling, is an alternative sampling strategy to
the more popular Riemann sampling strategy. In the Lebesgue sampling, the time-series data is sampled
whenever a signicant change takes place or when the measurement passes a certain limit [17]. A few
motivating examples of sampling strategy would be: whenever a specic value of the sensor reading crosses a
limit, when a data packet arrives at a node on a computer network, or when the system output has changed
with a specied amount.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;
The overall intuition of the Lebesgue sampling is to save the unnecessary data from being stored, processed,
or transmitted which represents either no change or a trivial change compared to the previous data point.
The nature of sampling based on events in the Lebesgue sampling is very appealing and natural in many
domains where the systems remain constant for an extended period such as wireless communications [19] or
systems with an on-o mechanism like those in the satellite control [2].
Increasing the battery life of the sensors and reducing their use [25], reducing network trac by decreasing
the amount of information transferred [32], or using fewer computer resources while maintaining the same
performance [31], are some of the advantages of event-based control over control based in time. 
&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;By contrast,
the management of the systems that implement Lebesgue sampling becomes more complicated [2].
When a time series signal is sampled, generally, the subsequent step is to reconstruct the original signal
as accurately as possible [14]. The interpolation method is one of the well-known criteria to reconstruct
the signal by lling the missing values between the range of the discrete set of data points. Despite the
signicance of the interpolation methods, the challenge of reconstructing the signal remains an important
area of research.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Moreover, common interpolation methods do not perform well on Lebesgue sampling as
demonstrated in this contribution.
In this contribution, it is proposed interpolation methods to reconstruct the time-series data sampled
using Lebesgue sampling. To the best of our knowledge, this is the rst interpolation method designed
exclusively for Lebesgue sampling. The proposed methods have a higher performance because they exploit
the particular properties of this kind of sampling.
Two novel interpolation methods are proposed: ZeLiC and ZeChipC. ZeLiC uses Zero-order hold and
Linear interpolation with specic shape approximation on the basis of Concavity/Convexity1. On the
other hand, ZeChipC uses Zero-order hold and PChip interpolation with the same Concavity/Convexity
improvement as ZeLiC.&lt;/p&gt;

&lt;h3 id=&quot;lebesgue-sampling&quot;&gt;Lebesgue Sampling&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;Lebesgue sampling is an alternative to the traditional approach of sampling time series at a constant frequency.
Instead of periodically taking samples from a system like in Riemann sampling, the event-based method takes
samples only when a predened event happens as shown in Figure 1. Some examples of typical events could
be a sudden change in the signal, the signal reaching a preset limit, the arrival of a data package, or a change
in the state of a system [2]. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Even though Lebesgue sampling is more accurate than Riemann sampling it is
less extended because those systems are more dicult to implement [2].
In recent years, a great interest has aroused in applications implementing event-based sampling. For
example, the \Send on Delta&quot; algorithm takes advantage of Lebesgue sampling to reduce the information
transmitted by wireless networks in order to increase the lifetime of the sensors batteries. Under this scheme,
the sampling is performed only when there is a deviation in the signal higher than the delta value. Results
show that using this approach it is possible to increase the lifetime of the sensors without any loss of quality
in the resolution of the signals [25].&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;We can find another positive example in the domain of Networked Control Systems (NCSs), where the
advantages of Lebesgue sampling become clear. In this type of systems increasing the sampling frequency
can be counterproductive since the information load increases and the trac of the network can collapse
the whole system functioning. In the last decade, many NCS have successfully implemented event-triggered
control reducing the required resources and the bandwidth of the network [32].
It is also interesting pointing out the convenience of using event-based sampling in the Fault Diagnosis
and Prognosis (FDP). In the last years, it has been increasingly dicult to manage microcontrollers and
embedded systems due to the volume of the information collected by sensors and to the complexity of the
programs that they implement. Increasing computational resources is not a good solution in the long term
since it increases economic costs. Yan et al. [31] found an ecient solution to this problem applying the
philosophy of \execution only when necessary&quot; based on Lebesgue sampling, which reduces computational
costs substantially without diminishing the performance of the system.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;
Some research has been done to nd the optimal balance between the number of samples and the performance
of the system. For example, Andren, et al. [1] studied this balance for a linear-quadratic-Gaussian
(LQG) control problem setting with output feedback. However, sampling based on changes works well with
signals that remain constant for some time and present sudden variations. This is because this kind of sampling
captures a higher number of points when the signal has abrupt changes while it does not take points
when the signal remains constant. For example, when a natural phenomenon like an earthquake takes place,
the sensor values can go from zero to a positive high value in an instant. With sampling based on events, more
points of the critical moments would be captured, which gives important information about the behaviour of
the phenomenon while if nothing occurs no information will be captured.
Lebesgue sampling can minimise energy consumption, storage space, computation time and the amount
of data to be transmitted as it has been claimed in many investigations [30].&lt;/p&gt;

&lt;h3 id=&quot;time-series-interpolation-methods&quot;&gt;Time series interpolation methods&lt;/h3&gt;

&lt;p&gt;The downsampled time series data can be reconstructed using different interpolation techniques. The interpolation function estimates the missing data points within the range of the discrete set of known data points with the objective of preserving the shape of the original signal before the application of downsampling [22].
Let $\left(x_i, y_i\right), i=0, \ldots, n$ be pairs of real values, where $f$ is the interpolation function, $x_i$ are the indexes of the downsampled data points, and $y_i$ are the values of those points. The objective of the optimal interpolation technique is to satisfy the condition where $f\left(x_i\right)$ verifies $y_i$.
\(f\left(x_i\right)=y_i \text { for } i=0, \ldots, n\)
There are a number of interpolation techniques ranging from simpler ones such as Zero-order hold [11] and Linear [11], to a more complex ones such as Multiquadric [18] which is based on radial basis function, Shannon [23] which is based on Nyquist-Shannon sampling theorem, Lasso [29] which is based on regression, Natural Neighbour [8] which is a spatial method and provides smoother approximation compared to simple interpolation technique. Cubic Hermite spline [21] and Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) [20] are interpolation techniques based on splines and cubic function respectively. They are often a preferred choice in the polynomial interpolation.&lt;/p&gt;

&lt;p&gt;The relation 2 describes the objective function of an interpolation method. Let $\left(x_i, y_i\right), i=0, \ldots, n$ pairs of real values. We want to find a function $f$ (easy to calculate), where $f$ verifies
\(f\left(x_i\right)=y_i \text { for } i=0, \ldots, n\)&lt;/p&gt;
&lt;h4 id=&quot;zero-order-hold-interpolation&quot;&gt;Zero-order hold interpolation&lt;/h4&gt;

&lt;p&gt;The zero-order hold (ZOH) interpolation is one of the simplest signal reconstruction techniques [11]. In this technique, the missing values between two sampled points are interpolated with a constant value. This constant value is the same value of the preceding known point before encountering missing values. This technique has several applications in electrical communication and the main advantage is its low computational complexity. However, this interpolation strategy fails to reconstruct continuity or trend in time series with non zero values for the first derivative.&lt;/p&gt;

&lt;p&gt;In ZOH, the polynomial $C_i(x)$ is of 0 th degree. Therefore, $C_i(x)=c$ where $c$ is constant. Because of (2), $C_i\left(x_{i-1}\right)=y_{i-1}$. If in $x_i$, a sudden change is presented, we cannot represent it because $C_{i+1}\left(x_i\right)=y_i \neq y_{i-1}$. Therefore, this interpolation cannot be used neither to represent continuous functions nor to produce a natural curves.&lt;/p&gt;

&lt;h4 id=&quot;first-order-or-linear-interpolation&quot;&gt;First order or Linear interpolation&lt;/h4&gt;

&lt;p&gt;Linear interpolation is also another popular choice for the reconstruction of a signal due to its simplicity and low computational complexity . In this method, missing values are reconstructed by fitting a straight line between successive known points. The shortcoming is that the reconstruction of a signal fails to capture any non-linear trend even though the overall known values follow a non-linear trend.&lt;/p&gt;

&lt;p&gt;The polynomial $C_i(x)$ is of 1st degree, which means $C_i(x)=a x+b$, and because of (2), $C_i\left(x_{i-1}\right)=y_{i-1}$ and $C_i\left(x_i\right)=y_i$, where each two consecutive pair of sampled points are connected using a straight line. The following formulas can be applied to calculate $a$ and $b, \forall i=1, \ldots, n$
\(\left\{\begin{array}{l}
a=\frac{y_i-y_{i-1}}{x_i-x_{i-1}} \\
b=y_i-a x_i
\end{array}\right.\)&lt;/p&gt;

&lt;p&gt;This interpolation gives a continuous but non-differentiable function $f$. Let $C_i(x)=a_i x+b_i$ and $C_{i+1}=$ $a_{i+1} x+b_{i+1}$, we have
\(\begin{aligned}
&amp;amp; \lim _{x^{-} \rightarrow x_i} f^{\prime}(x)=a_i \\
&amp;amp; \lim _{x^{+} \rightarrow x_i} f^{\prime}(x)=a_{i+1}
\end{aligned}\)
Therefore, the function is differentiable only if $a_i=a_{i+1}, \quad \forall i=1, \ldots, n$. We can conclude that for non-linear functions, $f$ is not differentiable with linear interpolation.&lt;/p&gt;

&lt;p&gt;Linear interpolation is fast to compute and very intuitive. However, the drawback is the non-derivability of the interpolation at each node, which makes it produce sharp changes in the reconstructed signal.&lt;/p&gt;
&lt;h4 id=&quot;spline-interpolation-methods&quot;&gt;Spline interpolation methods&lt;/h4&gt;

&lt;p&gt;In the spline interpolation methods, the interpolation function is a particular case of piecewise polynomial. The advantage of this type of method over the first order interpolation is that it reconstructs the signal using non-linear functions (which makes the transitions smoother) and also avoids the Runge phenomenon [5, 28]. The Runge phenomenon refers to the oscillation at the edges of a given interval while interpolating missing values.&lt;/p&gt;

&lt;p&gt;We can define $f$ as $f(x)=C_i(x)$ for $x \in\left[x_{i-1}, x_i\right], i=1, \ldots, n$ where $C_i$ is a polynomial of small degree. Where $C_i\left(x_i\right)=C_{i+1}\left(x_i\right)=f\left(x_i\right)=y_i$. The most common degrees in terms of interpolation are the first and third degree, which are Linear and Cubic interpolation.
2.2.4 Third order or Cubic interpolation
The cubic function is one of the most commonly used spline interpolation methods [21]. It uses a third-degree polynomial in the Hermite form for interpolating missing values as follows $C_i(x)=a x^3+b x^2+c x+d$. This interpolation strategy inherits the conditions of Linear interpolation and adds conditions on its first and second derivatives:
\(\begin{aligned}
C_i\left(x_i\right) &amp;amp; =C_{i+1}=f\left(x_i\right) \\
C_i^{\prime}\left(x_i\right) &amp;amp; =C_{i+1}^{\prime}=f^{\prime}\left(x_i\right) \\
C_i^{\prime \prime}\left(x_i\right) &amp;amp; =C_{i+1}^{\prime \prime}=f^{\prime \prime}\left(x_i\right)
\end{aligned}\)
The strength of this interpolation strategy is the fact that it produces smooth curves in the region of missing values which makes the signal look natural. The drawback of this method is that it can lead to significant errors in the region of reconstruction when there is an abrupt change at the end of an interval. Where the derivative on the nodes (sampled points) must be equal, this change will be presented in the beginning of the next interpolated interval.&lt;/p&gt;

&lt;h4 id=&quot;piecewise-cubic-interpolating-polynomial-pchip&quot;&gt;Piecewise Cubic Interpolating Polynomial (PCHIP)&lt;/h4&gt;

&lt;p&gt;The PCHIP (Piecewise Cubic Hermite Interpolating Polynomial) interpolation method is based on the same principle as the spline interpolation, but between each point, it fits a cubic polynomial in Hermites form [20]. The sampled points are known as knots, PCHIP connects those knows independently making a good performance in time and results. The given points have first derivative at the interpolated points, although the second derivative is not guaranteed to be continuous.&lt;/p&gt;

&lt;h3 id=&quot;other-interpolation-methods-for-lebesgue-sampling&quot;&gt;Other interpolation methods for lebesgue sampling&lt;/h3&gt;

&lt;p&gt;Lebesgue sampling is typically used in conjunction with interpolation techniques to reconstruct the continuous signal from the irregularly sampled data. Here are some interpolation techniques that are commonly used with Lebesgue sampling:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Sinc interpolation: Sinc interpolation is a commonly used technique for reconstructing a continuous signal from its samples. It involves using the sinc function, which is the Fourier transform of the rectangular window function used to sample the signal, to interpolate between samples.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Polynomial interpolation: Polynomial interpolation involves fitting a polynomial to the sampled data points and using the polynomial to interpolate between samples. This technique can be computationally efficient, but may not provide accurate interpolation for signals with high-frequency components.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Radial basis function (RBF) interpolation: RBF interpolation involves using a set of radial basis functions, such as Gaussian or inverse multiquadric functions, to interpolate between samples. This technique can be effective for signals with complex structure and can provide accurate interpolation with relatively few basis functions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wavelet interpolation: Wavelet interpolation involves using wavelet transforms to decompose the signal into different scales and interpolate the signal at each scale using a suitable interpolation technique. This technique can be effective for signals with complex structure and can provide accurate interpolation at different scales.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Overall, the choice of interpolation technique depends on the specific characteristics of the signal and the desired accuracy and computational efficiency of the interpolation. Its important to carefully evaluate the performance of each technique on a given signal and choose the one that provides the best results.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Intrinsic Time scale Decomposition</title>
   <link href="http://localhost:4000/2023/03/04/itd"/>
   <updated>2023-03-04T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/04/ITD</id>
   <content type="html">&lt;h2 id=&quot;about-itd&quot;&gt;About ITD&lt;/h2&gt;

&lt;p&gt;Intrinsic Scale Decomposition (ISD) is a signal processing technique that aims to decompose a given signal into a set of intrinsic scales or frequency bands, each of which captures different patterns and features of the signal.&lt;/p&gt;

&lt;p&gt;ISD is based on the idea of multiresolution analysis, which involves analyzing a signal at multiple scales or resolutions to extract different levels of detail. However, unlike traditional multiresolution analysis techniques such as wavelet transforms or Fourier transforms, ISD uses an adaptive and data-driven approach to identify the intrinsic scales of the signal.&lt;/p&gt;

&lt;p&gt;The basic idea behind ISD is to iteratively decompose a signal into two parts: a smooth part and a fluctuation part. The smooth part represents the low-frequency components of the signal, while the fluctuation part captures the high-frequency components. This decomposition is repeated at each scale, with the smooth part of the previous scale serving as the input for the next scale.&lt;/p&gt;

&lt;p&gt;The ISD algorithm typically involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Define an initial scale and compute the mean and standard deviation of the signal at that scale.&lt;/li&gt;
  &lt;li&gt;Decompose the signal into a smooth part and a fluctuation part at that scale, using the mean and standard deviation as thresholds.&lt;/li&gt;
  &lt;li&gt;Repeat the decomposition process at successively higher scales, using the smooth part of the previous scale as the input for the next scale.&lt;/li&gt;
  &lt;li&gt;Stop the decomposition process when the remaining signal has a small amplitude or when a predefined number of scales have been reached.&lt;/li&gt;
  &lt;li&gt;Reconstruct the signal by summing up the smooth parts of each scale.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The resulting decomposition provides a set of intrinsic scales or frequency bands that capture different patterns and features of the signal. These scales can be used for various signal processing tasks such as denoising, feature extraction, and pattern recognition.&lt;/p&gt;

&lt;p&gt;ISD has been applied in various fields such as biomedical signal processing, image processing, and audio processing. However, its worth noting that the effectiveness of ISD depends on the specific characteristics of the signal being analyzed and the choice of parameters used in the algorithm. Therefore, careful parameter tuning and validation are necessary to ensure the reliability and accuracy of the results.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np

def intrinsic_scale_decomposition(signal, num_scales):
    &quot;&quot;&quot;
    Perform intrinsic scale decomposition on a given signal.
    
    Args:
        signal (array_like): The input signal to be decomposed.
        num_scales (int): The number of scales to decompose the signal into.
        
    Returns:
        smooth (array_like): The smooth part of the signal at each scale.
        fluctuation (array_like): The fluctuation part of the signal at each scale.
    &quot;&quot;&quot;
    
    # Define an initial scale and compute the mean and standard deviation of the signal
    scale = 0
    mean = np.mean(signal)
    std = np.std(signal)
    
    # Initialize arrays to store the smooth and fluctuation parts of the signal
    smooth = np.zeros((num_scales, len(signal)))
    fluctuation = np.zeros((num_scales, len(signal)))
    
    # Perform ISD at each scale
    for i in range(num_scales):
        # Decompose the signal into a smooth part and a fluctuation part
        threshold = std * 2**(scale/2)
        smooth[i] = np.where(abs(signal - mean) &amp;lt; threshold, signal, mean)
        fluctuation[i] = signal - smooth[i]
        
        # Update the mean and standard deviation for the next scale
        mean = np.mean(smooth[i])
        std = np.std(fluctuation[i])
        
        # Increment the scale for the next iteration
        scale += 1
    
    return smooth, fluctuation

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Heres a brief explanation of the steps involved in the algorithm:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The input signal is decomposed into a set of scales, with the number of scales specified by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_scales&lt;/code&gt; parameter.&lt;/li&gt;
  &lt;li&gt;The mean and standard deviation of the signal are computed at the initial scale.&lt;/li&gt;
  &lt;li&gt;For each scale, the signal is decomposed into a smooth part and a fluctuation part using a threshold based on the standard deviation and the current scale.&lt;/li&gt;
  &lt;li&gt;The mean and standard deviation are updated for the next scale using the smooth and fluctuation parts of the previous scale.&lt;/li&gt;
  &lt;li&gt;The process is repeated for the specified number of scales.&lt;/li&gt;
  &lt;li&gt;The output of the algorithm is a set of arrays containing the smooth and fluctuation parts of the signal at each scale.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note that this is just one possible implementation of ISD, and there are many variations and extensions of the algorithm that can be used depending on the specific requirements of the application.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The De-noising Algorithm Based on Intrinsic Time-scale Decomposition</title>
   <link href="http://localhost:4000/2023/03/03/intrinsic-time-scale-decomposition"/>
   <updated>2023-03-03T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/03/intrinsic-time-scale-decomposition</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;A new de-noising algorithm based on Intrinsic Time-scale Decomposition (ITD) is
proposed after analyzing the statistical characteristics of additional Gaussian white noise decomposed
by ITD. Compared with the Wavelet Threshold De-noising(WTD) and de-noising algorithms based
on empirical mode decomposition (EMD), the numerical simulation results show that this algorithm
has comparable performance with the de-noising based on EMD and the WTD, and it is no need for
spline interpolation, iterative sifting and selection of the wavelet base. It is a new adaptive de-noising
algorithm.
&lt;/p&gt;

&lt;h2 id=&quot;about-itd&quot;&gt;About ITD&lt;/h2&gt;

&lt;p&gt;Intrinsic Scale Decomposition (ISD) is a signal processing technique that aims to decompose a given signal into a set of intrinsic scales or frequency bands, each of which captures different patterns and features of the signal.&lt;/p&gt;

&lt;p&gt;ISD is based on the idea of multiresolution analysis, which involves analyzing a signal at multiple scales or resolutions to extract different levels of detail. However, unlike traditional multiresolution analysis techniques such as wavelet transforms or Fourier transforms, ISD uses an adaptive and data-driven approach to identify the intrinsic scales of the signal.&lt;/p&gt;

&lt;p&gt;The basic idea behind ISD is to iteratively decompose a signal into two parts: a smooth part and a fluctuation part. The smooth part represents the low-frequency components of the signal, while the fluctuation part captures the high-frequency components. This decomposition is repeated at each scale, with the smooth part of the previous scale serving as the input for the next scale.&lt;/p&gt;

&lt;p&gt;The ISD algorithm typically involves the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Define an initial scale and compute the mean and standard deviation of the signal at that scale.&lt;/li&gt;
  &lt;li&gt;Decompose the signal into a smooth part and a fluctuation part at that scale, using the mean and standard deviation as thresholds.&lt;/li&gt;
  &lt;li&gt;Repeat the decomposition process at successively higher scales, using the smooth part of the previous scale as the input for the next scale.&lt;/li&gt;
  &lt;li&gt;Stop the decomposition process when the remaining signal has a small amplitude or when a predefined number of scales have been reached.&lt;/li&gt;
  &lt;li&gt;Reconstruct the signal by summing up the smooth parts of each scale.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The resulting decomposition provides a set of intrinsic scales or frequency bands that capture different patterns and features of the signal. These scales can be used for various signal processing tasks such as denoising, feature extraction, and pattern recognition.&lt;/p&gt;

&lt;p&gt;ISD has been applied in various fields such as biomedical signal processing, image processing, and audio processing. However, its worth noting that the effectiveness of ISD depends on the specific characteristics of the signal being analyzed and the choice of parameters used in the algorithm. Therefore, careful parameter tuning and validation are necessary to ensure the reliability and accuracy of the results.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np

def intrinsic_scale_decomposition(signal, num_scales):
    &quot;&quot;&quot;
    Perform intrinsic scale decomposition on a given signal.
    
    Args:
        signal (array_like): The input signal to be decomposed.
        num_scales (int): The number of scales to decompose the signal into.
        
    Returns:
        smooth (array_like): The smooth part of the signal at each scale.
        fluctuation (array_like): The fluctuation part of the signal at each scale.
    &quot;&quot;&quot;
    
    # Define an initial scale and compute the mean and standard deviation of the signal
    scale = 0
    mean = np.mean(signal)
    std = np.std(signal)
    
    # Initialize arrays to store the smooth and fluctuation parts of the signal
    smooth = np.zeros((num_scales, len(signal)))
    fluctuation = np.zeros((num_scales, len(signal)))
    
    # Perform ISD at each scale
    for i in range(num_scales):
        # Decompose the signal into a smooth part and a fluctuation part
        threshold = std * 2**(scale/2)
        smooth[i] = np.where(abs(signal - mean) &amp;lt; threshold, signal, mean)
        fluctuation[i] = signal - smooth[i]
        
        # Update the mean and standard deviation for the next scale
        mean = np.mean(smooth[i])
        std = np.std(fluctuation[i])
        
        # Increment the scale for the next iteration
        scale += 1
    
    return smooth, fluctuation

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Heres a brief explanation of the steps involved in the algorithm:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The input signal is decomposed into a set of scales, with the number of scales specified by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_scales&lt;/code&gt; parameter.&lt;/li&gt;
  &lt;li&gt;The mean and standard deviation of the signal are computed at the initial scale.&lt;/li&gt;
  &lt;li&gt;For each scale, the signal is decomposed into a smooth part and a fluctuation part using a threshold based on the standard deviation and the current scale.&lt;/li&gt;
  &lt;li&gt;The mean and standard deviation are updated for the next scale using the smooth and fluctuation parts of the previous scale.&lt;/li&gt;
  &lt;li&gt;The process is repeated for the specified number of scales.&lt;/li&gt;
  &lt;li&gt;The output of the algorithm is a set of arrays containing the smooth and fluctuation parts of the signal at each scale.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note that this is just one possible implementation of ISD, and there are many variations and extensions of the algorithm that can be used depending on the specific requirements of the application.&lt;/p&gt;

&lt;p&gt;See &lt;span title=&quot;There is no note that matches this link.&quot; class=&quot;invalid-link&quot;&gt;  &lt;span class=&quot;invalid-link-brackets&quot;&gt;[[&lt;/span&gt;  2023-05-14-ITD  &lt;span class=&quot;invalid-link-brackets&quot;&gt;]]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In this paper,we impose a new signal analysis method,called intrinsic time-scale decomposition
(ITD),that was first introduced by G. Frei Mark and Ivan Osorio in 2006.This method is specifically
proposed for application to non-stationary and nonlinear signals in nature and obtained from complex
systems with underlying dynamics that change on multiple time-scales simultaneously.The ITD
algorithm has the adavantages of low computation complexity, small edge effects and fast processing
speed, and avoids wavelet base seletion compared with decomposition algorithms based on EMD and
wavelet.According to direct extraction of the signal energy associated with various intrinsic time
scales,the ITD decomposes an input signal into a set of proper rotation components and a residual
signal.And the proper rotations may be applied to analyse the instantaneous information.Based on the
statistic features of uniformly distributed white noise using the ITD, an adaptive denoising algorithm
based on ITD is proposed.Compared with the de-noising based on wavelet threshold and EMD,the
simulation results show that the ITD algorithm has a good de-noising properties.&lt;/p&gt;

&lt;h3 id=&quot;intrinsic-time-scale-decomposition&quot;&gt;Intrinsic Time-scale Decomposition&lt;/h3&gt;

&lt;p&gt;The purpose of the intrinsic time-scale decomposition is to decompose the signal into a series of proper rotation components and a monotonous trend component,in ordor to obtain meaningful instantaneous frequency and amplitude information.&lt;/p&gt;

&lt;p&gt;A real-valued signal $\left{X_t, t \geq 0\right}$ is given, and we define an operator $L$, which decomposes the signal $X_t$ into the baseline signal and a proper rotation. The $X_t$ can be expressed as&lt;/p&gt;

&lt;p&gt;\(X_t=L X_t+(1-L) X_t=L_t+H_t\)
Where $L_t=L X_t$ is the baseline signal and $H_t=(1-L) X_t$ is a proper rotation. $\left{\tau_k, k=1,2, \ldots\right}$ is the local extrema of $X_t$, and especially define $\tau_0=0$. To simplify notation,let $X_k=X\left(\tau_k\right)$ and $L_k=L\left(\tau_k\right)$&lt;/p&gt;

&lt;p&gt;Provided that $X_t$ is known for $\left[0, \tau_{k+2}\right]$ and that $L_t$ and $H_t$ have been given on $\left(0, \tau_k\right]$. Then the baseline signal $L_t$ can be defined on the interval $\left(\tau_k, \tau_{k+1}\right]$ between the continuous extrema as follows:
\(L X_t=L_t=L_k+\left(\frac{L_{k+1}-L_k}{X_{k+1}-X_k}\right)\left(X_t-X_k\right), t \in\left(\tau_k, \tau_{k+1}\right] .\)
Where
\(L_{k+1}=L_t=\alpha\left(X_k+\left(\frac{\tau_{k+1}-\tau_k}{\tau_{k+2}-\tau_k}\right)\left(X_{k+2}-X_k\right)\right)+(1-\alpha) X_{k+1}\)
$\alpha$ acts as a linear gain on the amplitude of the proper rotation component.And $0&amp;lt;\alpha&amp;lt;1$ is typically fixed with $\alpha=0.5$. The proper rotation $H_t$ can also be defined, as
\(H X_t=H_t=(1-L) X_t=X_t-L_t\)
The rotation signal, $H_t$, indicates the highest relative frequency of the input signal. And the baseline signal, $L_t$, indicates the lowest relative frequency of the input signal. The baseline signal is then treated as new input signal. The process continues until a monotonic trend is reached. This decomposes the input signal into a sequence of proper rotations of successively decreasing instantaneous frequency at each subsequent level of the decomposition. So the decomposition of $X_t$ can be written as
\(\begin{aligned}
&amp;amp; X_t=H X_t+L X_t=H X_t+(H+L) L X_t \\
&amp;amp; =\left(H+H L+L^2\right) X_t \\
&amp;amp; =\left(H+H L+(H+L) L^2\right) X_t \\
&amp;amp; =\left(H+H L+H L^2+L^3\right) X_t \\
&amp;amp; =\ldots \ldots=\left(H \sum_{k=0}^{p-1} L^k+L^p\right) X_t
\end{aligned}\)
Where $H L^k X_t$ is the $(k+1)$ st level proper rotation and $L^p X_t$ is either the residual signal or the lowest frequency baseline signal before the monotonic trend is obtained. Here the formula, $H+L=1$, is defined, and we also apply for the compression sum formula : $1-L^p=(1-L)\left(1+L+\ldots+L^{p-2}+L^{p-1}\right)$&lt;/p&gt;

&lt;p&gt;Once the input signal has been decomposed into a set of proper rotations and a residual signal by the ITD, we are able to analysis the proper rotations to extract the instantaneous amplitude, phase and frequency.&lt;/p&gt;

&lt;h3 id=&quot;denoising-principle-based-on-the-itd&quot;&gt;Denoising Principle Based on the ITD&lt;/h3&gt;

&lt;p&gt;The numerical experiments are made to study the characteristics of white noise using the ITD. The results show that each proper rotation of the ITD is a normal distribution with mean 0 and variance $\delta^2$, that $\delta^2$ is variance of each rotation; and all the Fourier spectra except the first one have nearly the same shapes in terms of the semi-logarithmic scale. At the same time, we can obtain a simple equation that presents the relation of the energy density $E_n$ and the averaged period $\overline{T_n}$, i.e.
\(\begin{aligned}
&amp;amp; E_n \overline{T_n}=\text { const } \\
&amp;amp; \ln E_n+\ln \overline{T_n}=\text { const }
\end{aligned}\)
Where $E_n=\frac{1}{N} \sum_{i=1}^n\left[C_n(i)^2\right]$ is the energy density of the $n$th proper rotation with the data length of $\mathrm{N}$, and $\bar{T}&lt;em&gt;n=N / N&lt;/em&gt;{\max }$ is the averaged period of the $n$th proper rotation with $N_{\max }$ standing for the number of the maximum extrema in $C_n$. If a white-noise series is normalized, the constant in equation (6) is unity. Therefore, the constant of equation (7) is zero, i.e.
\(\ln \overline{E_n}+\ln \overline{T_n}=0\)
Where $\overline{E_n}$ is the mean of $E_n$ when $n$ approaches infinity. Based on the probability density function theory, the energy density is the $\chi^2$ distribution for the time series is a normal distribution. The degrees of the $\chi^2$ distribution should be the mean of the energy.&lt;/p&gt;

&lt;p&gt;The verification of equation (8) is given in figure 1 . The random dataset is $10^6$ data points divided into 1000 samples with an identical length of 1000 data points. From Fig. 1, we can get the conclusion that the energy density and the averaged period of the proper rotations could deviate from the standard line, but this is very small.&lt;/p&gt;

&lt;p&gt;Having determined the distribution function of the energy of the Gaussian white noise, we will discuss spread of the confidence levels of the energy of white-noise samples. The spread of the confidence levels of the energy is the range of the energy distribution with the upper-energy side and lower-energy side.&lt;/p&gt;

&lt;p&gt;First, we define a new variable $\mathrm{y}$, as $y=\ln E_n$. The spread line can be defined as
\(y=\ln E_n \pm k \sqrt{\delta^2}=-\ln T_n \pm k \sqrt{2 / N} \cdot \sqrt{T_n}=-\ln T_n \pm k \sqrt{2 / N} \cdot e^{\ln T_n / 2}\)
Where
\(x=\ln T_n\)
So
\(y=-x \pm k \sqrt{2 / N} e^{x / 2}\)
Here $\mathrm{k}$ is a constant determined by the confidence levels. For example, we will have $\mathrm{k}$ equal to $-2.326,-0.675,-0.0,0.675$ and 2.326 for the first, 25 th, 50 th, 75 th and 99 th percentiles, respectively. The spread lines of the confidence level based on equation (11) are plotted in Fig. 2 with the first (the lower side) and 99th (the upper side) percentiles. The bold blue lines are the first (the lower side) and 99th (the upper side) percentiles.&lt;/p&gt;

&lt;p&gt;Based on the statistical characteristics of white noise, we put forward a method, to extract the used information of a dataset with unknown noise. Specifically, we need to find which rotations from the noisy dataset include information, and which rotations are purely noise. We introduce $x(t)=s(t)+n(t)$, where $s(t)$ is the used information and $n(t)$ is the white-noise with mean 0 and variance 1 .&lt;/p&gt;

&lt;p&gt;The specific steps are as follows.
(1) decompose $x(t)$ into the proper rotations basing on the ITD.
(2) caculate the energy density and the averaged period of each rotation.
(3) determine the spread of confidence level of an artifical white-noide as a reference.
(4) compare the energy density for the rotations of $x(t)$ with the spread functions of the reference noise; the rotations that locate in the bound of the spread of the confidence level of the reference noise are considered to be the noise. And the corresponding rotations are subtracted from the original siganl to get the de-noising signal.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Signal denoising</title>
   <link href="http://localhost:4000/2023/03/02/signal-denoising"/>
   <updated>2023-03-02T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/02/signal-denoising</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Signal denoising is one of the classic problems in signal processing research. Especially in the
additional Gaussian white noise condition, a variety of algorithms,such as median filtering, Wiener
filtering, wavelet denoising and denoising based on EMD are proposed. The wavelet method can
analyze the non-stationary and non-linear time series,but the basic wavelet function and the
thresholding are not the same at different scales.EMD is an adaptive method to decompose any signal
into a collection of intrinsic mode functions (IMFs).Although the introduction of the EMD carry on a
conceptual advance in time-frequency-energy analysis for non-stationary and nonlinear signals,it still
has some practical limitations that reduce its practical utility and may cause inaccuracies in
demonstrating signal dynamics.For example,its use of splines to obtain the IMF causes the EMD to
inherit all the well-know difficulties associated with this form of interpolation.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Wavelet denoising: Wavelet denoising is a widely used method for removing noise from signals. It uses wavelet transforms to decompose the signal into different scales and removes noise at each scale. The denoised signal is then reconstructed from the remaining wavelet coefficients.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Singular value decomposition (SVD) denoising: SVD denoising is a technique that uses matrix decomposition to extract the signal from the noisy data. It involves decomposing the data matrix into three matrices, which can be used to filter out noise and reconstruct the signal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Principal component analysis (PCA) denoising: PCA denoising is a method that uses statistical analysis to extract the signal from the noisy data. It involves decomposing the data into its principal components, which can be used to filter out noise and reconstruct the signal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Non-local means denoising: Non-local means denoising is a method that exploits the redundancy in the signal to remove noise. It involves finding similar patches in the signal and using them to estimate the noise-free signal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Total variation denoising: Total variation denoising is a method that uses the total variation of the signal to remove noise. It involves minimizing the total variation of the signal subject to a constraint that the noisy signal must match the original signal at some locations.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Zero Lag</title>
   <link href="http://localhost:4000/2023/03/01/zero-lag-error-correction"/>
   <updated>2023-03-01T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/03/01/zero-lag-error-correction</id>
   <content type="html">&lt;p&gt;Here, we acknowledge the EMA filter has an error term. That error for the current data sample is just Price  EMA[1]. We introduce this error term into the equation in addition to the value of the new data sample. We further change the amplitude of the error term by multiplying the error by a gain term. We call the new filter EC (for Error Correcting) instead of EMA. So the equation for the EC filter is:&lt;/p&gt;

\[EC = \alpha*(Price + gain*(Price  EC[1])) + (1  \alpha)*EC[1];\]

&lt;p&gt;The equation is simple, but its results are profound. If the gain is zero, the EC becomes just an EMA.
If the gain is sufficiently large the error term causes EC to exactly track the price for all practical
purposes. That is, there is virtually no lag and virtually no smoothing.&lt;/p&gt;

&lt;p&gt;Therefore, we seek a value of gain that is a happy medium between tracing out the price and tracing out the EMA. We do this by limiting the maximum amount of allowable gain. If the difference between the price and the previous value of EC is small we do not want a large value of gain. Further, the previous value of EC can be either greater than or less than the current price.&lt;/p&gt;

&lt;p&gt;Therefore, to properly apply the error correction the gain must swing both positive and negative.&lt;/p&gt;

&lt;p&gt;There are two user inputs: the length of the equivalent SMA and the Gain Limit. Actually the Gain Limit input is ten times the actual gain used in the computation because the error correcting loop variable increments in steps of 1 and we want the gain to be incremented in steps of 0.1.&lt;/p&gt;

&lt;p&gt;The smoothing factor alpha and EMA are computed after the variables are declared.
Next, a loop searches for the least amount of error, varying gain from the lower Gain Limit to the
upper Gain Limit. When a lower error is computed, the values of best gain and least error are
recorded. Once the loop has completed its work, the BestGain value is used to compute the Error
Corrected (EC) indicator. Then, both the EMA and EC are plotted on the chart.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Inputs:
	Length(20),
	GainLimit(50);
Vars:
	alpha(0),
	Gain(0),
	BestGain(0),
	EC(0),
	Error(0),
	LeastError(0),
	EMA(0);
alpha = 2 / (Length + 1);
EMA = alpha*Close + (1 - alpha)*EMA[1];
LeastError = 1000000;
For Value1 = -GainLimit to GainLimit Begin
	Gain = Value1 / 10;
	EC = alpha*(EMA + Gain*(Close - EC[1])) + (1 - alpha)*EC[1];
	Error = Close - EC;
	If AbsValue(Error) &amp;lt; LeastError Then Begin
		LeastError = AbsValue(Error);
		BestGain = Gain;
	End;
End;
EC = alpha*(EMA + BestGain*(Close - EC[1])) + (1 - alpha)*EC[1];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Online algorithms for Blind Source Seperation</title>
   <link href="http://localhost:4000/2023/02/28/online-blind-source-seperation"/>
   <updated>2023-02-28T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/28/online-blind-source-seperation</id>
   <content type="html">&lt;p&gt;Real-time online algorithms for blind source separation (BSS) are those that process incoming data in real-time, without requiring the entire data set to be available beforehand. Here are some examples of real-time online BSS algorithms:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Online independent vector analysis (IVA): IVA is an extension of independent component analysis (ICA) that allows for real-time processing of data streams. It uses an online learning rule to update the mixing matrix estimates as new data arrives.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;FastICA online: FastICA is a popular ICA algorithm that has been adapted for online processing. The algorithm updates the mixing matrix estimates using a recursive algorithm that requires less computational resources than batch processing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Recursive least squares (RLS)-based BSS: RLS is a widely used algorithm for adaptive filtering and has been adapted for BSS. It uses a recursive updating rule to estimate the mixing matrix and source signals as new data arrives.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Subspace tracking-based BSS: Subspace tracking algorithms such as the subspace recursive least squares (SRLS) algorithm can be used for online BSS. The algorithm tracks the subspace of the mixing matrix and updates the estimates as new data arrives.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Online joint approximate diagonalization of eigenmatrices (OJADE): OJADE is an online version of the JADE algorithm for joint approximate diagonalization of eigenmatrices. It updates the estimates of the mixing matrix and source signals as new data arrives.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These algorithms have been shown to be effective for real-time BSS and can be used in applications such as audio and speech processing, EEG analysis, and telecommunications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Preprocessing for Blind Source Seperation</title>
   <link href="http://localhost:4000/2023/02/27/preprocessing-for-blind-source-seperation"/>
   <updated>2023-02-27T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/27/preprocessing-for-blind-source-seperation</id>
   <content type="html">&lt;h3 id=&quot;preprocessing-techniques-for-blind-source-separation&quot;&gt;Preprocessing Techniques for Blind Source Separation&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Permutation alignment:
Permutation alignment is a technique used to align the sources in a way that maximizes their independence. Since the order in which the sources are mixed is unknown in BSS, it is often necessary to align the sources by permuting them in a way that maximizes their independence. This can be done using techniques such as joint diagonalization or maximum likelihood estimation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nonlinear decorrelation:
Nonlinear decorrelation techniques such as kernel PCA or independent subspace analysis (ISA) can be used to transform the signals so that they are uncorrelated and higher-order statistics are taken into account. This can be useful for separating sources that are highly correlated.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Robust centering and scaling:
Centering and scaling can be sensitive to outliers in the data, so robust methods such as median centering and scaling or rank-based normalization can be used instead.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Blind channel identification:
In some cases, it may be necessary to identify the mixing matrix or channel responses before attempting to separate the sources. Blind channel identification techniques such as blind source separation via constant modulus algorithm (BSS-CMA) or blind source separation via time-frequency masking (BSS-TF) can be used for this purpose.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Time-frequency analysis:
The mixture signals may be transformed into the time-frequency domain using techniques such as wavelet analysis or spectrogram analysis to extract features that are more easily separable. These features can then be used as input for a blind source separation algorithm.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Whitening and Quasi Whitening</title>
   <link href="http://localhost:4000/2023/02/26/whitening"/>
   <updated>2023-02-26T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/26/whitening</id>
   <content type="html">&lt;h2 id=&quot;quasi-whitening-of-sensor-matrices&quot;&gt;Quasi-Whitening of Sensor Matrices&lt;/h2&gt;

&lt;p&gt;In signal processing and machine learning, sensor matrices are often used to represent high-dimensional data collected from sensors. These matrices can be analyzed using techniques such as independent component analysis (ICA) or principal component analysis (PCA), but these methods often assume that the samples are uncorrelated and have unit variance. Quasi-whitening is a preprocessing technique that can transform a given sensor matrix into a form that has these desirable statistical properties.&lt;/p&gt;

&lt;p&gt;The goal of quasi-whitening is to transform the sensor matrix in such a way that the samples become uncorrelated and have unit variance. This can help improve the performance of algorithms that rely on these statistical properties. The term quasi refers to the fact that the transformed matrix is not perfectly whitened, meaning that the samples are not completely uncorrelated and do not have exactly unit variance. However, the transformation is still useful because it can significantly reduce the correlation among the sensor samples, making them more suitable for subsequent analysis.&lt;/p&gt;

&lt;p&gt;One common technique for quasi-whitening a sensor matrix is to use a preprocessing step called decorrelation, which involves applying a matrix transformation to the original sensor matrix to eliminate correlations among the samples. After decorrelation, the transformed matrix can be further scaled so that each sample has unit variance.&lt;/p&gt;

&lt;p&gt;The decorrelation transformation can be achieved using the following equation:&lt;/p&gt;

\[X&apos; = DX\]

&lt;p&gt;where $X$ is the original sensor matrix, $D$ is a decorrelation matrix, and $X$ is the transformed matrix. The decorrelation matrix $D$ is typically computed using the eigenvalue decomposition of the sample covariance matrix of $X$. Specifically, if the sample covariance matrix of $X$ is denoted by $C$, then $D$ can be computed as:&lt;/p&gt;

\[D = C^{-1/2}\]

&lt;p&gt;where $C^{-1/2}$ is the matrix inverse square root of $C$. This transformation has the property that the transformed matrix $X$ has a sample covariance matrix that is approximately equal to the identity matrix.&lt;/p&gt;

&lt;p&gt;After decorrelation, the transformed matrix $X$ can be further scaled so that each sample has unit variance. This is achieved using the following equation:&lt;/p&gt;

\[X&apos;&apos; = \frac{X&apos;}{\sqrt{\mathrm{diag}(X&apos;^TX&apos;)}}\]

&lt;p&gt;where $\mathrm{diag}(A)$ denotes the diagonal elements of matrix $A$. This transformation scales each sample so that it has unit variance, while preserving the decorrelation achieved by the earlier transformation.&lt;/p&gt;

&lt;p&gt;In summary, quasi-whitening is a useful preprocessing technique for improving the performance of signal processing and machine learning algorithms that rely on uncorrelated and unit variance samples. By decorrelating and scaling the sensor matrix, quasi-whitening can reduce the impact of correlations among the samples and make them more suitable for subsequent analysis.&lt;/p&gt;

&lt;h1 id=&quot;whitening-for-blind-source-signal-separation&quot;&gt;Whitening for Blind Source Signal Separation&lt;/h1&gt;

&lt;p&gt;In many applications such as speech recognition and biomedical signal processing, it is common to encounter signals that are mixtures of multiple sources. Blind source separation (BSS) is the problem of separating these sources from their mixture without any prior knowledge of the sources or the mixing process. One technique used for BSS is whitening, which transforms the mixture to a new space where the sources are uncorrelated and have unit variance.&lt;/p&gt;

&lt;h2 id=&quot;whitening&quot;&gt;Whitening&lt;/h2&gt;

&lt;p&gt;Whitening is a linear transformation that maps a random vector $\mathbf{x} \in \mathbb{R}^n$ with covariance matrix $\mathbf{\Sigma}$ to a new vector $\mathbf{y} \in \mathbb{R}^n$ with identity covariance matrix, i.e.,&lt;/p&gt;

\[\mathbf{y} = \mathbf{W} \mathbf{x},\]

&lt;p&gt;where $\mathbf{W}$ is a square matrix such that $\mathbf{W}\mathbf{\Sigma}\mathbf{W}^T = \mathbf{I}$, where $\mathbf{I}$ is the identity matrix.&lt;/p&gt;

&lt;p&gt;To see why this is useful for BSS, consider a mixture of $m$ sources:&lt;/p&gt;

\[\mathbf{x}(t) = \sum_{i=1}^m s_i(t) \mathbf{a}_i,\]

&lt;p&gt;where $\mathbf{a}_i$ is the mixing matrix for the $i$th source, and $s_i(t)$ is the signal of the $i$th source at time $t$. We assume that the sources are statistically independent and have zero mean and unit variance. The covariance matrix of $\mathbf{x}$ is then&lt;/p&gt;

\[\mathbf{\Sigma}_x = \mathbb{E}[\mathbf{xx}^T] = \sum_{i=1}^m \mathbf{a}_i \mathbf{a}_i^T.\]

&lt;p&gt;To separate the sources, we want to find a matrix $\mathbf{B}$ such that&lt;/p&gt;

\[\mathbf{y}(t) = \mathbf{B} \mathbf{x}(t) = \sum_{i=1}^m b_i s_i(t) \mathbf{e}_i,\]

&lt;p&gt;where $\mathbf{e}_i$ is the $i$th canonical basis vector. The covariance matrix of $\mathbf{y}$ is then&lt;/p&gt;

\[\mathbf{\Sigma}_y = \mathbb{E}[\mathbf{yy}^T] = \mathbf{B} \mathbf{\Sigma}_x \mathbf{B}^T.\]

&lt;p&gt;If we choose $\mathbf{B} = \mathbf{W}^{-1}$, then we have&lt;/p&gt;

\[\mathbf{\Sigma}_y = \mathbf{W}^{-1} \mathbf{\Sigma}_x (\mathbf{W}^{-1})^T = \mathbf{W}^{-1} \mathbf{W} \mathbf{\Sigma}_s \mathbf{W}^T (\mathbf{W}^{-1})^T = \mathbf{I},\]

&lt;p&gt;where $\mathbf{\Sigma}_s$ is the diagonal matrix of the variances of the sources.&lt;/p&gt;

&lt;p&gt;Thus, by whitening the mixture with $\mathbf{W}$, we transform the problem of BSS into a problem of finding a linear transformation that makes the sources uncorrelated.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Blind source separation for noisy time series by combining non-Gaussianity and time correlation</title>
   <link href="http://localhost:4000/2023/02/25/blind-source-seperation-by-combining-non-gaussianity-and-time-correlation"/>
   <updated>2023-02-25T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/25/blind-source-seperation-by-combining-non-gaussianity-and-time-correlation</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;This paper addressed the separation of noisy time series
(noisy signals with time structure). Based on the non-
Gaussianity of innovations, we first present an objective
function with negentropy forms about innovations of time
series. Furthermore, this criterion is extended for the noisy
time series separation through combing Gaussian moments
into it. Maximizing this objective function, a simple blind
source separation algorithm is presented.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Generally,
classical BSSmethods often utilize the non-Gaussianity as a
leading principle, which only use the marginal distributions
of the estimated signals and completely ignore any time
structure in their basic forms. However, in many applications,
what are mixed are not random variables but time signals,
or time series. Moreover, it has been shown interestingly
that under some restrictions, the time-dependency information
along is sufficient to estimated independent components
[5, 6, 7, 8]. Therefore, it would be most useful to
define a more general method that finds interesting projections
of time series using both the non-Guassianity and the
time structure of the projections.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Moreover, in many
cases we often assume that the innovations of the time series
are super-Gaussian, which seems to be the preponderant 
case in natural data. In this paper, we make
full use of the non-Gaussianity of the innovations to generate
the criterion based on the negentropy expression of the
innovations firstly. Furthermore, this criterion is developed
for the blind source separation of noisy time series. This
novel approaches combine the Gaussian moments and the
non-Gaussianity of the innovations, where Gaussian moments
are selected as the replacement of the nonquadratic
functions in negentropy expression. Maximizing this objective
function, a blind source separation algorithm is derived.
Experiments in the following show that in the separation
of noisy time series, the proposed algorithm outperforms
some existing algorithms, such as noise techniques
the algorithm of [12] (simplified with NoisyCP), the algorithm
in (called FastNoisyICA), and noise-free
approach GradCP algorithm.&lt;/p&gt;

&lt;h2 id=&quot;proposed-algorithm&quot;&gt;Proposed algorithm&lt;/h2&gt;

&lt;h3 id=&quot;quasi-whitening&quot;&gt;Quasi-whitening&lt;/h3&gt;

&lt;p&gt;Denote the observed sensor signals $\mathrm{x}(t)=$ $\left(x_1(t), \cdots, x_m(t)\right)^T$ described by matrix equation
\(\mathbf{x}(t)=\mathbf{A} \mathbf{s}(t)+\mathbf{n}(t)\)
where $\mathbf{A}$ is an $m \times n$ unknown mixing matrix $(n \leq m)$, $\mathbf{s}(t)=\left(s_1(t), \cdots, s_n(t)\right)^T$ is a vector of unknown temporally correlated sources (zero-mean and unit-variance), $\mathbf{n}(t)=\left(n_1(t), \cdots, n_m(t)\right)^T$ is a vector of additive noise which is modeled as a stationary, temporally white, zeromean complex random process independent of the source signals, and whose covariance matrix is defined as $\boldsymbol{\Sigma}$ (that is, $\boldsymbol{\Sigma}=E\left{\mathbf{n}(t) \mathbf{n}(t)^T\right}$ ) and $t=1,2, \ldots, T$ is the time index. It is further assumed that the dimensions of $\mathrm{x}$ and $\mathrm{s}$ are equal, i.e. $m=n$ in this paper.&lt;/p&gt;

&lt;p&gt;It must be noted, however, in the preliminary whitening, the effect of noise must be taken into account. This is quite simple if the noise covariance matrix $\Sigma$ is known or can be estimated. Provided that the measured sensor signals $\mathbf{x}(t)$ has the covariance matrix denoted by $\mathbf{C}=E\left{\mathbf{x}(t) \mathbf{x}(t)^T\right}$, the ordinary whitening should be changed into the following quasi-whitening operation
\(\tilde{\mathbf{x}}(t)=(\mathbf{C}-\mathbf{\Sigma})^{-\frac{1}{2}} \mathbf{x}(t)\)
In other words, the covariance matrix $(\mathbf{C}-\mathbf{\Sigma})$ of the noisefree data should be used in whitening instead of the covariance matrix $\mathbf{C}$ of the noisy data. The quasi-whiten data $\tilde{\mathbf{x}}$ follows a noisy ICA model as well, that is
\(\tilde{\mathbf{x}}(t)=\mathbf{B s}(t)+\tilde{\mathbf{n}}(t)\)
where $\mathbf{B}=(\mathbf{C}-\boldsymbol{\Sigma})^{-\frac{1}{2}} \mathbf{A}$ is an orthogonal mixing matrix, and noise $\tilde{\mathbf{n}}$ is a linear transform of the original noise, which having the following covariance matrix $[13,14]$
\(\tilde{\mathbf{\Sigma}}=E\left\{\tilde{\mathbf{n}}(t) \tilde{\mathbf{n}}(t)^T\right\}=(\mathbf{C}-\mathbf{\Sigma})^{-\frac{1}{2}} \mathbf{\Sigma}(\mathbf{C}-\mathbf{\Sigma})^{-\frac{1}{2}}\)&lt;/p&gt;
&lt;h3 id=&quot;contrast-function&quot;&gt;Contrast function&lt;/h3&gt;

&lt;p&gt;Denote the noise-free data by $\mathbf{y}(t)=\mathbf{B s}(t)$, the basic idea in the complexity pursuit is to find projection $\mathbf{w}^T \mathbf{y}(t)$ such that the Kolmogoroff complexity of the projection is minimized. Similarly, we consider predictive coding of a scalar signal $z(t)=\mathbf{w}^T \mathbf{y}(t)(t=1, \ldots, T)$. Suppose the value of $z(t)$ is predicted from the preceding values by some function to be specified
\(\hat{z}(t)=f(z(t-1), \ldots, z(1))\)
To code the actual value $z(t)$, the innovation
\(\delta z(t)=z(t)-\hat{z}(t)\)
is coded by a scalar quantization method. Assuming that the innovation is stationary and ergodic and that the predictor uses a history of bounded length, and ignoring border effects. In practice, we need to fix the structure of the predictor $f$ and use a computationally simple predictor structure, given by a linear autoregressive model
\(\hat{z}(t)=\sum_{\tau&amp;gt;0} \alpha_\tau z(t-\tau)\)
Note that in [9] it has been pointed that minimizing the first term of their objective function amounts to finding direction in which the innovation is as non-Gaussianity as possible. In particular, in many cases we can assume that the innovations are super-Gaussian, which seems to be the preponderant case in natural data $[9,10,11]$. Therefore, the innovations can be considered as a random vector with non-Gaussianity. There also is a fact that the higher nonGaussianity of the innovations corresponds to the more sparseness of theirs and furthermore the better performance of source separations.&lt;/p&gt;

&lt;p&gt;Actually, non-Gaussianity is of paramount importance in ICA estimation, which is a simple and intuitive principle for estimating ICs. The fourth-order cumulant, or kurtosis is the first practical measure of non-Gaussianity, however, it gives estimators that are very sensitive to outliers and have large mean square errors (at least for super-Gaussian data) $[4,13,14]$. Therefore, we use the information-theoretic quantity called negentropy as an alternative measure of innovations non-Gaussianity, and derive the corresponding algorithms for this measure. Denote the contrast functions of the innovations $\delta z(t)$ as follows
\(J_G(\delta z(t))=\left[E\{G(\delta z(t)\}-E\{G(\nu)\}]^2\right.\)
where the function $G$ is a sufficiently regular nonquadratic function, $\nu$ is a standardized Gaussian variable, and innovations $\delta z(t)=\mathbf{w}^T \delta \mathbf{y}(t)$ are mutually statistically independent and have zero mean and unit variance, where $\delta \mathbf{y}(t)=\mathbf{y}(t)-\sum_{\tau&amp;gt;0} \alpha_\tau \mathbf{y}(t-\tau)$&lt;/p&gt;

&lt;h3 id=&quot;gaussian-moments&quot;&gt;Gaussian moments&lt;/h3&gt;

&lt;p&gt;In formula (8), however, the noise term was not considered at all. Therefore, we might extend this formula to the case when noise is present. It must be pointed out that these approaches given in Section 2.2 could be used for noisy data, if only we were able to estimate $J_G(\delta z(t))$ of the noise-free data from the noisy observations $x$. The main point of this problem is to select some suitable measures, which are immune to Gaussian noise, or at least, whose values for the original data can be easily estimated from noisy observations. Denote by
\(\varphi_c(x)=\frac{1}{c} \varphi\left(\frac{x}{c}\right)=\frac{1}{\sqrt{2 \pi} c} \exp \left(-\frac{x^2}{2 c^2}\right)\)
the Gaussian density function of variance $c^2$, and by $\varphi_c^{(k)}(x)$ the $k$-th $(k&amp;gt;0)$ derivative of $\varphi_c(x)$. Denote further by $\varphi_c^{(-k)}(x)$ the $k$-th integral function of $\varphi_c(x)$, obtained by $\varphi_c^{(-k)}(x)=\int_0^x \varphi_c^{(-k+1)}(\xi) d \xi$, where we define $\varphi_c^{(0)}(x)=\varphi_c(x)$. Then we have the following theorem $[12,13,14]$&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;u&gt;Theorem 1&lt;/u&gt; Let $v$ be any non-Gaussian random variable, and denote by $n$ an independent Gaussian noise variable of variance $\sigma^2$. Define the Gaussian function $\varphi$ as in (9). Then for any constant $c&amp;gt;\sigma^2$, we have&lt;/em&gt;
\(E\left\{\varphi_c(v)\right\}=E\left\{\varphi_d(v+n)\right\}\)
&lt;em&gt;with $d=\sqrt{c^2-\sigma^2}$. Moreover, (10) still holds when $\varphi$ is replaced $\varphi^{(k)}$ for any integer index $k$.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This theorem means that we can estimate the ICs from noisy observations by maximizing a general contrast function of form (8), where the estimation of the statistics $E{G(\delta z(t)}$ of the noise-free data is made possible by using $E\left{\varphi_c^{(k)}(\delta z(t)}\right.$. The statistics of the form $E\left{\varphi_c^{(k)}(\delta z)\right}$ is called the Gaussian moments of the innovations $\delta z(t)$ $[12,13,14]$. Thus from (8) and (10), we can estimate the noisy model by maximizing, for the innovations of the quasi-whitened data $\tilde{\mathrm{x}}$, the following contrast function
\(\max _{\|\mathbf{w}\|=1} \Phi\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)=\left[E\left\{\varphi_{d(\mathbf{w})}^{(k)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right\}-E\left\{\varphi_c^{(k)}(\nu)\right\}\right]^2\)
where $\delta \tilde{\mathbf{x}}(t)=\tilde{\mathbf{x}}(t)-\sum_{\tau&amp;gt;0} \alpha_\tau \tilde{\mathbf{x}}(t-\tau), \mathbf{w}^T \delta \tilde{\mathbf{x}}(t)=$ $\delta z(t)+\mathbf{w}^T\left(\tilde{\mathbf{n}}(t)-\sum_{\tau&amp;gt;0} \alpha_\tau \tilde{\mathbf{n}}(t-\tau)\right)$, correspondingly, $d(\mathbf{w})=\sqrt{c^2-\left(1+\sum_{\tau&amp;gt;0} \alpha_\tau^2\right) \mathbf{w}^T \tilde{\mathbf{\Sigma}} \mathbf{w}}$&lt;/p&gt;

&lt;h3 id=&quot;learning-algorithm&quot;&gt;Learning algorithm&lt;/h3&gt;

&lt;p&gt;Before we derive the learning algorithm, it is worth noting that the maxima of the approximation of the negentropy of the $\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)$ are typically obtained at certain optima of $E\left{\varphi_{d(\mathbf{w})}^{(k)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right}[4]$.
Note that
\(\varphi_c^{(k)}(x)=\varphi^{(k)}\left(\frac{x}{c}\right) c^{(-k-1)}\)
and denote as above
\(\begin{aligned}
&amp;amp; d(\mathbf{w})=\sqrt{c^2-\left(1+\sum_{\tau&amp;gt;0} \alpha_\tau^2\right) \mathbf{w}^T \tilde{\mathbf{\Sigma}} \mathbf{w}} \\
&amp;amp; X=\mathbf{w}^T \delta \tilde{\mathbf{x}}(t), \\
&amp;amp; \tilde{d}=c^2-\left(1+\sum_{\tau&amp;gt;0} \alpha_\tau^2\right) \mathbf{w}^T \tilde{\mathbf{\Sigma}} \mathbf{w}
\end{aligned}\)
Then the gradient of $\operatorname{term} \varphi_{d(\mathbf{w})}^{(k)}(X)$ with respect to $\mathbf{w}$ can be computed as
\(\begin{aligned}
&amp;amp; \nabla_{\mathbf{w}} \varphi_{d(\mathbf{w})}^{(k)}(X)=\varphi_{d(\mathbf{w})}^{(k+1)}(X) \nabla_{\mathbf{w}} X-\frac{1}{2} d^{-2}(\mathbf{w}) \\
&amp;amp; \times\left(X \varphi_{d(\mathbf{w})}^{(k+1)}(X)+(k+1) \varphi_{d(\mathbf{w})}^{(k)}(X)\right) \nabla_{\mathbf{w}} \tilde{d} .
\end{aligned}\)
To proceed, we use the lemma in [14] to imply
\(\begin{aligned}
&amp;amp; d^{-2}(\mathbf{w})\left(X \varphi_{d(\mathbf{w})}^{(k+1)}(X)+(k+1) \varphi_{d(\mathbf{w})}^{(k)}(X)\right) \\
&amp;amp; =-\varphi_{d(\mathbf{w})}^{(k+2)}(X)
\end{aligned}\)
This means the gradient in (16) can be expressed as
\(\begin{aligned}
\nabla_{\mathbf{w}} \varphi_{d(\mathbf{w})}^{(k)}(X)= &amp;amp; \varphi_{d(\mathbf{w})}^{(k+1)}(X) \nabla_{\mathbf{w}} X \\
&amp;amp; +\frac{1}{2} \varphi_{d(\mathbf{w})}^{(k+2)}(X) \nabla_{\mathbf{w}} \tilde{d}
\end{aligned}\)&lt;/p&gt;

&lt;p&gt;That is
\(\begin{aligned}
&amp;amp; \nabla_{\mathbf{w}} \varphi_{d(\mathbf{w})}^{(k)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)=\varphi_{d(\mathbf{w})}^{(k+1)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right) \delta \tilde{\mathbf{x}}(t) \\
&amp;amp; -\left(1+\sum_{\tau&amp;gt;0} \alpha_\tau^2\right) \varphi_{d(\mathbf{w})}^{(k+2)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right) \tilde{\mathbf{\Sigma}} \mathbf{w} .
\end{aligned}\)
Suppose $\delta s_i(t)=s_i(t)-\sum_{\tau&amp;gt;0} \alpha_\tau^i s_i(t-\tau)(i=1, \ldots, n)$ are mutually independent and have zero mean and unit variance (assume that $\alpha_\tau^i, i=1, \ldots, n$ are the known constants). Therefore, the equation giving the fixed-point algorithm was given just like in $[4,15,16]$ as
\(\mathbf{w} \leftarrow E\left\{\nabla G\left(\mathbf{w}^T \delta \mathbf{y}(t)\right)\right\}-\mathbf{w} E\left\{G^{\prime \prime}\left(\mathbf{w}^T \delta \mathbf{y}(t)\right)\right\} .\)
Choosing $G(u)=\varphi_c^{(k)}(u)$ and using the above derivation, we obtain the gradient part as (19). By Theorem 1, we have
\(E\left\{G^{\prime \prime}\left(\mathbf{w}^T \delta \mathbf{y}(t)\right)\right\}=E\left\{\varphi_{d(\mathbf{w})}^{(k+2)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right\} .\)
Then we obtain
\(\begin{aligned}
\mathbf{w} \leftarrow &amp;amp; E\left\{\nabla_{\mathbf{w}} \varphi_{d(\mathbf{w})}^{(k)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right\} \\
&amp;amp; -\mathbf{w} E\left\{\varphi_{d(\mathbf{w})}^{(k+2)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right\} .
\end{aligned}\)
Thus we obtain the form of the fixed-point iteration for the innovations of the quasi-whitened data
\(\begin{aligned}
&amp;amp; \mathbf{w} \leftarrow E\left\{\varphi_{d(\mathbf{w})}^{(k+1)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right) \delta \tilde{\mathbf{x}}(t)-\left(1+\sum_{\tau&amp;gt;0} \alpha_\tau^2\right)\right. \\
&amp;amp; \left.\times \tilde{\mathbf{\Sigma}} \mathbf{w} \varphi_{d(\mathbf{w})}^{(k+2)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right\}-E\left\{\mathbf{w} \varphi_{d(\mathbf{w})}^{(k+2)}\left(\mathbf{w}^T \delta \tilde{\mathbf{x}}(t)\right)\right\} .
\end{aligned}\)
Note that we could adapt parameter $c$ before every step so that $d(\mathbf{w})=\sqrt{c^2-\mathbf{w}^T \tilde{\mathbf{\Sigma}} \mathbf{w}}=1[13,14]$, and correspondingly choosing $G(u)=\varphi^{(k)}(u)$. Thus the learning rule is
\(\begin{aligned}
\mathbf{w} \leftarrow &amp;amp; E\left\{( \tilde { \mathbf { x } } ( t ) - \sum _ { \tau &amp;gt; 0 } \alpha _ { \tau } \tilde { \mathbf { x } } ( t - \tau ) ) g \left(\mathbf{w}^T(\tilde{\mathbf{x}}(t)-\right.\right. \\
&amp;amp; \left.\left.\left.\sum_{\tau&amp;gt;0} \alpha_\tau \tilde{\mathbf{x}}(t-\tau)\right)\right)\right\}-\left(1+\sum_{\tau&amp;gt;0} \alpha_\tau^2\right) \tilde{\mathbf{\Sigma}} \mathbf{w} \\
&amp;amp; \times E\left\{g^{\prime}\left(\mathbf{w}^T\left(\tilde{\mathbf{x}}(t)-\sum_{\tau&amp;gt;0} \alpha_\tau \tilde{\mathbf{x}}(t-\tau)\right)\right)\right\} \\
&amp;amp; -\mathbf{w} E\left\{g^{\prime}\left(\mathbf{w}^T\left(\tilde{\mathbf{x}}(t)-\sum_{\tau&amp;gt;0} \alpha_\tau \tilde{\mathbf{x}}(t-\tau)\right)\right)\right\} \\
\mathbf{w} \leftarrow &amp;amp; \frac{\mathbf{w}}{\|\mathbf{w}\|},
\end{aligned}\)
where $\tilde{\mathbf{\Sigma}}$ is given by (4) and the function $g$ is the derivative of $G, g^{\prime}$ corresponds to the derivative of $g$. Example of choice is $G(u)=\log \cosh (u)$, which is an approximation of $\varphi^{(-2)}$ and has been widely used in ICA $[1,2,12,13,14]$.
A simple special case of the method is obtained when the autoregressive model has just one predicting term [9]
\(\hat{z}(t)=\alpha_1 z(t-1)\)
The lag need not be equal to 1 , but this is the basic case. The parameter $\alpha_1$ in the algorithm can then be estimated simply by a least-squares method as [9]
\(\hat{\alpha}_1=\mathbf{w}^T E\left\{\tilde{\mathbf{x}}(t) \tilde{\mathbf{x}}(t-1)^T\right\} \mathbf{w}\)&lt;/p&gt;
&lt;h3 id=&quot;simulations&quot;&gt;Simulations&lt;/h3&gt;

&lt;p&gt;In this section, extensive computer simulations were carried out to verify the validity of the proposed algorithm, which compared to the noise techniques- FastnoisyICA algorithm, NosiyCP algorithm and noise-free methodGradCP algorithm. In the comparisons, the quasi-whitening data were applied as the inputs of all the algorithms. The step sizes in GradCP algorithm and NoisyCP algorithm were taken equal to 1 , the time delays of GradCP, NoisyCP and our algorithm were 1 and the nonlinearity functions of all algorithms were chosen as $G(u)=\log \cosh (u)$. Note that in the simulations, the symmetric orthogonalization version of all algorithms for quasi-whitening data was used for estimating the weight vectors $\mathbf{w}&lt;em&gt;i$ in parallel. Moreover, the performance of algorithms to the estimated signal is measured by performance index (PI), which is defined as follows
\(\begin{aligned}
\mathrm{PI}= &amp;amp; \frac{1}{n^2}\left\{\sum_{i=1}^n\left(\sum_{j=1}^n \frac{\left|p_{i j}\right|}{\max _k\left|p_{i k}\right|}-1\right)\right. \\
&amp;amp; \left.+\sum_{j=1}^n\left(\sum_{i=1}^n \frac{\left|p_{i j}\right|}{\max _k\left|p_{k j}\right|}-1\right)\right\},
\end{aligned}\)
where $p&lt;/em&gt;{i j}$ denotes the $i j$ th element of $n \times n$ matrix $\mathbf{P}=$ $\mathbf{W}^T \mathbf{B A}$, where $\mathbf{W}=\left(\mathbf{w}_1, \ldots, \mathbf{w}_n\right)$ is the demixing matrix, $\mathbf{B}$ corresponds to the orthogonal matrix in quasiwhitening operation and $\mathbf{A}$ is the mixing matrix. The larger value PI is, the poorer performance of the algorithm is. In the following experiments, we considered the separation of four signals using an AR(1) model, which have been applied in $[9,12]$. Signals 1 and 2 were created with superGaussian innovations and signals 3 and 4 with Gaussian innovations; all innovations had unit variance. Signals 1 and 3 had identical autoregressive coefficients $(0.25)$ and therefore identical autocovariances; signals 2 and 4 had identical coefficients $(0.5)$ as well. And here the sample size was 25000. The observations $\mathrm{x}$ with a white Gaussian noise (covariance $0.01 \mathrm{I}$ ) were generated by a $4 \times 4$ random mixing matrix. The performance was estimated as the average PI values of 50 independent trials. At every trial, four algorithms were run with 100 iterations respectively, which seemed to be always enough for convergence. Here $\mathbf{A}$ and W were initialized randomly.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Boundary effects</title>
   <link href="http://localhost:4000/2023/02/24/boundary-effects"/>
   <updated>2023-02-24T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/24/boundary-effects</id>
   <content type="html">&lt;p&gt;The boundary or endpoint effect is a common issue that arises when decomposing signals using various signal processing techniques, including the Fourier transform and its variants. It occurs because the signal at the boundaries is not continuous, and thus the signal decomposition may not be accurate near the edges of the signal.&lt;/p&gt;

&lt;p&gt;There are several techniques to deal with the boundary or endpoint effect in signal decomposition:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Zero-padding: One approach is to add zeros to the signal at the beginning and/or end of the signal before performing the decomposition. This increases the length of the signal and reduces the impact of the boundary effect. However, it does not completely eliminate the boundary effect, and the choice of the padding length can be subjective.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Windowing: Another approach is to apply a window function to the signal before performing the decomposition. A window function reduces the amplitude of the signal at the boundaries, thus reducing the boundary effect. However, it also introduces a trade-off between the accuracy of the decomposition and the width of the main lobe of the window function.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Overlap-add or overlap-save methods: These are techniques that divide the signal into overlapping segments, perform the decomposition on each segment, and then combine the decomposed segments using appropriate methods. This reduces the boundary effect and provides a more accurate decomposition of the signal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Circular convolution: This is a technique that assumes that the signal is periodic and performs the decomposition using the circular convolution instead of the linear convolution. This technique can eliminate the boundary effect completely, but it requires the signal to be periodic, which may not be the case for all signals.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In general, the choice of the technique to deal with the boundary effect depends on the specific application and the characteristics of the signal. Experimentation with different techniques can help identify the most suitable technique for a given application.&lt;/p&gt;

&lt;p&gt;Model aliasing phenomenon, also known as aliasing error or model folding, is a phenomenon that occurs when a mathematical model of a physical system is used to simulate or predict the behavior of the system, but the model is not able to accurately capture all the high-frequency dynamics of the system due to limited sampling or computation resources.&lt;/p&gt;

&lt;p&gt;This can lead to errors or inaccuracies in the model predictions, particularly at high frequencies, and can cause the model to behave as if the high-frequency dynamics are actually low-frequency dynamics. This is because the model cannot distinguish between the high-frequency dynamics and the low-frequency dynamics that have similar characteristics when sampled or computed.&lt;/p&gt;

&lt;p&gt;The aliasing phenomenon is related to the Nyquist-Shannon sampling theorem, which states that in order to accurately capture the dynamics of a system, the sampling rate must be at least twice the highest frequency of the system. If the sampling rate is too low, high-frequency components of the signal will be aliased or folded back into the lower frequency range, leading to errors in the signal representation.&lt;/p&gt;

&lt;p&gt;To avoid model aliasing, it is important to ensure that the model has sufficient resolution and accuracy to capture the high-frequency dynamics of the system. This may involve increasing the sampling rate, improving the numerical methods used to solve the model equations, or using more complex models that better capture the dynamics of the system.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Adaptive fourier Decomposition</title>
   <link href="http://localhost:4000/2023/02/23/afd"/>
   <updated>2023-02-23T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/23/AFD</id>
   <content type="html">&lt;h2 id=&quot;adaptive-fourier-decomposition-afd-algorithm&quot;&gt;Adaptive Fourier Decomposition (AFD) Algorithm&lt;/h2&gt;

&lt;p&gt;The Adaptive Fourier Decomposition (AFD) algorithm is a data-driven approach for analyzing nonlinear and non-stationary signals. It decomposes a signal into a sum of sinusoidal functions with time-varying frequencies, amplitudes, and phases, allowing for a more accurate representation of the underlying dynamics.&lt;/p&gt;

&lt;p&gt;The AFD algorithm iteratively extracts sinusoidal components from the signal by fitting them to the residual signal, which is the original signal minus the sum of previously extracted components. The frequency, amplitude, and phase of each sinusoidal component are adjusted adaptively based on the residual signal, leading to a more accurate decomposition of the signal.&lt;/p&gt;

&lt;p&gt;Mathematically, let x(t) be the signal to be decomposed. The AFD algorithm decomposes x(t) into a sum of K sinusoidal functions as follows:&lt;/p&gt;

\[x(t) = \sum_{k=1}^K A_k(t)  \sin(2\pi f_k(t)t + \phi_k(t)) + r(t)\]

&lt;p&gt;where $A_k(t), f_k(t),$ and $\phi_k(t)$ are the amplitude, frequency, and phase of the k-th component at time t, respectively, and r(t) is the residual signal.&lt;/p&gt;

&lt;p&gt;The AFD algorithm has many applications in signal processing, including feature extraction, noise reduction, and signal denoising.&lt;/p&gt;

&lt;h2 id=&quot;python-implementation&quot;&gt;Python Implementation&lt;/h2&gt;

&lt;p&gt;Here is a Python implementation of the AFD algorithm using the NumPy library:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;afd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Initialize residual signal and extracted components
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute the Fourier transform of the residual signal
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Find the frequency with the maximum amplitude
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;f_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Extract the sinusoidal component with the maximum amplitude
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;component&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;component&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Remove the extracted component from the residual signal
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;component&lt;/span&gt;
        
    &lt;span class=&quot;c1&quot;&gt;# Return the extracted components
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;the-brief-theory-foundation-of-afd&quot;&gt;The Brief Theory Foundation of AFD&lt;/h3&gt;

&lt;p&gt;AFD was motivated by the fact that Gabors [12] method does not always produce analytic signals of non-negative instantaneous frequency (IF) [13]. To stick on the analytic signal idea, one has to accept that not all analytic signals have non-negative analytic phase derivative, or IF. This suggests seeking ways to approximate the given signal by appropriate basic signal with non-negative analytic IF, viz., monocomponents [13]. Progress has been made along this direction in which AFD is a core concept in the theory and practice. The brief explanation of AFD is provided below.&lt;/p&gt;

&lt;p&gt;AFD decomposes any given analytic signal of finite energy into a linear combination of a type of basic normal mono-component signals called modified Blaschke products. For a real-valued signal $f$ defined on the unit circle, AFD is to be applied to its Hardy space projection
\(f^{+}=\frac{1}{2}(f+i H f)+\frac{c_0}{2},\)
where $H f$ is the circular Hilbert transform of $f$ with the formula
\(f^{+}\left(e^{i t}\right)=\sum_{k=1}^{\infty}&amp;lt;f_k, e_{a_k}&amp;gt;B_k\left(e^{i t}\right),\)
where
\(\begin{aligned}
&amp;amp; e_{a_k}\left(e^{i t}\right)=\frac{\sqrt{1-\left|a_k\right|^2}}{1-\bar{a}_k e^{i t}}, \\
&amp;amp; a_k=\operatorname{argmax}\left\{\sqrt{1-|b|^2}\left|f_k(b)\right|: b \in \text { the unit disc }\right\} \\
&amp;amp; B_k\left(e^{i t}\right)=e_{a_k}\left(e^{i t}\right) \prod_{l=1}^{k-1} \frac{e^{i t}-a_l}{1-\bar{a}_l e^{i t}}, \\
&amp;amp; f_k\left(e^{i t}\right)=\frac{f_{k-1}\left(e^{i t}\right)-&amp;lt;f_{k-1}, e_{a_{k-1}}&amp;gt;e_{a_{k-1}}\left(e^{i t}\right)}{\frac{e^{i t}-a_{k-1}}{1-\bar{a}_{k-1} e^t}}, k=1,2, \cdots \\
&amp;amp; f_0=f^{+} .
\end{aligned}\)
The algorithm stops at the step $N$ such that
\(\left\|f^{+}\right\|-\sum_{k=1}^N\left(1-\left|a_k\right|^2\right)\left|f_k\left(a_k\right)\right|^2&amp;lt;\varepsilon\)
for the first time. The approximation to the original realvalued function $f$ is
\(f=2 \operatorname{Re}\left\{\sum_{k=1}^N&amp;lt;f_k, e_{a_k}&amp;gt;B_k\right\}-c_0\)&lt;/p&gt;

&lt;p&gt;\(=\sum_{k=1}^N \rho_k(t) \cos \theta_k(t)-c_0\)
where
\(\begin{aligned}
&amp;amp; \rho_k(t) e^{i \theta_k(t)}=2&amp;lt;f_k, e_{a_k}&amp;gt;B_k\left(e^{i t}\right) \\
&amp;amp; c_0=\frac{1}{2 \pi} \int_0^{2 \pi} f\left(e^{i t}\right) d t .
\end{aligned}\)
Practically we take the initial value $a_1=0$.
This article makes use the open algorithm code in the homepage of Qian: http://www.fst.umac.mo/en/staff/ fsttq.html. There are three AFD algorithms. The algorithm used in this paper is Cyclic AFD.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Dual Window Selective Median Switching Filter</title>
   <link href="http://localhost:4000/2023/02/22/dual-window-selective-median-switching-filter"/>
   <updated>2023-02-22T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/22/dual-window-selective-median-switching-filter</id>
   <content type="html">
&lt;hr /&gt;
&lt;p&gt;layout: post
title: Dual Window Selective Median Switching Filter
description: Dual Window Selective Median Switching Filter
summary: Dual Window Selective Median Switching Filter
author:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pavan Donthireddy
usemathjax: true
tags: [filters, switching]
original: zhang2017
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;A simple and efficient nonlinear image filtering
technique, called the dual window selective median switching
(DWSMS) filter, for the removal of both additive and impulse
noise from corrupted images, is proposed. Two moving concentric
windows are employed to determine the luminance value for
replacing that of the center pixel. Three steps are involved in this
filtering technique. First, the usual median filtering is applied to
the smaller window. Second, the median filtering is applied to the
larger window. Third, the two median filtered values are then
compared to the original center pixel, and the median-filtered
value closer to the center pixel is chosen to be the pixels filtering
output.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Local averaging is one of the simplest filtering techniques. It
preserves the mean luminance level while suppressing the
variability in flat regions. However, simple linear local
averaging is undesirable for image smoothing because it is
incapable of preserving image edges. Linear local averaging
filters are essentially low pass filters, which tend to blur the
edges and fine structures in the original image. In order to
preserve the edges while achieving some degree of smoothing,
it is desirable to employ nonlinear filters. Some of the most
popular nonlinear filters are the median filter [1], and its various
generalizations [2-12], which are well known to have the
required properties for edge preservation and impulse noise
removal. The basic idea for these methods is to select only a
portion of the luminance level values in the local window to use
in a (weighted) average. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In references [6-8], an alpha-trimmed
mean (-TM) filter, which uses a median basket&apos;&apos; to select a
predetermined number of pixels above and below the median
pixel to the sorted pixels of the moving window, was proposed.
The values in the basket are averaged to give the -TM filtering
output. An asymmetric way to select the averaging pixels whose
values are close to that of the median pixel was presented in
references [8-9] and was named the modified trimmed mean
(MTM) filter in reference [8]. In general practice, the averaging
weights of these filters are predetermined and are fixed
throughout the filtering processing. In [10], a varying weight
trimmed mean (VWTM) filter was introduced.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;This filter employs the same median basket as the -TM filter. However,
the averaging weights of the selected pixels vary dynamically
based on their differences with the median value.
Although superior to the median filter in some applications,
these median generalized filters also have their own limitations.
In general, the MTM outperforms the median filter in removing
additive noise, but not as well as the median filter in removing
impulse noise. The -TM filter is, in general, superior to the
median filter as an impulse detector, but its performance in
removing impulse noise is not so well. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Although performing
better than many other filters, the VWTM filters computational
complexity is high. One common issue of all these nonlinear
filters is their difficulty/complexity of the parameter selections.
Because of its simplicity and outlier removal capability, the
median filtering technique is still widely used today.
To preserve the implementation simplicity and improve the
performance of the median filter, this paper proposes a new
nonlinear filtering technique, called the dual window selective
median switching&apos;&apos; (DWSMS) filter, for the removal of both
additive and impulse noise. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;We shall assume implicitly that the
ideal image is piecewise flat. Two normal concentric moving
windows are employed to determine the values to be used in
replacing the luminance level value of the center pixel. Three
steps are employed in this filtering procedure. First, the usual
median filtering is applied to the smaller window. Second, the
median filtering is applied to the larger window. Third, the two
median filtered values are then compared to the original center
pixel, and the value closer to the center pixel is chosen to be the
pixels filtering output.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Noise</title>
   <link href="http://localhost:4000/2023/02/21/noise"/>
   <updated>2023-02-21T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/21/noise</id>
   <content type="html">&lt;h2 id=&quot;additive-noise&quot;&gt;Additive noise&lt;/h2&gt;

&lt;p&gt;Additive noise can be modeled as a random process that is independent of the original signal. Let x(t) be the original signal and n(t) be the additive noise, then the noisy signal y(t) is given by:&lt;/p&gt;

\[y(t) = x(t) + n(t)\]

&lt;p&gt;where n(t) is a random process with mean zero and variance sigma^2.&lt;/p&gt;

&lt;h2 id=&quot;impulsive-noise&quot;&gt;Impulsive noise&lt;/h2&gt;

&lt;p&gt;Impulsive noise is characterized by sudden spikes or drops in the signal amplitude. It can be modeled as a random process that is uncorrelated with the original signal. Let x(t) be the original signal and d(t) be the impulsive noise, then the noisy signal y(t) is given by:&lt;/p&gt;

\[y(t) = x(t) + d(t)\]

&lt;p&gt;where d(t) is a random process with probability density function f(d(t)).&lt;/p&gt;

&lt;h2 id=&quot;gaussian-noise&quot;&gt;Gaussian noise&lt;/h2&gt;

&lt;p&gt;Gaussian noise is also known as white noise and is characterized by a normal distribution. It can be modeled as a random process that is uncorrelated with the original signal. Let x(t) be the original signal and w(t) be the Gaussian noise, then the noisy signal y(t) is given by:&lt;/p&gt;

\[y(t) = x(t) + w(t)\]

&lt;p&gt;where w(t) is a random process with mean zero and variance sigma^2.&lt;/p&gt;

&lt;h2 id=&quot;shot-noise&quot;&gt;Shot noise&lt;/h2&gt;

&lt;p&gt;Shot noise is caused by the discrete nature of electrical charge and can be modeled as a Poisson process. Let x(t) be the original signal and s(t) be the shot noise, then the noisy signal y(t) is given by:&lt;/p&gt;

\[y(t) = x(t) + s(t)\]

&lt;p&gt;where s(t) is a Poisson process with mean lambda.&lt;/p&gt;

&lt;h2 id=&quot;thermal-noise&quot;&gt;Thermal noise&lt;/h2&gt;

&lt;p&gt;Thermal noise is caused by the random motion of electrons in a conductor due to temperature fluctuations. It can be modeled as a Gaussian process with mean zero and variance proportional to the temperature. Let x(t) be the original signal and z(t) be the thermal noise, then the noisy signal y(t) is given by:&lt;/p&gt;

\[y(t) = x(t) + z(t)\]

&lt;p&gt;where z(t) is a Gaussian process with mean zero and variance proportional to the temperature.&lt;/p&gt;

&lt;h2 id=&quot;quantization-noise&quot;&gt;Quantization noise&lt;/h2&gt;

&lt;p&gt;Quantization noise is introduced when an analog signal is converted to a digital signal. It can be modeled as a uniform quantization error. Let x(t) be the original signal and q(t) be the quantization noise, then the noisy signal y(t) is given by:&lt;/p&gt;

\[y(t) = Q[x(t)] + q(t)\]

&lt;p&gt;where Q[x(t)] is the quantized version of the original signal x(t) and q(t) is a uniform quantization error.&lt;/p&gt;

&lt;h2 id=&quot;white-noise&quot;&gt;White noise&lt;/h2&gt;

&lt;p&gt;White noise is a type of noise that has a flat power spectral density, meaning that it has equal power at all frequencies. It can be modeled as a Gaussian process with mean zero and constant variance sigma^2. Let w(t) be the white noise process, then the power spectral density S(f) is given by:&lt;/p&gt;

\[S(f) = \sigma^2\]

&lt;p&gt;where f is frequency.&lt;/p&gt;

&lt;h2 id=&quot;pink-noise&quot;&gt;Pink noise&lt;/h2&gt;

&lt;p&gt;Pink noise is a type of colored noise that has equal power in each octave. It is also known as 1/f noise, because its power spectral density is proportional to 1/f, where f is frequency. Pink noise can be modeled as a filtered white noise process. Let p(t) be the pink noise process, then its power spectral density S(f) is given by:&lt;/p&gt;

\[S(f) \propto \frac{1}{f}\]

&lt;p&gt;where f is frequency.&lt;/p&gt;

&lt;h2 id=&quot;brownian-noise&quot;&gt;Brownian noise&lt;/h2&gt;

&lt;p&gt;Brownian noise is a type of colored noise that has a power spectral density that is proportional to f^2, where f is frequency. It can be modeled as the integral of white noise over time. Let b(t) be the Brownian noise process, then its power spectral density S(f) is given by:&lt;/p&gt;

\[S(f) \propto f^2\]

&lt;p&gt;where f is frequency.&lt;/p&gt;

&lt;h2 id=&quot;blue-noise&quot;&gt;Blue noise&lt;/h2&gt;

&lt;p&gt;Blue noise is a type of colored noise that has a power spectral density that is proportional to f, where f is frequency. It is also known as azure noise or transient noise. Blue noise can be modeled as the derivative of Brownian noise with respect to time. Let u(t) be the blue noise process, then its power spectral density S(f) is given by:&lt;/p&gt;

\[S(f) \propto f\]

&lt;p&gt;where f is frequency.&lt;/p&gt;

&lt;h2 id=&quot;violet-noise&quot;&gt;Violet noise&lt;/h2&gt;

&lt;p&gt;Violet noise is a type of colored noise that has a power spectral density that is proportional to f^(-2), where f is frequency. It is also known as purple noise or differentiated white noise. Violet noise can be modeled as the second derivative of Brownian noise with respect to time. Let v(t) be the violet noise process, then its power spectral density S(f) is given by:&lt;/p&gt;

\[S(f) \propto f^{-2}\]

&lt;p&gt;where f is frequency.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Nearest Subspace Classification</title>
   <link href="http://localhost:4000/2023/02/20/nearest-subspace-classification"/>
   <updated>2023-02-20T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/20/nearest-subspace-classification</id>
   <content type="html">&lt;h1 id=&quot;nearest-subspace-classification&quot;&gt;Nearest Subspace Classification&lt;/h1&gt;

&lt;p&gt;Nearest Subspace Classification (NSC) is a classification algorithm that is used to classify high-dimensional data into different categories. It is based on the idea that the data can be represented as a subspace in a higher-dimensional feature space, and the nearest subspace to a new observation can be used to classify it into one of the predefined categories.&lt;/p&gt;

&lt;h2 id=&quot;subspace-representation&quot;&gt;Subspace Representation&lt;/h2&gt;

&lt;p&gt;Let $X$ be a matrix of size $n \times p$, where $n$ is the number of data points and $p$ is the number of features. Let $Y$ be a vector of size $n \times 1$, where each element $y_i$ is the label of the corresponding data point $x_i$.&lt;/p&gt;

&lt;p&gt;We can represent the data points in $X$ as subspaces in a higher-dimensional feature space by using a linear projection. Let $V$ be a matrix of size $p \times k$, where $k &amp;lt; p$, that represents the projection matrix. The subspace representation of a data point $x_i$ is then given by:&lt;/p&gt;

\[\hat{x_i} = VV^T x_i\]

&lt;p&gt;The subspace representation of the entire dataset can be obtained by computing the projection of $X$ onto the subspace spanned by $V$:&lt;/p&gt;

\[\hat{X} = XV(XV)^+\]

&lt;p&gt;where (+) denotes the Moore-Penrose pseudoinverse. The subspace spanned by $V$ is also called the column space of $V$.&lt;/p&gt;

&lt;h2 id=&quot;nearest-subspace-classification-1&quot;&gt;Nearest Subspace Classification&lt;/h2&gt;

&lt;p&gt;Given a new data point $x$, the goal of NSC is to classify it into one of the predefined categories based on its subspace representation. The basic idea is to compute the distance between the subspace representation of $x$ and the subspace representations of each category, and classify $x$ into the category with the smallest distance.&lt;/p&gt;

&lt;p&gt;Let $C_i$ be the set of data points in class $i$, and let $V_i$ be the matrix that represents the subspace spanned by the data points in $C_i$. The distance between the subspace representation of $x$ and the subspace spanned by $V_i$ is given by:&lt;/p&gt;

\[d_i = \|x - V_iV_i^Tx\|\]

&lt;p&gt;The classification rule of NSC is then to classify $x$ into the category with the smallest distance:&lt;/p&gt;

\[\hat{y} = \operatorname*{argmin}_{i=1}^k d_i\]

&lt;p&gt;where $k$ is the number of categories.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;p&gt;The algorithm for NSC can be summarized as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Given a labeled training dataset $X$ and $Y$, compute the subspace representations of each class by computing the projection matrix $V$ for each class.&lt;/li&gt;
  &lt;li&gt;Given a new data point $x$, compute its subspace representation using the projection matrix $V$.&lt;/li&gt;
  &lt;li&gt;For each class $i$, compute the distance between the subspace representation of $x$ and the subspace spanned by the data points in class $i$.&lt;/li&gt;
  &lt;li&gt;Classify $x$ into the category with the smallest distance.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;advantages-and-disadvantages&quot;&gt;Advantages and Disadvantages&lt;/h2&gt;

&lt;p&gt;NSC has several advantages over other classification algorithms, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It can handle high-dimensional data by representing the data as subspaces in a higher-dimensional feature space.&lt;/li&gt;
  &lt;li&gt;It is robust to noise and outliers, since the subspace representation of the data is obtained by a linear projection.&lt;/li&gt;
  &lt;li&gt;It can handle non-linear decision boundaries by using a non-linear projection.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, NSC also has some disadvantages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is sensitive to the choice of projection matrix $V$, which can affect the performance of the classifier. In practice, multiple projection matrices can be used and the best one can be selected using cross-validation or other methods.&lt;/li&gt;
  &lt;li&gt;It assumes that the data points in each class are drawn from a single subspace, which may not always be true in practice.&lt;/li&gt;
  &lt;li&gt;It may not perform well on imbalanced datasets, where some classes have significantly fewer data points than others. In this case, it may be necessary to use techniques such as oversampling or undersampling to balance the dataset.&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Nearest Subspace with Discriminative Regularization for Time Series Classification</title>
   <link href="http://localhost:4000/2023/02/19/nearest-subspace-with-discriminative-regularization-for-time-series-classification"/>
   <updated>2023-02-19T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/19/Nearest-Subspace-with-Discriminative-Regularization-for-Time-Series-Classification</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;For time series classification (TSC) problem, many studies
focus on elastic distance measures for comparing time series and complete
the task with the help of Nearest Neighbour (NN) classifier. This
is mainly due to the fact that the order of variables is a crucial factor for
time series. Unlike the NN classifier only considers one training sample,
in this paper, we propose an improved Nearest Subspace (NS) classifier
to classify new time series. By adding a discriminative regularization
item, the improved NS classifier takes full advantage of all training time
series of one class. Two kinds of discriminative regularization items are
employed in our method. One is directly calculated based on Euclidean
distance of time series. For the other, we obtain the regularization items
from a lower-dimensional subspace. Two well-known dimensional reduction
methods, Generalized Eigenvector Method (GEM) and Local Fisher
Discriminant Analysis (LFDA), are employed to complete this task. Furthermore,
we combine these improved NS classifiers through ensemble
schemes to accommodate different time series datasets&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;The empirical studies have shown that the simple 1-NN classifier can get high accuracy and is very hard to beat. So numerous TSC studies
focus on how to calculate the distance between two time series. The standard
benchmark distance measure is Euclidean distance (ED), but it cannot handle
the slight phase shift of time series.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;To overcome this drawback, Ratanamahatana
and Keogh [26] propose to utilize dynamic time warping (DTW) distance to
mitigate against distortions in the time axis. By extensive experiments, Ding
et al. [9] validate that DTW with a proper warping window size set is commonly
accepted as the standard measures. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Another way to deal with this phase shift is
based on edit distance to measure the similarity.
Due to the characteristic of DTW and edit distance, lots of studies try to
improve elastic distance measures based on these two techniques for TSC task.
Jeong et al. [14] propose a modified DTW that weights against large warping
(WDTW) by adding a multiplicative weight penalty.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Another improvement of
DTW, called DDTW, which transforms the time series into a series of first-order
differences [17]. By this transformation, DDTW can avoid the scenarios that a
single point on one time series may map onto a large number of points of another
time series. Meanwhile, it also can be used in conjunction with standard DTW to
calculate similarity between time series simultaneously [11]. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Several approaches
based on the edit distance are also proposed, such as edit distance with real
penalty (ERP) [6], time warp edit (TWE) [22] and move-split-merge (MSM)
[27] distance. A recent work [20] combines most of elastic distance measures
through ensemble schemes to improve the accuracy.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Although the NN classifier with elastic distance measure has the advantages
of simplicity, the label prediction of new instance relies on the special training
samples. In this paper, we propose an improved nearest subspace (NS) method
to deal with the TSC problem, which considers all training samples of one class
when predicting the new instances label. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;This is a linear combination way and
the similar idea has been used in other research field [7,19]. In this method,
the most important factor is the combination coefficients of training samples.
We get the coefficients based on the differences between the new instance and
each training sample. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Concretely, we calculate the distances between them and
take these distances as weighted items to regularize the coefficients. In this way,
the training time series which has a large distance with the new instance will
be assigned a small coefficient. Its the biggest difference between our method
and NN classifier. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;By the discriminative regularization item, the improved NS
method not only considers the most similar training samples with a new instance
but also takes other training time series into account.
To achieve higher performance, we map the time series into the lowdimensional
space where the samples with the same label are closer and the different
classes are more separate. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Thus, the weighted regularization items obtained
in the low-dimensional space are more powerful for the improved NS method.
We employ two well-known dimensionality reduction methods, GEM [15] and
LFDA [28], for this task. Furthermore, ensemble schemes which combine different
weighted regularization items are proposed to suit different kinds of time
series dataset. The extensive experiments demonstrate that the proposed method
can gain better performance than NN classifier with different elastic distance
measures.&lt;/p&gt;

&lt;h3 id=&quot;basic-nearest-subspace-algorithm&quot;&gt;Basic Nearest Subspace Algorithm&lt;/h3&gt;

&lt;p&gt;The NN classifier may be the simplest supervised method to predict the label of a test instance. Essentially, it seeks the best representation of a test instance in term of one training sample. Unlike NN algorithm, the nearest subspace (NS) classifier (e.g. $[18,21])$ takes all training samples of each class into consideration and tries to find the best representation by fitting the test instance. Formally, we assign a test instance $y$ to class $i$ if the distance from $y$ to the subspace spanned by all samples $\boldsymbol{X}&lt;em&gt;i=\left[\boldsymbol{x}&lt;/em&gt;{i, 1}, \ldots, \boldsymbol{x}_{i, n_4}\right]$ of class $i$ is the smallest one among all classes, i.e.,
\(r_i(\boldsymbol{y})=\min _{\boldsymbol{\alpha}_i \in \mathbb{R}^{n_1, i \in\{1, \ldots, K\}}}\left\|\boldsymbol{y}-\boldsymbol{X}_i \boldsymbol{\alpha}_i\right\|_2\)
where $\boldsymbol{\alpha}_i$ is a fitting coefficient vector.
One may notice that the Eq. (1) is easily overfitting which makes the problem ill-posed when we attempt to get the best solution. In general, we can introduce an additional regularization item to prevent overfitting. An alternative is to restrict the variation of $\boldsymbol{\alpha}$ by adding an $L_2$-regularization term:
\(\widetilde{\boldsymbol{\alpha}}_i=\underset{\alpha_i \in \mathbb{R}^{n_i}}{\arg \min }\left\|\boldsymbol{y}-\boldsymbol{X}_i \boldsymbol{\alpha}_i\right\|_2^2+\lambda\left\|\boldsymbol{\alpha}_i\right\|_2^2\)&lt;/p&gt;
&lt;h2 id=&quot;improved-nearest-subspace-classifier&quot;&gt;Improved Nearest Subspace Classifier&lt;/h2&gt;

&lt;p&gt;In Eq. (2), $L_2$-norm is employed to overcome the ill-posed problem of NS algorithm. Its optional to restrict parameter $\boldsymbol{\alpha}&lt;em&gt;i$, but for classification, the uniform weight for each element $\alpha&lt;/em&gt;{i, j}\left(j \in\left{1, \ldots, n_i\right}\right)$ does not consider the differences between training samples. In this paper, we want to utilize a non-uniform regularization to improve nearest subspace classifier. Like NS with $L_2$-regularization, we still calculate the residual for each class and assign the test instance to the class with the minimum residual. The difference is that we utilize Tikhonov regularization [10] with non-uniform weight to replace the simple $L_2$-regularization. The non-uniform regularization can penalize the dissimilarity training samples with a specific test instance $y$ from being assigned large contributions when constructing $\tilde{\boldsymbol{y}}_i$. Thus, the approximation coefficients can be formulated as
\(\widetilde{\boldsymbol{\alpha}}_i=\underset{\alpha_i \in \mathbb{R}^{n_i}}{\arg \min }\left\|\boldsymbol{y}-\boldsymbol{X}_i \boldsymbol{\alpha}_i\right\|_2^2+\lambda\left\|\boldsymbol{\Gamma}_{i, y} \boldsymbol{\alpha}_i\right\|_2^2\)&lt;/p&gt;

&lt;p&gt;where $\boldsymbol{\Gamma}&lt;em&gt;{i, y}$ is the weight matrix to measure the similarity between $\boldsymbol{y}$ and each sample of class $i$. In the following, we utilize Euclidean distance to describe $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$ and discuss the effect of $\boldsymbol{\Gamma}&lt;em&gt;{i, y}$ for approximation coefficients $\boldsymbol{\alpha}_i$.
3.1 ED-Based Regularization
For TSC, the widely studied NN-based classifiers have demonstrated that the distance is a proper alternative to measure the similarity of time series. So we first use Euclidean distance as the weight to restrict regularization term. Concretely, for each element of $\boldsymbol{\alpha}_i\left(\alpha&lt;/em&gt;{i, j}\right)$, we calculate the distance between the test instance $\boldsymbol{y}$ and each training sample $\boldsymbol{X}&lt;em&gt;{i, j}$ and use this distance to restrict $\alpha&lt;/em&gt;{i, j}$, i.e.,
\(\boldsymbol{\Gamma}_{i, y}=\operatorname{diag}\left(\left\|\boldsymbol{y}-\boldsymbol{X}_{i, 1}\right\|_2, \ldots,\left\|\boldsymbol{y}-\boldsymbol{X}_{i, n_1}\right\|_2\right)\)
By $\boldsymbol{\Gamma}&lt;em&gt;{i, y}$, the training samples that is the most similar to $y$ in terms of Euclidean distance can get more contribution to construct the approximation instance than those which are dissimilar. After weight matrix is determined, Eq. (3) can be rewritten as
\(f\left(\boldsymbol{\alpha}_i\right)=\frac{1}{2}\left\|\boldsymbol{y}-\boldsymbol{X}_i \boldsymbol{\alpha}_i\right\|^2+\lambda\left\|\boldsymbol{\Gamma}_{i, y} \boldsymbol{\alpha}_i\right\|^2\)
This is convex in $\alpha_i$, so we can find its the optimal coefficients $\widetilde{\alpha}_i$ by setting the derivative of $f\left(\boldsymbol{\alpha}_i\right)$ to 0 :
\(\widetilde{\boldsymbol{\alpha}}_i=\left(\boldsymbol{X}_i^T \boldsymbol{X}_i+\lambda \boldsymbol{\Gamma}_{i, y}^T \boldsymbol{\Gamma}_{\boldsymbol{i}, y}\right)^{-1} \boldsymbol{X}_i^T \boldsymbol{y}\)
Thus, $\widetilde{\boldsymbol{y}}_i$ is
\(\widetilde{\boldsymbol{y}}_i=\boldsymbol{X}_i \widetilde{\alpha}_i=\boldsymbol{X}_i\left(\boldsymbol{X}_i^T \boldsymbol{X}_i+\lambda \boldsymbol{\Gamma}_{i, y}^T \boldsymbol{\Gamma}_{i, y}\right)^{-1} \boldsymbol{X}_i^T \boldsymbol{y}=\boldsymbol{H}_i \boldsymbol{y}\)
So $\boldsymbol{H}_i$ can be considered as a projection matrix.
To further investigate the effect of $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$ when constructing $\widetilde{\boldsymbol{y}}&lt;em&gt;i$, we analyze the properties of $\boldsymbol{H}_i$ in terms of eigen-decomposition. Because $\boldsymbol{H}_i$ contains two matrices, $\boldsymbol{X}_i$ and $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$, we employ the generalized singular value decomposition (GSVD) [1] between them to do this task.
For matrices $\boldsymbol{X}&lt;em&gt;i$ and $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$, their GSVD is given by
\(\boldsymbol{X}_i=\boldsymbol{U} \boldsymbol{\Sigma}_1[\mathbf{0}, \boldsymbol{\Omega}] \boldsymbol{Q}^T, \quad \boldsymbol{\Gamma}_{i, y}=\boldsymbol{V} \boldsymbol{\Sigma}_2[\mathbf{0}, \boldsymbol{\Omega}] Q^T\)
where $U, V$ and $Q$ are unitary matrices, $\boldsymbol{\Omega}$ is upper triangular and nonsingular matrix. Since $\boldsymbol{\Gamma}&lt;em&gt;{i, y}$ is a diagonal square matrix, $\boldsymbol{U}, \boldsymbol{V}$ and $\boldsymbol{Q}$ are orthogonal and matrices $\Sigma_1$ and $\Sigma_2$ are non-negative diagonal, which hold that $\boldsymbol{\Sigma}_1^T \boldsymbol{\Sigma}_1=\left\lceil\sigma&lt;/em&gt;{\boldsymbol{X}, 1}^2, \sigma_{\boldsymbol{X}, 2}^2, \ldots, \sigma_{\boldsymbol{X}, r}^2\right\rfloor$ and $\boldsymbol{\Sigma}&lt;em&gt;2^T \boldsymbol{\Sigma}_2=\left\lceil\sigma&lt;/em&gt;{\boldsymbol{\Gamma}, 1}^2, \sigma_{\boldsymbol{\Gamma}, 2}^2, \ldots, \sigma_{\boldsymbol{\Gamma}, r}^2\right\rfloor$, where $r=\operatorname{rank}\left(\left[\boldsymbol{X}&lt;em&gt;i^T, \boldsymbol{\Gamma}&lt;/em&gt;{i, y}^T\right]\right)$. Two properties of GSVD is $0 \leq \sigma_{\boldsymbol{X}, i}, \sigma_{\Gamma, i} \leq 1$ and $\boldsymbol{\Sigma}&lt;em&gt;1^T \boldsymbol{\Sigma}_1+\boldsymbol{\Sigma}_2^T \boldsymbol{\Sigma}_2=\boldsymbol{I}_r$ which implies $\sigma&lt;/em&gt;{\boldsymbol{X}, i}^2+\sigma_{\boldsymbol{\Gamma}, i}^2=1$.
By these decompositions, $\boldsymbol{H}_i$ of Eq. (7) is formulated as
\(\boldsymbol{H}_i=\boldsymbol{U} \boldsymbol{\Sigma}_1\left(\boldsymbol{\Sigma}_1 \boldsymbol{\Sigma}_1+\lambda \boldsymbol{\Sigma}_2 \boldsymbol{\Sigma}_2\right) \boldsymbol{\Sigma}_1 \boldsymbol{U}^T=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{U}^T\)&lt;/p&gt;

&lt;p&gt;As can be seen, $\boldsymbol{\Sigma}$ is still a diagonal matrix with the values $\sigma_k$ :
\(\sigma_k=\frac{\sigma_{\boldsymbol{X}, i}^2}{\sigma_{\boldsymbol{X}, i}^2+\lambda \sigma_{\Gamma, i}^2}=\frac{1-\sigma_{\Gamma, i}^2}{1+(\lambda-1) \sigma_{\boldsymbol{\Gamma}, i}^2}\)
Apparently, $\sigma_k \in[0,1]$. Since $\boldsymbol{U}$ is an orthogonal matrix, the decomposition of Eq. (9) can represent the eigen decomposition of $\boldsymbol{H}&lt;em&gt;i$. It is clear that the values of $\sigma_k(k=1, \ldots, r)$ depend on three parts: the structure of the training samples of class $i$ (i.e., $\sigma&lt;/em&gt;{\boldsymbol{X}, i}$ ), the regularization parameter $(\lambda)$ and the distances between $y$ and each sample of class $i$ (i.e., $\sigma_{\Gamma, i}$ ). This means that different test instances have different amount of shrinkage when constructing the approximation instance even using the same training samples.&lt;/p&gt;

&lt;p&gt;Due to $\lambda&amp;gt;0$ and $\sigma_{\Gamma, i} \in[0,1], \sigma_k$ and $\sigma_{\Gamma, i}$ have an inverse relationship. To be more specific, when $y$ has large distances with the training samples of $\boldsymbol{X}&lt;em&gt;i$ (that is, the non-zero entries of $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$ have large values), the values of $\sigma_k$ are large and the eigenvalues of $\boldsymbol{H}&lt;em&gt;i$ are small. This suggests that the classes whose training samples are distant from test instance lead to a stiffer shrinkage penalty. The large penalty will make the obtained $\widetilde{y}_i$ dissimilar to $y$. Back to Eq. (3), large distances in $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$ make $\boldsymbol{\alpha}&lt;em&gt;i$ become small, which results in a large residual. One thing should be noticed that $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$ is an ensemble of distances and only one or several small values have little effect for the final $\boldsymbol{\alpha}_i$. This is the primary difference with NN-based approaches.&lt;/p&gt;

&lt;h3 id=&quot;gem-based-regularization&quot;&gt;GEM-Based Regularization&lt;/h3&gt;

&lt;p&gt;Through the analysis of $\boldsymbol{H}_i$, we find the training sample that is distant from test instance will lead to a small coefficient which makes little effect for calculating the residual. Therefore, if we map the time series into a lower-dimensional subspace where the samples of each class become more closed while the different classes are more separated, the prediction in terms of $\left|\boldsymbol{y}-\widetilde{\boldsymbol{y}}_i\right|_2$ will be more accurate. In this section, we employ the state-of-the-art supervised feature extraction technique, generalized eigenvector method (GEM) [15], to complete this task.&lt;/p&gt;

&lt;p&gt;GEM exploits the simple second-order structure of the training samples and extracts the discriminative features from the generalized eigenvectors of the class conditional second moments. In [15], the author suggests that an alternative would be to use the covariance matrix instead of the second moment. GEM gets the direction by maximizing the ratio of projected data variances between different classes. Thus the direction $v$ is calculated as
\(\boldsymbol{v}=\underset{v}{\arg \max } \frac{\boldsymbol{v}^T \boldsymbol{C}_i \boldsymbol{v}}{\boldsymbol{v}^T\left(\boldsymbol{C}_j+\frac{\gamma}{d} \operatorname{trace}\left(\boldsymbol{C}_j\right)\right) \boldsymbol{v}}\)
where $C_i$ is the covariance matrix of class $i, d$ is the dimensionality of samples, $\gamma$ is a small multiple and trace() denotes the trace of a matrix. The item $\frac{\gamma}{d} \operatorname{trace}\left(\boldsymbol{C}_j\right)$ is used to solve the problem that $\boldsymbol{C}_j$ is rank deficient when there are few training samples [24]. This objection function is solved by the generalized
Nearest Subspace with Discriminative Regularization for TSC $\quad 589$
eigenvectors of $\boldsymbol{C}_i \boldsymbol{v}=\mu\left(\boldsymbol{C}_j+\frac{\gamma}{d} \operatorname{trace}\left(\boldsymbol{C}_j\right)\right) \boldsymbol{v}$. Generally, there are many eligible eigenvalues, so we can get a transformation matrix $\boldsymbol{V}$ by merging all $v \mathrm{~s}$.&lt;/p&gt;

&lt;p&gt;When $\boldsymbol{V}$ is obtained, we can calculate the weight matrix $\boldsymbol{\Gamma}&lt;em&gt;{i, y}^G$ (distinguished from Eq. (4)). Recall that each element in the diagonal of $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}$ is the distance between test instance $y$ and each training sample of class $i$. We calculate the diagonal values of $\boldsymbol{\Gamma}&lt;em&gt;{i, y}^G$ by
\(D_G\left(\boldsymbol{V}, \boldsymbol{y}, \boldsymbol{X}_{i, j}\right)=\left\|\boldsymbol{V} \boldsymbol{y}-\boldsymbol{V} \boldsymbol{X}_{i, j}\right\|_2=\sqrt{\left(\boldsymbol{y}-\boldsymbol{X}_{i, j}\right)^T \boldsymbol{\Phi}\left(\boldsymbol{y}-\boldsymbol{X}_{i, j}\right)}\)
where $\boldsymbol{\Phi}=\boldsymbol{V}^T \boldsymbol{V}, \boldsymbol{X}&lt;/em&gt;{i, j}$ denotes the $j$-th training sample of class $i$.
The above procedure is suited for the scenario of two class. For multi-class problem involving $K(K&amp;gt;2)$ classes, we use two strategies to get the projection matrix: one-vs-rest and multiple one-vs-one. The transformation matrix and weight matrix are denoted as $\boldsymbol{V}^{(1: r)}, \boldsymbol{\Gamma}&lt;em&gt;{i, y}^{G(1: r)}, \boldsymbol{V}^{(1: 1)}$ and $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}^{G(1: 1)}$, respectively.&lt;/p&gt;

&lt;h3 id=&quot;lfda-based-regularization&quot;&gt;LFDA-Based Regularization&lt;/h3&gt;

&lt;p&gt;Local Fisher discriminant analysis (LFDA) is another effective method which embeds the high-dimensional data into a lower-dimensional subspace. In this section, we employ LFDA to help the construction of $\boldsymbol{\Gamma}&lt;em&gt;{i, y}$. To deal with the multi-modal problem of sample distribution, LFDA employs a concept of affinity to represent the neighbour relationship of two samples. Let $\boldsymbol{W}$ be the affinity matrix, and an elaborate and proper definition of the affinity between $\boldsymbol{x}_i$ and $\boldsymbol{x}_j$ is provided by [29]: $\boldsymbol{W}&lt;/em&gt;{i, j}=\exp \left(-d^2\left(\boldsymbol{x}&lt;em&gt;i, \boldsymbol{x}_j\right) / \eta_i \eta_j\right)$, where $d\left(\boldsymbol{x}_i, \boldsymbol{x}_j\right)$ is a distance measure, $\eta_i=d\left(\boldsymbol{x}_i, \boldsymbol{x}_i^{k n n}\right)$ is a local scaling parameter in terms of the neighbourhood of $\boldsymbol{x}_i$ and $\boldsymbol{x}_i^{k n n}$ is the knn-nearest neighbour of $\boldsymbol{x}_i$. By this definition, a large distance between two samples will lead to a small affinity. If the values of local within-class scatter matrix $\left(S&lt;/em&gt;{l w}\right)$ and local between-class scatter matrix $\left(S_{l b}\right)$ used in LFDA are weighted by the affinity, the far-apart samples have less influence, which can preserve the local structure of the data. Based on affinity matrix, the $S_{l w}$ and $S_{l b}$ are defined as
\(\begin{aligned}
\boldsymbol{S}_{l w} &amp;amp; =\frac{1}{2} \sum_{i, j=1}^n \boldsymbol{W}_{i j}^w\left(\boldsymbol{x}_i-\boldsymbol{x}_j\right)\left(\boldsymbol{x}_i-\boldsymbol{x}_j\right)^T \\
\boldsymbol{S}_{l b} &amp;amp; =\frac{1}{2} \sum_{i, j=1}^n \boldsymbol{W}_{i j}^b\left(\boldsymbol{x}_i-\boldsymbol{x}_j\right)\left(\boldsymbol{x}_i-\boldsymbol{x}_j\right)^T
\end{aligned}\)&lt;/p&gt;

&lt;p&gt;where
\(\boldsymbol{W}_{i j}^w=\left\{\begin{array}{ll}
\boldsymbol{W}_{i j} / n_c, &amp;amp; l_i=l_j=c \\
0, &amp;amp; l_i \neq l_j
\end{array}, \boldsymbol{W}_{i j}^b= \begin{cases}\boldsymbol{W}_{i j}\left(1 / n-1 / n_c\right), &amp;amp; l_i=l_j=c \\
1 / n, &amp;amp; l_i \neq l_j\end{cases}\right.\)
where $l_i, l_j$ are class labels, $n_c$ is the number of training samples of $c$-th class. As usual, we still use [24]s solution to regularize $S_{l w}$. The reason is that $S_{l w}$ will be the denominator matrix in the objection function of LFDA. Using $S_{l w}$ and $S_{l b}$, the LFDA transformation matrix $T$ is defined as
\(\boldsymbol{T}=\underset{T}{\arg \max } \frac{\boldsymbol{T}^T \boldsymbol{S}_{l b} \boldsymbol{T}}{\boldsymbol{T}^T\left(\boldsymbol{S}_{l w}+\frac{\gamma}{d} \operatorname{trace}\left(\boldsymbol{S}_{l w}\right)\right) \boldsymbol{T}}\)
Now, we can project the samples into a low-dimensional subspace by $\boldsymbol{T}$ and recalculate the weight matrix $\boldsymbol{\Gamma}&lt;em&gt;{i, y}$ of Eq. (4). For the sake of distinction, we denote it as $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}^L$ and each element is obtained by calculating
\(D_L\left(\boldsymbol{T}, \boldsymbol{y}, \boldsymbol{X}_{i, j}\right)=\left\|\boldsymbol{T} \boldsymbol{y}-\boldsymbol{T} \boldsymbol{X}_{i, j}\right\|_2=\sqrt{\left(\boldsymbol{y}-\boldsymbol{X}_{i, j}\right)^T \boldsymbol{\Psi}\left(\boldsymbol{y}-\boldsymbol{X}_{i, j}\right)}\)
where $\boldsymbol{\Psi}=\boldsymbol{T}^T \boldsymbol{T}$.
Except the transformation matrix is obtained by Eq. (16), for $K(K&amp;gt;2)$ classes, we also use one-vs-rest strategy to find the discriminative projection directions and merge them to form transformation matrix $\left(\boldsymbol{T}^{(1: r)}\right)$. We use $\boldsymbol{\Gamma}_{i, y}^{L(1: r)}$ to denote the weight matrix of this case.&lt;/p&gt;

&lt;h3 id=&quot;effect-of-gem-and-lfda-based-regulation-for-improved-ns&quot;&gt;Effect of GEM and LFDA-Based Regulation for Improved NS&lt;/h3&gt;

&lt;p&gt;In Sects. 3.2 and 3.3, we respectively employ GEM and LFDA to transform the samples into a low-dimensional space where the obtained weight matrix is expected to have a proper shrinkage penalty for approximation coefficients $\alpha_i$. No matter GEM or LFDA, the purpose is to make the samples with the same label more closed in the new space while the samples from different classes are apart. So by comparing the distance relationships calculated in original sample space, the distances obtained in new low-dimensional space become more meaningful for the classification task. What is different is that GEM excepts more information contained in data distribution while LFDA tries to make the interclass more separated. Therefore, GEM uses the covariance matrix as the basis while LFDA employs the collection of class-conditional mean feature vectors. In the low-dimensional space constructed by LFDA, the inter-class separability is increased, which penalizes the class whose memberships are most distant from $\boldsymbol{y}$. Meanwhile, the samples that are truly neighbours of $\boldsymbol{y}$ are also seen as neighbours, which gives better information on within-class distance relationships with $y$ and offers more benefit for classification.&lt;/p&gt;

&lt;p&gt;Empirically, LFDA seems to be a more suitable choice for classification task to restrict $\boldsymbol{\alpha}_i$. But there are various kinds of time series datasets in our daily life and no one technique is a panacea which can deal with all situations. Bagnall and Liness works $[3,20]$ have demonstrated this point and they suggest that an ensemble scheme of different approaches is an alternative. In the next section, we will utilize all these weight matrices to propose an ensemble NS classifier.&lt;/p&gt;

&lt;h3 id=&quot;ensemble-ns-classifier&quot;&gt;Ensemble NS Classifier&lt;/h3&gt;

&lt;p&gt;An ensemble of classifiers is a set of base classifiers, which has been widely studied in machine learning domain. When classifying new samples, the decisions of all base classifiers are combined through a fusion way. In Sect. 3 , we design 5 different weight matrices: $\boldsymbol{\Gamma}&lt;em&gt;{i, y}, \boldsymbol{\Gamma}&lt;/em&gt;{i, y}^{G(1: r)}, \boldsymbol{\Gamma}&lt;em&gt;{i, y}^{G(1: 1)}, \boldsymbol{\Gamma}_i^L$ and $\boldsymbol{\Gamma}&lt;/em&gt;{i, y}^{L(1: r)}$, where $\boldsymbol{\Gamma}_{i, y}$ is directly constructed by calculating the distance between test instance $y$ and each training sample of class $i$ while the other 4 weight matrices are constructed in different low-dimensional spaces.&lt;/p&gt;

&lt;p&gt;Our ensemble approach is transparent, i.e., we first construct the five different forms of NS classifiers by these weight matrices and then take the simple voting schemes to make a decision for each test instance. For convenience, we denote these five different forms of NS classifiers as NS_ED, NS_G(1:r), NS_G(1:1), NS_L and NS_L(1:r).&lt;/p&gt;

&lt;p&gt;We separately test three weighting schemes for the ensemble classifier: equal, proportional and best. The equal scheme, as the name implies, sets the equal weight for each classifier when classifying new instance. Clearly, it is the fastest scheme, but it does not consider the difference of base classifiers. The proportional and best schemes exploit unequal voting weight. A widely used technique is to calculate the cross-validation accuracy of each base classifier on the training set and then the weight is set based on the accuracy [20]. The proportional scheme assigns the wights as the cross-validation accuracy directly while the best scheme takes a binary strategy which assigns a weight of 1 to the base classifier with the highest cross-validation accuracy and 0 to the others. In the next Section, these schemes are all employed for TSC task. Here, we propose an ensemble algorithm of improved NS classification with five weight matrices by the best scheme.&lt;/p&gt;

&lt;p&gt;The time consuming of Algorithm 1 mainly depends on two parts: one is the calculation of weight matrices, the other is the solution of optimal coefficients.&lt;/p&gt;

&lt;p&gt;For optimal coefficient $\widetilde{\boldsymbol{\alpha}}_i$ of Eq. (6), it takes $O\left(n_i^2 m\right)$ where $n_i$ is the number of $i$-th class and $m$ is the length of time series. For weight matrix $\boldsymbol{\Gamma}$, the GEM and LFDA consume most of running time but they only need to be computed once. When using GEM, the projection vector of Eq. (11) requires $O\left(\mathrm{~m}^2\right)$, thus, the one-vs-one way takes $O\left(K^2 m^2\right)$ and one-vs-rest strategy needs $O\left(K m^2\right)$. When using LFDA, Eq. (16) needs $O\left(n^2 k\right)$ where $k$ is the number of selected projection vectors and $k=1$ for one-vs-one strategy. So the total time complexity is $O\left(\max \left(K n_i^2 m, \max \left(K^2 m^2, n^2 k\right)\right)\right)$.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Tensor Singular value decomposition</title>
   <link href="http://localhost:4000/2023/02/18/tensor-svd"/>
   <updated>2023-02-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/18/tensor-SVD</id>
   <content type="html">&lt;h1 id=&quot;tensor-singular-value-decomposition-svd&quot;&gt;Tensor Singular Value Decomposition (SVD)&lt;/h1&gt;

&lt;p&gt;Tensor Singular Value Decomposition (SVD) is a powerful mathematical tool that decomposes a higher-order tensor into a set of lower-order tensors with orthogonal bases. In this article, we will explore the concept of tensor SVD, its applications, and how it is computed using mathematical equations.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;A tensor can be defined as a multidimensional array of numerical values. For instance, a 2D tensor is a matrix, a 3D tensor is a cube, and a higher-order tensor is a multidimensional array. Tensor SVD is used to decompose a tensor into a set of lower-order tensors with orthogonal bases.&lt;/p&gt;

&lt;h2 id=&quot;svd-in-matrix-form&quot;&gt;SVD in Matrix Form&lt;/h2&gt;

&lt;p&gt;To understand the concept of SVD for tensors, let us first look at SVD for matrices. For a given matrix A, its SVD can be written as:&lt;/p&gt;

\[A = U \Sigma V^T\]

&lt;p&gt;Here, U and V are orthogonal matrices, and $\Sigma$ is a diagonal matrix with non-negative real numbers on the diagonal, known as the singular values.&lt;/p&gt;

&lt;h2 id=&quot;svd-for-tensors&quot;&gt;SVD for Tensors&lt;/h2&gt;

&lt;p&gt;Now, let us extend the concept of SVD to tensors. For a given tensor $\mathcal{X}$ with dimensions $I_1 \times I_2 \times \cdots \times I_N$, its SVD can be written as:&lt;/p&gt;

\[\mathcal{X} = \sum_{r=1}^R \lambda_r \mathbf{u}_r \circ \mathbf{v}_r\]

&lt;p&gt;Here, $\lambda_r$ is a non-negative singular value, and $\mathbf{u}_r$ and $\mathbf{v}_r$ are orthogonal vectors with dimensions $I_k \times 1$ for $k=1,2,\cdots,N$. The symbol $\circ$ denotes the outer product of two vectors.&lt;/p&gt;

&lt;h2 id=&quot;tensor-svd-in-1d-case&quot;&gt;Tensor SVD in 1D Case&lt;/h2&gt;

&lt;p&gt;Let us now consider the 1D case of tensor SVD. In this case, the tensor $\mathcal{X}$ can be represented as a vector $\mathbf{x}$ of length $I_1 \times I_2 \times \cdots \times I_N$. Its SVD can be written as:&lt;/p&gt;

\[\mathbf{x} = \sum_{r=1}^R \lambda_r \mathbf{u}_r \mathbf{v}_r^T \mathbf{x}\]

&lt;p&gt;Here, $\mathbf{u}_r$ and $\mathbf{v}_r$ are orthogonal vectors with dimensions $I_1 \times 1$ and $I_2 \times 1$, respectively.&lt;/p&gt;

&lt;p&gt;To compute the SVD of a tensor in the 1D case, we first calculate the covariance matrix $C = \mathbf{x} \mathbf{x}^T$. We then calculate its eigenvectors and eigenvalues, which can be used to compute the orthogonal bases $\mathbf{u}_r$ and $\mathbf{v}_r$, as well as the singular values $\lambda_r$.&lt;/p&gt;

&lt;h2 id=&quot;applications-of-tensor-svd&quot;&gt;Applications of Tensor SVD&lt;/h2&gt;

&lt;p&gt;Tensor SVD has many applications in data analysis and machine learning. It is used for dimensionality reduction, feature extraction, data compression, and clustering, among other things. It is also used in image and video processing, where tensors are used to represent higher-dimensional data.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In conclusion, Tensor Singular Value Decomposition (SVD) is a powerful mathematical tool that decomposes a higher-order tensor into a set of lower-order tensors with orthogonal bases.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Singular value decomposition</title>
   <link href="http://localhost:4000/2023/02/17/svd"/>
   <updated>2023-02-17T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/17/SVD</id>
   <content type="html">&lt;h1 id=&quot;singular-value-decomposition-svd-and-its-variants&quot;&gt;Singular Value Decomposition (SVD) and its Variants&lt;/h1&gt;

&lt;p&gt;Singular Value Decomposition (SVD) is a matrix factorization technique that has many applications in signal processing, image compression, and machine learning. In this article, we will explore the basic SVD algorithm and its variants.&lt;/p&gt;

&lt;h2 id=&quot;basic-svd-algorithm&quot;&gt;Basic SVD Algorithm&lt;/h2&gt;

&lt;p&gt;Given an $m \times n$ matrix $\mathbf{A}$, the goal of SVD is to find matrices $\mathbf{U}$, $\mathbf{D}$, and $\mathbf{V}$ such that:&lt;/p&gt;

\[\mathbf{A} = \mathbf{U} \mathbf{D} \mathbf{V}^T\]

&lt;p&gt;where $\mathbf{U}$ is an $m \times m$ orthogonal matrix, $\mathbf{D}$ is an $m \times n$ diagonal matrix with non-negative entries called singular values, and $\mathbf{V}$ is an $n \times n$ orthogonal matrix.&lt;/p&gt;

&lt;p&gt;The singular values in $\mathbf{D}$ are arranged in descending order along the diagonal. The first $k$ singular values and their corresponding columns in $\mathbf{U}$ and $\mathbf{V}$ capture the most important information in the matrix.&lt;/p&gt;

&lt;p&gt;The truncated SVD approximation of rank $k$ is given by:&lt;/p&gt;

\[\mathbf{A}_k = \mathbf{U}_k \mathbf{D}_k \mathbf{V}_k^T\]

&lt;p&gt;where $\mathbf{U}_k$ is the first $k$ columns of $\mathbf{U}$, $\mathbf{D}_k$ is the first $k$ rows and columns of $\mathbf{D}$, and $\mathbf{V}_k$ is the first $k$ columns of $\mathbf{V}$.&lt;/p&gt;

&lt;p&gt;The SVD can be computed using various algorithms, such as the Golub-Kahan bidiagonalization algorithm, the Jacobi method, and the power iteration method.&lt;/p&gt;

&lt;h2 id=&quot;variants-of-svd&quot;&gt;Variants of SVD&lt;/h2&gt;

&lt;h3 id=&quot;truncated-svd&quot;&gt;Truncated SVD&lt;/h3&gt;

&lt;p&gt;Truncated SVD is a variant of SVD that is useful for dimensionality reduction and feature extraction. It involves computing the truncated SVD approximation of rank $k$, as described above.&lt;/p&gt;

&lt;h3 id=&quot;randomized-svd&quot;&gt;Randomized SVD&lt;/h3&gt;

&lt;p&gt;Randomized SVD is a variant of SVD that is useful for large datasets that do not fit into memory. It involves approximating the SVD using a randomized algorithm that computes a low-rank approximation of the matrix.&lt;/p&gt;

&lt;p&gt;The algorithm consists of the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Generate a random $n \times k$ matrix $\mathbf{R}$.&lt;/li&gt;
  &lt;li&gt;Compute the matrix $\mathbf{Y} = \mathbf{A} \mathbf{R}$.&lt;/li&gt;
  &lt;li&gt;Compute the QR decomposition $\mathbf{Y} = \mathbf{Q} \mathbf{B}$.&lt;/li&gt;
  &lt;li&gt;Compute the SVD of the matrix $\mathbf{B} = \mathbf{W} \mathbf{\Sigma} \mathbf{V}^T$.&lt;/li&gt;
  &lt;li&gt;Compute the matrix $\mathbf{U} = \mathbf{Q} \mathbf{W}$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The randomized SVD algorithm is faster than the basic SVD algorithm for large datasets, and can be used to compute a low-rank approximation of the matrix in a reasonable amount of time.&lt;/p&gt;

&lt;h1 id=&quot;sparse-svd-and-kernel-svd&quot;&gt;Sparse SVD and Kernel SVD&lt;/h1&gt;

&lt;h2 id=&quot;sparse-svd&quot;&gt;Sparse SVD&lt;/h2&gt;

&lt;p&gt;Sparse SVD is a variant of traditional SVD that can handle sparse data. It is often used in text mining and natural language processing, where the data is represented as a sparse matrix. The goal of sparse SVD is to decompose the data into a low-rank component and a sparse component, while preserving the original sparsity pattern.&lt;/p&gt;

&lt;p&gt;The mathematical formulation of sparse SVD involves solving the following optimization problem:&lt;/p&gt;

\[\begin{equation}
\min_{L,S} ||L||_* + \lambda ||S||_1 \quad \text{subject to} \quad X = L + S
\end{equation}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;where $X$ is the data matrix, $L$ is the low-rank component, $S$ is the sparse component, $&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;_*$ is the nuclear norm (sum of singular values), $&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;_1$ is the l1 norm (sum of absolute values), and $\lambda$ is a regularization parameter that controls the trade-off between low-rankness and sparsity.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To solve this optimization problem, various algorithms have been proposed, including Principal Component Pursuit (PCP), Accelerated Proximal Gradient (APG), and Alternating Direction Method of Multipliers (ADMM). These algorithms are iterative and require solving sub-problems at each iteration.&lt;/p&gt;

&lt;h2 id=&quot;kernel-svd&quot;&gt;Kernel SVD&lt;/h2&gt;

&lt;p&gt;Kernel SVD is a variant of traditional SVD that can handle nonlinear data. It is often used in machine learning, where the data is represented as a kernel matrix. The goal of kernel SVD is to decompose the data into a low-dimensional linear subspace and a nonlinear component, while preserving the original kernel similarity structure.&lt;/p&gt;

&lt;p&gt;The mathematical formulation of kernel SVD involves solving the following optimization problem:&lt;/p&gt;

\[\begin{equation}
\min_{L,S} ||L||_* + \lambda ||S||_1 \quad \text{subject to} \quad K = LL^T + S
\end{equation}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;where $K$ is the kernel matrix, $L$ is the low-dimensional subspace, $S$ is the nonlinear component, $&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;_*$ is the nuclear norm (sum of singular values), $&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;_1$ is the l1 norm (sum of absolute values), and $\lambda$ is a regularization parameter that controls the trade-off between low-rankness and sparsity.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To solve this optimization problem, various algorithms have been proposed, including Kernel PCA, Kernel Ridge Regression, and Kernel Ridge Regression with Iterative Hard Thresholding (KRR-IHT).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Principal Component Analysis</title>
   <link href="http://localhost:4000/2023/02/16/pca"/>
   <updated>2023-02-16T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/16/PCA</id>
   <content type="html">&lt;h1 id=&quot;principal-component-analysis-pca-and-its-variants&quot;&gt;Principal Component Analysis (PCA) and its Variants&lt;/h1&gt;

&lt;p&gt;Principal Component Analysis (PCA) is a widely used technique for dimensionality reduction and feature extraction. PCA finds a lower-dimensional representation of the data that retains as much of the original information as possible. In this article, we will explore the basic PCA algorithm and its variants.&lt;/p&gt;

&lt;h2 id=&quot;basic-pca-algorithm&quot;&gt;Basic PCA Algorithm&lt;/h2&gt;

&lt;p&gt;Given a dataset $\mathbf{X} = {\mathbf{x}_1, \mathbf{x}_2, , \mathbf{x}_n}$ consisting of $n$ data points, each with $d$ dimensions, the goal of PCA is to find a set of $k$ orthonormal basis vectors ${\mathbf{v}_1, \mathbf{v}_2, , \mathbf{v}_k}$ that capture the most important information in the data.&lt;/p&gt;

&lt;p&gt;The first principal component $\mathbf{v}_1$ is the direction that maximizes the variance of the projected data. This can be found by solving the optimization problem:&lt;/p&gt;

\[\mathbf{v}_1 = \operatorname*{argmax}_{\|\mathbf{v}\|=1} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{v}^T \mathbf{x}_i)^2\]

&lt;p&gt;The second principal component $\mathbf{v}_2$ is the direction that maximizes the variance of the projected data, subject to the constraint that it is orthogonal to $\mathbf{v}_1$. This can be found by solving the optimization problem:&lt;/p&gt;

\[\mathbf{v}_2 = \operatorname*{argmax}_{\|\mathbf{v}\|=1, \mathbf{v} \perp \mathbf{v}_1} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{v}^T \mathbf{x}_i)^2\]

&lt;p&gt;This process is repeated to find the remaining principal components ${\mathbf{v}_3, \mathbf{v}_4, , \mathbf{v}_k}$.&lt;/p&gt;

&lt;p&gt;The projection of the data onto the $k$-dimensional subspace spanned by ${\mathbf{v}_1, \mathbf{v}_2, , \mathbf{v}_k}$ is given by:&lt;/p&gt;

\[\mathbf{Z} = \begin{bmatrix}
\mathbf{v}_1^T \mathbf{x}_1 &amp;amp; \mathbf{v}_2^T \mathbf{x}_1 &amp;amp; \cdots &amp;amp; \mathbf{v}_k^T \mathbf{x}_1 \\
\mathbf{v}_1^T \mathbf{x}_2 &amp;amp; \mathbf{v}_2^T \mathbf{x}_2 &amp;amp; \cdots &amp;amp; \mathbf{v}_k^T \mathbf{x}_2 \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\mathbf{v}_1^T \mathbf{x}_n &amp;amp; \mathbf{v}_2^T \mathbf{x}_n &amp;amp; \cdots &amp;amp; \mathbf{v}_k^T \mathbf{x}_n
\end{bmatrix}\]

&lt;p&gt;where each row of $\mathbf{Z}$ corresponds to a projected data point.&lt;/p&gt;

&lt;h1 id=&quot;sparse-pca-and-its-variants&quot;&gt;Sparse PCA and its Variants&lt;/h1&gt;

&lt;p&gt;Sparse PCA is a variant of Principal Component Analysis (PCA) that aims to find sparse representations of the data. It is useful for feature selection and dimensionality reduction in high-dimensional datasets where only a few features are relevant.&lt;/p&gt;

&lt;h2 id=&quot;basic-sparse-pca-algorithm&quot;&gt;Basic Sparse PCA Algorithm&lt;/h2&gt;

&lt;p&gt;Given an $n \times p$ data matrix $\mathbf{X}$, the goal of Sparse PCA is to find a sparse $p \times 1$ loading vector $\mathbf{w}$ that maximizes the variance of the projected data.&lt;/p&gt;

&lt;p&gt;The Sparse PCA optimization problem can be formulated as:&lt;/p&gt;

\[\max_{\mathbf{w}} \frac{\mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w}}{\|\mathbf{w}\|^2}\]

&lt;p&gt;subject to the constraint $|\mathbf{w}|_0 \leq k$, where $k$ is a sparsity parameter that controls the number of non-zero entries in $\mathbf{w}$.&lt;/p&gt;

&lt;p&gt;This problem is non-convex and NP-hard, but can be approximately solved using various algorithms, such as the Orthogonal Matching Pursuit (OMP), the Iterative Soft Thresholding (IST), and the Iterative Hard Thresholding (IHT).&lt;/p&gt;

&lt;p&gt;The solution to the Sparse PCA problem is not unique, and depends on the choice of the sparsity parameter $k$ and the algorithm used.&lt;/p&gt;

&lt;h2 id=&quot;variants-of-sparse-pca&quot;&gt;Variants of Sparse PCA&lt;/h2&gt;

&lt;h3 id=&quot;group-sparse-pca&quot;&gt;Group Sparse PCA&lt;/h3&gt;

&lt;p&gt;Group Sparse PCA is a variant of Sparse PCA that takes into account the group structure of the features. It involves partitioning the features into groups and enforcing sparsity within each group.&lt;/p&gt;

&lt;p&gt;The Group Sparse PCA optimization problem can be formulated as:&lt;/p&gt;

\[\max_{\mathbf{w}_1, \dots, \mathbf{w}_G} \sum_{g=1}^G \frac{\mathbf{w}_g^T \mathbf{X}_g^T \mathbf{X}_g \mathbf{w}_g}{\|\mathbf{w}_g\|^2}\]

&lt;p&gt;subject to the constraint $|\mathbf{w}_g|_2 \leq c_g$ for each group $g$, where $c_g$ is a regularization parameter that controls the sparsity within the group.&lt;/p&gt;

&lt;p&gt;The Group Sparse PCA problem can be solved using various algorithms, such as the Group Iterative Soft Thresholding (GIST), the Group Iterative Hard Thresholding (GIHT), and the Group Orthogonal Matching Pursuit (GOMP).&lt;/p&gt;

&lt;h3 id=&quot;sparse-pca-with-orthogonal-constraint&quot;&gt;Sparse PCA with Orthogonal Constraint&lt;/h3&gt;

&lt;p&gt;Sparse PCA with Orthogonal Constraint is a variant of Sparse PCA that enforces orthogonality between the loading vectors. It involves solving the Sparse PCA problem subject to the constraint $\mathbf{W}^T \mathbf{W} = \mathbf{I}$, where $\mathbf{W}$ is the $p \times k$ loading matrix.&lt;/p&gt;

&lt;p&gt;The Sparse PCA with Orthogonal Constraint problem can be formulated as:&lt;/p&gt;

\[\max_{\mathbf{W}} \frac{\text{tr}(\mathbf{W}^T \mathbf{X}^T \mathbf{X} \mathbf{W})}{\|\mathbf{W}\|^2}\]

&lt;p&gt;subject to the constraint $|\mathbf{w}_i|_0 \leq k$ for each column of $\mathbf{W}$.&lt;/p&gt;

&lt;p&gt;The Sparse PCA with Orthogonal Constraint problem can be solved using various algorithms, such as the Sparse Orthogonal Iteration (SOI)&lt;/p&gt;

&lt;h1 id=&quot;robust-principal-component-analysis-pca&quot;&gt;Robust Principal Component Analysis (PCA)&lt;/h1&gt;

&lt;p&gt;Principal Component Analysis (PCA) is a popular statistical technique used for data analysis and dimensionality reduction. It is often used to identify patterns and relationships within datasets by reducing the number of dimensions and extracting a set of uncorrelated variables, known as principal components. However, traditional PCA assumes that the data is well-behaved and has no outliers.&lt;/p&gt;

&lt;p&gt;Robust PCA is a modification of traditional PCA that can handle outliers in the data. It is particularly useful when dealing with datasets that are corrupted by noise or contain anomalies. The goal of robust PCA is to separate the data into a low-rank component (representing the underlying structure of the data) and a sparse component (representing the outliers or anomalies in the data).&lt;/p&gt;

&lt;p&gt;The mathematical formulation of robust PCA involves solving the following optimization problem:&lt;/p&gt;

\[\begin{equation}
\min_{L,S} ||L||_* + \lambda ||S||_1 \quad \text{subject to} \quad X = L + S
\end{equation}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;where $X$ is the data matrix, $L$ is the low-rank component, $S$ is the sparse component, $&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;_*$ is the nuclear norm (sum of singular values), $&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;_1$ is the l1 norm (sum of absolute values), and $\lambda$ is a regularization parameter that controls the trade-off between low-rankness and sparsity.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To solve this optimization problem, various algorithms have been proposed, including Principal Component Pursuit (PCP), Accelerated Proximal Gradient (APG), and Alternating Direction Method of Multipliers (ADMM). These algorithms are iterative and require solving sub-problems at each iteration.&lt;/p&gt;

&lt;p&gt;In this example, the original data matrix (top left) contains outliers (red points). Robust PCA separates the data into a low-rank component (bottom left) and a sparse component (bottom right). The low-rank component represents the underlying structure of the data, while the sparse component represents the outliers.&lt;/p&gt;

&lt;p&gt;Robust PCA has many applications, including image and video processing, recommender systems, and anomaly detection. It is a powerful tool for data analysis when dealing with noisy or corrupted data.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Collocation and  Galerkin Approximation</title>
   <link href="http://localhost:4000/2023/02/15/collocation-galerkin"/>
   <updated>2023-02-15T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/15/collocation-galerkin</id>
   <content type="html">&lt;p&gt;Collocation and Galerkin approximation are two methods commonly used in numerical analysis for approximating solutions to differential equations or integral equations.&lt;/p&gt;

&lt;p&gt;Collocation is a method of numerical approximation in which the differential equation or integral equation is evaluated at a finite set of points, known as collocation points. These points are chosen in such a way that the approximation is expected to be accurate. The resulting set of equations can then be solved to obtain an approximation to the solution of the original equation. Collocation is a simple and efficient method for approximating solutions to differential equations and integral equations.&lt;/p&gt;

&lt;h1 id=&quot;collocation&quot;&gt;Collocation&lt;/h1&gt;

&lt;p&gt;Collocation is a numerical method used to approximate solutions to differential equations or integral equations. The method involves evaluating the equation at a finite set of points, known as collocation points, and then solving the resulting set of equations to obtain an approximation to the solution of the original equation.&lt;/p&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;p&gt;To use collocation to solve a differential equation or integral equation, we first choose a set of collocation points. These points can be chosen in a variety of ways, but the choice of points is important for the accuracy of the approximation. Once the collocation points have been chosen, we evaluate the equation at these points. This results in a set of equations that can be solved to obtain an approximation to the solution of the original equation.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Consider the differential equation:&lt;/p&gt;

\[y&apos;&apos; + y = \cos(x)\]

&lt;p&gt;We can use collocation to approximate the solution to this equation. Lets choose two collocation points, $x_1 = 0$ and $x_2 = \pi/2$. Evaluating the equation at these points gives:&lt;/p&gt;

\[y&apos;&apos;(0) + y(0) = 1\]

\[y&apos;&apos;(\pi/2) + y(\pi/2) = 0\]

&lt;p&gt;We can solve these equations to obtain an approximation to the solution of the original equation.&lt;/p&gt;

&lt;h2 id=&quot;advantages&quot;&gt;Advantages&lt;/h2&gt;

&lt;p&gt;Collocation is a simple and efficient method for approximating solutions to differential equations and integral equations. The method is easy to implement and requires only basic mathematical knowledge. Collocation can also be used to solve a wide variety of equations, including both linear and nonlinear equations.&lt;/p&gt;

&lt;h2 id=&quot;disadvantages&quot;&gt;Disadvantages&lt;/h2&gt;

&lt;p&gt;The accuracy of collocation depends on the choice of collocation points. Choosing the wrong set of points can result in a poor approximation. Collocation also requires the evaluation of the equation at a finite set of points, which may not capture all of the important features of the solution.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Collocation is a powerful method for approximating solutions to differential equations and integral equations. The method is simple, efficient, and can be used to solve a wide variety of equations. However, the accuracy of the approximation depends on the choice of collocation points, and the method may not be suitable for all problems.&lt;/p&gt;

&lt;h1 id=&quot;galerkin-approximation&quot;&gt;Galerkin Approximation&lt;/h1&gt;

&lt;p&gt;Galerkin approximation is a numerical method used to approximate solutions to differential equations or integral equations. The method involves finding an approximate solution in a finite-dimensional subspace of the space of solutions to the original equation.&lt;/p&gt;

&lt;h2 id=&quot;method-1&quot;&gt;Method&lt;/h2&gt;

&lt;p&gt;To use the Galerkin method to solve a differential equation or integral equation, we first choose a finite-dimensional subspace of the space of solutions to the equation. This subspace is often chosen to be a space of polynomial functions or piecewise polynomial functions. We then choose a set of basis functions that span the subspace. These basis functions can be chosen in a variety of ways, but the choice of functions is important for the accuracy of the approximation.&lt;/p&gt;

&lt;p&gt;Once the subspace and basis functions have been chosen, we project the original equation onto this subspace. This results in a set of algebraic equations that can be solved to obtain an approximation to the solution of the original equation.&lt;/p&gt;

&lt;h2 id=&quot;example-1&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Consider the differential equation:&lt;/p&gt;

\[y&apos;&apos; + y = \cos(x)\]

&lt;p&gt;We can use the Galerkin method to approximate the solution to this equation. Lets choose a subspace consisting of quadratic polynomials, and lets choose the basis functions to be the functions $1$, $x$, and $x^2$. We can project the original equation onto this subspace to obtain the following set of equations:&lt;/p&gt;

\[(2c_1 + c_2)\cos(0) + (2c_1 + 5c_2 + 2c_3)\cos(\pi/2) = 1\]

\[(2c_1 + 5c_2 + 2c_3)\cos(0) + (18c_3 + 10c_2)\cos(\pi/2) = 0\]

&lt;p&gt;where $c_1$, $c_2$, and $c_3$ are the coefficients of the basis functions.&lt;/p&gt;

&lt;p&gt;We can solve these equations to obtain an approximation to the solution of the original equation.&lt;/p&gt;

&lt;h2 id=&quot;advantages-1&quot;&gt;Advantages&lt;/h2&gt;

&lt;p&gt;The Galerkin method is more accurate than collocation, but it is also more computationally intensive. The method can be used to solve a wide variety of equations, including both linear and nonlinear equations. The Galerkin method is also a powerful tool for analyzing the stability and convergence of numerical methods.&lt;/p&gt;

&lt;h2 id=&quot;disadvantages-1&quot;&gt;Disadvantages&lt;/h2&gt;

&lt;p&gt;The Galerkin method requires the choice of a subspace and a set of basis functions, which can be difficult for complex problems. The method can also be computationally intensive for high-dimensional problems.&lt;/p&gt;

&lt;h2 id=&quot;conclusion-1&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Galerkin approximation is a powerful method for approximating solutions to differential equations and integral equations. The method is more accurate than collocation, but it is also more computationally intensive. The choice of subspace and basis functions is important for the accuracy of the approximation, and the method may not be suitable for all problems.&lt;/p&gt;

&lt;p&gt;Galerkin approximation, on the other hand, is a more sophisticated method that involves finding an approximate solution in a finite-dimensional subspace of the space of solutions to the original equation. This subspace is often chosen to be a space of polynomial functions or piecewise polynomial functions. The Galerkin method involves choosing a set of basis functions that span the subspace, and then projecting the original equation onto this subspace to obtain a set of algebraic equations that can be solved to obtain an approximation to the solution of the original equation. The Galerkin method is more accurate than collocation, but it is also more computationally intensive.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Jump process for the trend estimation of time series</title>
   <link href="http://localhost:4000/2023/02/14/jump-process-for-trend-estimation-time-series"/>
   <updated>2023-02-14T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/14/jump-process-for-trend-estimation-time-series</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;A jump process approach is proposed for the trend estimation of time series. The proposed
jump process estimator can locally minimize two important features of a trend, the smoothness
and 0delity, and explicitly balance the fundamental tradeoff between them. A weighted average
form of the jump process estimator is derived. The connection of the proposed approach to the
Hanning 0lter, Gaussian kernel regression, the heat equation and the Wiener process is discussed.
It is found that the weight function of the jump process approaches the Gaussian kernel, as the
smoothing parameter increases.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The main objective of this paper is to present a new nonparametric approach, jump process, to estimate the unknown deterministic trend function of a time series. In conrast to the global implicit minimization approach, a localized approach is developed for trend estimation. The proposed jump process can locally minimize both characteristics and explicitly balance the fundamental tradeoff between them. A weighted average form of the jump process estimate is derived in the present paper, so that the implementation of jump process becomes extremely simple. The connection between the present jump process approach and the traditional trend estimation methods, as well as the DSP is discussed. It is found that the weight function of the jump process filter approaches the normal kernel, as the smoothing parameter increases.&lt;/p&gt;

&lt;h2 id=&quot;theory-and-algorithm&quot;&gt;Theory and Algorithm&lt;/h2&gt;

&lt;h3 id=&quot;local-measurement-of-smoothness-and-fidelity&quot;&gt;Local measurement of smoothness and fidelity&lt;/h3&gt;

&lt;p&gt;A common feature of optimization schemes WH, HP, SS and MR is to minimize the linear combination of the global measure of fidelity and smoothness, while using a smoothing parameter to balance the tradeoff between fidelity and smoothness. There are three key aspects in the design of these nonparametric trend estimation approaches:
(1) Define measures for fidelity and smoothness,
(2) balance the tradeoff by employing a smoothing parameter,
(3) minimize the linear combination of two measures to achieve an estimate which is optimal in the sense of the given measures.&lt;/p&gt;

&lt;p&gt;In the present study, an iterative jump process will be considered, which actually admits a simpler optimization approach for trend estimation
\(\begin{aligned}
&amp;amp; T_t^{M+1}=T_t^M+R\left(T_{t-1}^M-2 T_t^M+T_{t+1}^M\right) \\
&amp;amp; \quad=T_t^M+R \Delta^2 T_t^M \\
&amp;amp; T_t^0=y_t, \quad t=1, \ldots, N,
\end{aligned}\)
where ratio $R(R&amp;gt;0)$ and iteration parameter $M$ are user-specified constants. The second term on the right-hand side of iterative process (7), $T_{t-1}^M-2 T_t^M+T_{t+1}^M$, is the pointwise measure of smoothness. To have a better understanding of this iterative jump process, $T_t^M$ of Eq. (7) is rewritten in terms of $y_t$ :
\(T_t^M=y_t+R \sum_{k=0}^{M-1} \Delta^2 T_t^k, \quad t=1, \ldots, N .\)
Further denote $v_t^{M-1}=\sum_{k=0}^{M-1} \Delta^2 T_t^k$, this yields
\(\left(y_t-T_t^M\right)+R v_t^{M-1}=0, \quad t=1, \ldots, N .\)
It is obvious that the first term on the left-hand side of (9), $\left(y_t-T_t^M\right)$, is the local measure of the fidelity, while the second term, $v_t^{M-1}$, is the accumulative local measure of smoothness. At each step of the iteration, this process guarantees that the sum of the linear combination of the local deviation from $y_t$ and the accumulative local measure of smoothness equals to zero. In the sense of such local minimization, the optimal estimated trend is the output of iterative jump process (7) by using $y_t$ as input. Such a trend estimation method will be referred as a jump process estimator.&lt;/p&gt;

&lt;p&gt;In terms of minimization, the relationship between the jump process and the optimization schemes WH, HP, SS, and MR is somewhat analogous to the relationship between the collocation and Galerkin approximation schemes well known in numerical analysis (see for example, Wei, 2000). The previous optimization schemes minimize the criterion function over the entire domain to obtain optimal estimates, while jump process forces the criterion function to pass through zero at each step of the iteration to give an optimal trend.&lt;/p&gt;

&lt;p&gt;Besides the minimization of two properties, another important aspect of the construction of nonparametric trend estimation approach is the tradeoff balance. To illustrate how jump process (7) balances the tradeoff between smoothness and fidelity, the stability of jump process (7) is considered first. For this purpose, Eq. (7) is rewritten in a matrix form,
\(\mathbf{T}^{M+1}=\mathbf{A T}^M\)
where $\mathbf{T}^M=\left(T_1^M, T_2^M, \ldots, T_N^M\right)^{\prime}$, and the tridiagonal matrix $\mathbf{A}$ has coefficients: $a_{t, t-1}=$ $a_{t, t+1}=R$ and $a_{t, t}=1-2 R$, for $t=1,2, \ldots, N$. If all of the eigenvalues of $\mathbf{A}$ are smaller than unity, the iterative correction $\varepsilon^{M+1}=\left|\mathbf{T}^{M+1}-\mathbf{T}^M\right|$ will decay, then the process is stable. Since each diagonal term of the matrix is a constant, the eigenvectors of $\mathbf{A}$ can be represented in terms of a complex exponential form,
\(\mathbf{T}_t^M=q^M \mathrm{e}^{\mathrm{i} \gamma t}\)
where $\mathrm{i}=\sqrt{-1}$ and $\gamma$ is a wavenumber that can be chosen arbitrarily. Substituting Eq. (11) into Eq. (10) and removing the common term $\mathrm{e}^{\mathrm{i} \gamma t}$, an explicit expression for the eigenvalue $q$ is obtained
\(q=1+2 R(\cos \gamma-1)\)
For a stable process, the magnitude of this quantity is required to be smaller than unity,
\(q^2=[1+2 R(\cos \gamma-1)]^2&amp;lt;1\)
and $q$ is maximum when $\cos \gamma=-1$. Therefore, the iterative process is stable provided $R&amp;lt;\frac{1}{2}$&lt;/p&gt;

&lt;p&gt;Thus, when $0&amp;lt;R&amp;lt;\frac{1}{2}$, one has $\varepsilon^{M+1} \leqslant \varepsilon^M$, for any $M \in \mathbb{Z}^{+}$. Due to $\varepsilon^{M+1}=| \mathbf{T}^{M+1}-$ $\mathbf{T}^M|=| \Delta^2 \mathbf{T}^M |$, is actually the global smoothness measure of estimated trend at the $M$ th iteration step, one can argue that as the iterative process is carried out longer and longer, the estimated trend becomes smoother and smoother, while the deviation of $\mathbf{T}^M$ from $\mathbf{Y}=\left(y_1, y_2, \ldots, y_N\right)^{\prime}$ becomes larger and larger. Two smoothing parameters, $R$ and $M$, govern the fundamental tradeoff between the smoothness and fidelity. In practice, $R$ can be pre-fixed in the iteration process and only $M$ is used to achieve the desired tradeoff.&lt;/p&gt;

&lt;h3 id=&quot;weighted-average-form-of-jump-process&quot;&gt;Weighted average form of jump process&lt;/h3&gt;

&lt;p&gt;The advantage of the proposed approach is its simplicity, robustness and efficiency. However, the relationship between final estimates and original time series needs to be clarified for jump process (7). Fortunately, like most of the other nonparametric approaches, the estimated trend of the jump process also permits a weighted average representation in terms of the original series $y_t$. If $M$ equals to 1 , the estimates are
\(T_t^1=R y_{t-1}+(1-2 R) y_t+R y_{t+1}, \quad t=1, \ldots, N,\)
which is clearly a local weighted average form for $y_t$. In general, after $M$ iterations, the estimated trend can be represented as
\(T_t^M=\sum_{k=t-M}^{t+M} W(k, M) y_k,\)
where weight function $W(k, M)$ has the general form of
and
\(g(k, M, h)=\frac{M ! R^{M-h}(1-2 R)^h}{((M+k-h) / 2) !((M-k-h) / 2) ! h !} .\)
It can be easily verified that,
\(\sum_{k=t-M}^{t+M} W(k, M)=1\)
and
\(W(-k, M)=W(k, M) \quad \forall k=1, \ldots, M .\)
Eq. (15) indicates that the jump process estimator can be viewed as a kernel smoother with (16) as a jump process kernel. From the point of view of the DSP, the weight function $W(k, M)$ is a low-pass filter. The implementation of the jump process becomes extremely simple due to the existence of (15). Therefore, the weighted average form (15) is very useful numerically.&lt;/p&gt;

&lt;p&gt;The weight assignment of the jump process filter is analogous to that of other kernel regression methods. When $M$ is not too small, and for any reasonable choice of $R$, such as $0.1 \leqslant R&amp;lt;0.5$, the greater of the weights is assigned to the points close $y_i$, the smaller weight will be assigned to the points far away from $y_i$, see Table 1 and Fig. 1. It can also be seen from the figure that, when $M$ is large, although the involved neighborhood is large, the effective window size of significant nonzero filter coefficients is smaller than $2 M+1$.&lt;/p&gt;

&lt;p&gt;A simple moving average filter can be formed by convolving $\left(\frac{1}{2}, \frac{1}{2}\right)$ with itself $2 M$ times. When $M=1$, such a filter is the so-called Hanning filter (see Goodall, 1990)
\(\left(W_{-1}, W_0, W_1\right)=\left(\frac{1}{4}, \frac{1}{2}, \frac{1}{4}\right)\)
By setting $R=\frac{1}{4}$ in Eq. (14), it is clear that the one step jump process filter has the same coefficients as those of the Hanning filter and the $M$ step jump process filter is identical to the digital filter obtained by convolving Hanning filter with itself M
times. Thus, the proposed jump process 0lter can be viewed as a generalization of the
Hanning 0lter.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;k&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;W_(k,6)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;General&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;R=0.4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;R=0.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;924R^(6)-1512R^(5)+1050R^(4)-400R^(3)+90R^(2)-12 R+1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.181824&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.390804&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-792R^(6)+1260R^(5)-840R^(4)+300R^(3)-60R^(2)+6R&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.154368&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.227808&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;495R^(6)-720R^(5)+420R^(4)-120R^(3)+15R^(2)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.12672&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.065295&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-220R^(6)+270R^(5)-120R^(4)+20R^(3)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.07168&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.01048&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;66R^(6)-60R^(5)+15R^(4)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.039936&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000966&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-12R^(6)+6R^(5)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.012288&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000048&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;R^(6)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.004096&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.000001&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;generalization-of-jump-process-estimator&quot;&gt;Generalization of jump process estimator&lt;/h3&gt;

&lt;p&gt;For simplicity, only the uniformly spaced data have been considered for trend estimation so far. However, the framework of jump process estimator can be extended easily to randomly distributed data (i.e. nonuniformly spaced observations),
\(\begin{aligned}
&amp;amp; T_t^{M+1}=T_t^M+\bar{R} \frac{T_{t-1}^M\left(x_t-x_{t-1}\right)-T_t^M\left(x_{t+1}-x_{t-1}\right)+T_{t+1}^M\left(x_{t+1}-x_t\right)}{\frac{1}{2}\left(x_{t+1}-x_{t-1}\right)\left(x_{t+1}-x_t\right)\left(x_t-x_{t-1}\right)} \\
&amp;amp; T_t^0=y_t, \quad t=1, \ldots, N .
\end{aligned}\)
This iteration process is stable provided $\bar{R}&amp;lt;(\Delta x)^2 / 2$, where $\Delta x=\min &lt;em&gt;t\left(x_t-x&lt;/em&gt;{t-1}\right)$. The weighted average form of $(21)$ depends on the design. It will be quite complicated to obtain the explicit expression of the weighted function similar to (16). Fortunately, the
S. Zhao, G.W. Wei/ Computational Statistics \&amp;amp; Data Analysis 42 (2003) 219-241 227
regression estimates based on the iterative jump process (21) can be easily obtained. Therefore, the trend estimation based on jump process (21) will be useful even if either some data points are missing or a cross validation method is employed.&lt;/p&gt;

&lt;p&gt;It is well known that the continuous counterpart of the jump process in stochastic processes is the diffusion process, which is usually represented in the form of a partial differential equation,
\(\begin{aligned}
&amp;amp; \frac{\partial T(x, \tau)}{\partial \tau}=\nabla^2 T(x, \tau), \\
&amp;amp; T(x, 0)=y(x) .
\end{aligned}\)
Here, the temporal variable $\tau$ is the continuous time, rather than the time variable of the time series. To numerically simulate the diffusion process on uniformly spaced data, the second-order central difference and explicit Euler scheme may be employed for spatial and temporal discretizations
\(\begin{aligned}
&amp;amp; T_t^{M+1}=T_t^M+\frac{\Delta \tau}{(\Delta x)^2}\left(T_{t-1}^M-2 T_t^M+T_{t+1}^M\right), \\
&amp;amp; T_t^0=y_t, \quad t=1, \ldots, N .
\end{aligned}\)
It is interesting to note that if one sets $R=\Delta \tau /(\Delta x)^2$, discretized approximation scheme (23) is the same as the iterative jump process (7) and the stability of explicit Euler scheme also requires mesh ratio $\Delta \tau /\left(\Delta x^2\right)&amp;lt;1 / 2$. Thus, the diffusion Eq. (22) is capable of providing alternative perspective for the understanding of the jump process estimator. For example, the nonuniform jump process (21) can be easily derived from the heat Eq. (22). Obviously, high-order spatiotemporal discretization of Eq. (22) can also be used to construct a family of jump processes.&lt;/p&gt;

&lt;h3 id=&quot;jump-process-and-wiener-process&quot;&gt;Jump process and Wiener process&lt;/h3&gt;

&lt;p&gt;For an appropriate range of $R(0&amp;lt;R&amp;lt;1 / 2)$, the coefficients of (14), i.e. $(R, 1-$ $2 R, R)$, are nonnegative and $R+(1-2 R)+R=1$. Therefore, these coefficients may be interpreted as probabilities. Consider a particle at position $k$ on the $x$-axis at time $\tau=M \Delta \tau$, in the next $\Delta \tau$ time period, the particle can have only three possible states: forward $\Delta k$, backward $\Delta k$, no change in position, with probabilities of $P^{+}, P^{-}$and $P$, respectively,
\(\Delta k= \begin{cases}\Delta x &amp;amp; \text { with probability } P^{+}=R, \\ 0 &amp;amp; \text { with probability } P=1-2 R, \\ -\Delta x &amp;amp; \text { with probability } P^{-}=R,\end{cases}\)
where $k+\Delta k$ is the particle position after $\Delta \tau$. The process (24) is usually called a jump process in the stochastic process analysis, see for example Cox and Ross (1976). If a particle follows the jump process (24) and starts at the origin of the $x$-axis at $\tau=0$, after $M$ steps, it is easy to prove that the probability of this particle at position $k$ is exactly the weight $W(k, M)$ given by (16). Hence, further investigation of jump process (24) will provide considerable insight into the proposed jump process filter.&lt;/p&gt;

&lt;p&gt;It is obvious that the local mean and variance of $\Delta k$ in (24) are
\(\begin{aligned}
E\{\Delta k\} &amp;amp; =\Delta x\left(P^{+}-P^{-}\right)=0 \\
\operatorname{Var}\{\Delta k\} &amp;amp; =\Delta x^2\left(P^{+}+P^{-}\right)-(E\{\Delta k\})^2 \\
&amp;amp; =2 \Delta x^2 R \\
&amp;amp; =2 \Delta \tau .
\end{aligned}\)
In the continuum limit of an infinitesimally small step size, the discrete model (24) yields
\(\mathrm{d} k=\sqrt{2} \mathrm{~d} Z\)
where $\mathrm{d} Z$ is a standard Wiener process with $E{\mathrm{~d} Z}=0, \operatorname{Var}\left{\mathrm{d} Z^2\right}=\mathrm{d} \tau$. This implies that the $\mathrm{d} k$ is also a one-dimensional Wiener process (Brownian motion without the drift). Hence, the increase of particle movement during a relatively long period of time $\tau$ is given by
\(k(\tau)-k(0)=\sum_{t=1}^M \varepsilon_t \sqrt{2 \mathrm{~d} \tau},\)
where the $\varepsilon_t(t=1,2, \ldots, M)$ are random numbers drawn from a standardized normal distribution. Consequently, it can be shown that $k(\tau)-k(0)$ is normally distributed with (Hull, 1999, Section 10.2)
\(\begin{aligned}
&amp;amp; E\{k(\tau)-k(0)\}=0, \\
&amp;amp; \operatorname{Var}\{k(\tau)-k(0)\}=\sqrt{2 \tau} .
\end{aligned}\)
Here $k(0)=0$ and $k(\tau)=k$. This means that under the jump process (24), the particle movement will follow the normal distribution in the continuum limit $\Delta \tau \rightarrow 0$. Since $\Delta \tau \rightarrow 0$ is equivalent to $M \rightarrow \infty$ when $\tau$ is fixed, and the particle movement probability function is exactly the weight function $W(k, M)$. One can conclude that the weight function $W(k, M)$ of the proposed jump process filter will approach the normal kernel at the limit of $M \rightarrow \infty$.&lt;/p&gt;

&lt;p&gt;It is well known that the filter coefficients generated by convolving Hanning moving average filter approximate the Gaussian kernel as $M \rightarrow \infty$. The above finding indicates that, the present generalized Hanning filter, the jump process filter, shares the same property. Such property endows the jump process weight function to be a good kernel function for kernel regression, for which a widely used kernel is the Gaussian density. The proposed jump process weight function provides a discrete approximation to the Gaussian kernel. On the other hand, as pointed out in the DSP literature (such as Koenderink, 1984; Hummel, 1987), the solution of the heat diffusion Eq. (22) may equivalently be viewed as the result obtained by convolving original signal with the Gaussian kernel. This again agrees with the present finding about the jump process estimator.&lt;/p&gt;

&lt;h3 id=&quot;implementation-particulars&quot;&gt;Implementation particulars&lt;/h3&gt;

&lt;p&gt;It follows from above discussion that there are two simple and controllable ways to implement the jump process trend estimation. One way is based on iterative jump process (7). The time series $y_{t}$ is used as the input data. The iteration number M is
used to control the final estimates.&lt;/p&gt;

&lt;p&gt;The other way is to use the weighted average form
(15). The trend is estimated by convolving $y_{t}$ and the jump process kernel once. In both
ways, the R can be fixed and only M needs to be adjusted. Theoretically, the estimated
trends from two ways are the same, however, there are some minor differences due
to possible different boundary treatment and applicability. Generally speaking, for uniform
spacing data trend estimation problems, the convolution implementation is more
efficient than iterative implementation. However, the iterative implementation can be
easily done for randomly spaced data regression, for which the weight kernel of the
form of (15) is difficult to be constructed.&lt;/p&gt;

&lt;p&gt;Another difference of these two implementations is the different possible modification
in dealing with boundary effect. The boundary effect is a common thorny problem
for linear filtering and kernel smoothing, i.e., linear symmetric filters fail to provide
estimates for the initial or=and end terms of the series (Kendall et al., 1983). The
problem seems to be more serious in a convolution, since a larger computational support
will locate outside the boundaries in this case, while there is only one point outside
each boundary for the iterative way at each iteration step.&lt;/p&gt;

&lt;p&gt;In the literature, there are some alternative approaches for dealing with boundary
effect (Goodall, 1990).&lt;/p&gt;

&lt;p&gt;One approach uses progressively more asymmetric versions
of filters at the end points, it will result in more biased estimates. Such techniques
were widely used in moving average filtering and kernel smoothing, see for
example Gasser and MNuller (1979), and can be directly adopted by the convolution
implementation of the jump process estimation. The counterpart of such a technique
in an iterative implementation is the well-known upwind difference approximation
scheme in numerical analysis. However, though based on the same motivation,
these two modifications along with two implementations generally yield different
estimates.&lt;/p&gt;

&lt;p&gt;Artificially padding data or extrapolating the series is another approach for generating
necessary support for the symmetric filter. According to the observed characteristic
of trend component, repeating the latest observation, symmetric or antisymmetric
extension may be used.&lt;/p&gt;

&lt;p&gt;The same extension technique, such as symmetric or antisymmetric,
can be adopted by both convolution and iterative implementations. Furthermore,
it can be proved that by using the same symmetric=antisymmetric extension technique,
the final estimates of two different implementations of the jump process are identical.
Therefore, we limit our attention in the present study to the implementation of
convolution with boundary extensions.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The characteristic of the jump process estimator is its local optimization. In terms of
minimization, the relationship between the jump process approach and traditional methods
is analogous to the relationship between the collocation and Galerkin approximation
in numerical analysis. The numerical strengths of the jump process are simplicity and
robustness.&lt;/p&gt;

&lt;p&gt;Like many nonparametric approaches, the estimate of the jump process also permits a
weighted average form, which is very useful numerically. The weight shape of the jump
process filter is also analogous to that of other kernel regression schemes. The present
study reveals that the jump process filter can be viewed as a generalization of the
Hanning filter. A jump process trend estimation scheme is developed for nonuniformly
spaced data. Such a scheme is useful in case where some data points are missing
or cross validation method is used. Furthermore, it is shown that the proposed jump
process is equivalent to a discretized form of the heat diffusion equation. Hence the
continuous discusion process can be used as the other convenient starting point for
theoretical analysis.&lt;/p&gt;

&lt;p&gt;By examining the jump process from the point of view of stochastic process analysis,
it is shown that such a jump process, in an appropriate limit, is a Wiener process.
Hence, the weight function of jump process Filter approaches the normal curve when
smoothing parameter tends to infinity. This agrees with the relevant 0ndings of the
convolution Hanning Filter, as well as the findings of the heat equation in the DSP
literature.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Trend Estimation</title>
   <link href="http://localhost:4000/2023/02/13/trend-estimation"/>
   <updated>2023-02-13T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/13/trend-estimation</id>
   <content type="html">&lt;p&gt;From the viewpoint of mathematical modeling, trend is not a well-defined concept. In general, trend may be considered as long-term smooth change
in the mean level.&lt;/p&gt;

&lt;p&gt;To carry out in-depth statistical study of time series, it is often necessary to convert
a nonstationary series into a stationary one before the statistical model is treated. In
other words, time series will be decomposed into individual trend, seasonal, and irregular
components.&lt;/p&gt;

&lt;p&gt;Conventionally, there are two different ways to decompose a time
series which does not consist of seasonal component (or is seasonally adjusted): differencing
and detrending. The differencing will remove trend, while the detrending (trend
estimation) will present an estimate to trend. Thus, the differencing and detrending
are essentially high-pass filter and low-pass filter, respectively, from the viewpoint of
digital signal processing (DSP).&lt;/p&gt;

&lt;p&gt;Generally speaking, methods of trend estimation fall into two major categories: parametric
and nonparametric. In the parametric approach, a deterministic trend is commonly
expressed by a particular smoothing function or model, such as a polynomial,
the Gompertz curve or the logistic curve (Meade and Islam, 1995), or the structural
time series model (Harvey, 1989). However, the use of an inappropriate parametric
model may cause misleading information and even incorrect inference about the trend
curve. Therefore, alternative nonparametric trend estimation methods are widely used.
In particular, nonparametric approaches offer considerable Lexibility in the selection of
0tting curves and may yield satisfactory estimates. In conventional time series analysis,
some of the most widely used nonparametric approaches include moving average 0lters
and exponential smoothing 0lter, which are linear low-pass 0lters in the sense of the
DSP. A variety of moving average 0lters are proposed, such as Spencer 0lter (Kendall
et al., 1983), Henderson 0lter (Kenny and Durbin, 1982), and GLAS 0lter (Blanchi
et al., 1999), etc. The asymmetric exponential smoothing filter (Kenny and Durbin), has a distinguished advantage in the treatment of boundary effect, hence is often
preferred for the purpose of forecasting.&lt;/p&gt;

&lt;p&gt;Apart from these linear filters, various nonparametric regression estimators existing
in the literature can be easily adopted for the purpose of trend estimation. This is
because that the counterpart of trend component $T_{t}$ in the content of nonparametric
regression is just the regression function $T(x_{t} )$,&lt;/p&gt;

\[y_{t} = T(x_{t})+ \epsilon_{t}, \qquad t=1,2,\dots, N\]

&lt;p&gt;where $x$ and $y$ are explanatory and response variable, respectively. Many powerful nonparametric regression estimators have been proposed and applied in the literature, such as kernel smoothing (Mller, 1988), LOESS (Cleveland, 1979), locally weighted polynomial regression (Fan and Gijbels, 1996), smoothing spline (Eubank, 1999), and regression spline (Doksum and Koo, 2000). Furthermore, there are also many interesting studies suggested in the literature in order to enhance the performance of nonparametric regression estimators, such as improving the accuracy (e.g., Borra and Ciaccio, 2002), dealing with special data (e.g., Keilegom et al., 2001), and so on. In fact, the nonparametric regression has been successfully used in trend estimation, see for example Hrdle and Tuan (1986), Goodall (1990), Hart (1991, 1994), Hst (1999), and Ferreira et al. (2000). Other nonparametric trend estimation methods that were studied in the literature include: Hodrick Prescott (HP) filter (Hodrick and Prescott, 1997), median filter (Wen and Zeng, 1999), wavelet shrinkage (Donoho et al., 1995), and linear programming (Mosheiov and Raveh, 1997). Usually, a successful nonparametric method has one or more underlying smoothing parameters which can be adjusted to balance the fundamental tradeoffs of the estimates, i.e., the smoothness-fidelity tradeoff and the variance-bias tradeoff.&lt;/p&gt;

&lt;p&gt;What is more relevant to the present work is a class of nonparametric trend estimation methods that attempt to globally quantify the competition between the two conflicting features: the smoothness and the fidelity. The earliest motivation to this approach dates back to 1923 when Whittaker (1923) introduced graduation, which is also one of the earliest works of nonparametric regression in the literature. By using the residual sum of squares $\sum_{t=1}^N\left(y_t-T_t\right)^2$ as the global measure of fidelity of the estimated trend $T_t$, Whittaker (1923) suggested to define the sum of the squares of $k$ th order differences as the measure of roughness. Then the optimal trend is given by solving the following minimization scheme:
\((\mathrm{WH}): \min _{\left\{T_t\right\}_{t=1}^N}\left\{\sum_{t=1}^N\left(y_t-T_t\right)^2+\lambda^2 \sum_{t=1}^{N-k}\left(\Delta^k T_t\right)^2\right\},\)
where order $k$ and smoothing parameter $\lambda$ are user-specified constants and $\Delta$ is the difference operator.&lt;/p&gt;

&lt;p&gt;A particular example following Whittakers approach is the HP filter (Hodrick and Prescott, 1997), which has been most extensively used in the real business cycle literature for detrending
\(\text { (HP): } \min _{\left\{T_t\right\}_{t=1}^N}\left\{\sum_{t=1}^N\left(y_t-T_t\right)^2+\lambda \sum_{t=1}^N\left(T_{t-1}-2 T_t+T_{t+1}\right)^2\right\} .\)
Hodrick and Prescott recommended setting $\lambda=1600$ when applying to real business studies. By manipulating the relevant first-order condition, the HP scheme leads to a two-way moving average with weights subjected to a damped harmonic approximately, see King and Rebelo (1993).&lt;/p&gt;

&lt;p&gt;Recently, a popularly used measurement of the roughness penalty of estimates $T\left(x_t\right)$ in nonparametric regression is $\int\left[T^{\prime \prime}(x)\right]^2 \mathrm{~d} x$. This leads to following penalized leastsquares regression scheme:
$(\mathrm{SS}): \min &lt;em&gt;{\left{T_t\right}&lt;/em&gt;{t=1}^N}\left{\sum_{t=1}^N\left(y_t-T_t\right)^2+\lambda \int\left[T^{\prime \prime}(x)\right]^2 \mathrm{~d} x\right}$,
which is known as smoothing spline estimator. Remarkably, the problem of optimization SS over the space of all twice differentiable functions on the interval $[a, b]=\left[x_1, x_N\right]$ has a unique solution $T_\lambda(x)$ which is defined as the natural cubic spline, see Eubank (1999) and references therein.&lt;/p&gt;

&lt;p&gt;More recently, Mosheiov and Raveh (1997) (MR) proposed a linear programming approach to estimate the trend by employing the sum of the absolute values rather than the common sum of squares to measure the smoothness and fidelity. The tradeoff balancing leads to such an optimization scheme
\((\mathrm{MR}): \min _{\left\{T_t\right\}_{t=1}^N}\left\{\lambda \sum_{t=1}^N\left|y_t-T_t\right|+(1-\lambda) \sum_{t=1}^{N-2}\left|T_{t+2}-2 T_{t+1}+T_t\right|\right\} .\)
Through a trick of variable changing, the objective function of the minimization scheme MR will be free of the absolute operator. However, extra constraints, monotonicity or polytonicity, have to be forced upon estimates in order to uniquely solve the linear programming problem. The location of the changing points of polytone trend is case-dependent and its selection is somewhat arbitrary.&lt;/p&gt;

&lt;p&gt;Obviously, all these optimization schemes are closely related. The pointwise roughness measure of MR, $T_{t+2}-2 T_{t+1}+T_t$, is essentially the same as those of HP and WH, and is the discrete version of SS. Instead of forward difference, $T_{t+2}-2 T_{t+1}+T_t$, the backward and central difference approximation may also be used in the optimization MR. Moreover, with appropriate boundary modifications (such as in HP filter, see Baxter and King, 1995), the summation of the global smoothness measure in WH and MR can be processed from 1 to $N$, which may be more reasonable in a comparison with the integration in SS. Apart from their common motivation, another common feature of this class of nonparametric approaches is their use of global implicit minimization. As is well known, a global minimization problem can be quite expensive for its numerical computation.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Matrix Pencil</title>
   <link href="http://localhost:4000/2023/02/12/matrix-pencil"/>
   <updated>2023-02-12T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/12/matrix-pencil</id>
   <content type="html">&lt;p&gt;A matrix pencil is a mathematical construct that consists of two matrices, typically denoted as A and B, that are related by a parameter, often denoted as . The matrix pencil can be written as:&lt;/p&gt;

\[(A - \lambda B)\]

&lt;p&gt;where  is the parameter and A and B are two matrices of the same size. The matrix pencil is used in many areas of mathematics and engineering, including control theory, linear algebra, and numerical analysis.&lt;/p&gt;

&lt;p&gt;The matrix pencil is often used to solve eigenvalue problems, which involve finding the eigenvectors and eigenvalues of a matrix. In particular, the generalized eigenvalue problem can be formulated as a matrix pencil problem, where the matrices A and B are symmetric and positive definite. The solutions to this problem are the eigenvalues and eigenvectors of the matrix pencil, which can be used to solve a variety of linear algebraic problems.&lt;/p&gt;

&lt;p&gt;The matrix pencil can also be used to represent linear operators and to study the behavior of dynamical systems. In control theory, for example, the matrix pencil is used to describe the transfer function of a linear system, which relates the input and output of the system.&lt;/p&gt;

&lt;p&gt;The matrix pencil is a powerful mathematical tool that has applications in many areas of mathematics and engineering. It allows us to represent and solve a wide range of problems involving matrices and linear systems.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Generalized Eigenvalue Decomposition</title>
   <link href="http://localhost:4000/2023/02/11/ged"/>
   <updated>2023-02-11T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/11/GED</id>
   <content type="html">&lt;p&gt;Generalized eigenvalue decomposition is a mathematical technique that involves finding a set of eigenvectors and eigenvalues for two matrices, typically a symmetric matrix and a positive definite matrix.&lt;/p&gt;

&lt;p&gt;Given two matrices A and B, the generalized eigenvalue decomposition finds a set of eigenvectors x and corresponding eigenvalues  that satisfy the equation:&lt;/p&gt;

\[Ax = \lambda Bx\]

&lt;p&gt;where x is a non-zero vector. In other words, the eigenvalues are scalar values that determine how the eigenvectors of A are scaled when multiplied by B.&lt;/p&gt;

&lt;p&gt;This decomposition is useful in a variety of applications, including solving systems of linear equations, analyzing linear transformations, and solving partial differential equations. The generalized eigenvalue decomposition can also be used to determine the stability of a system in control theory.&lt;/p&gt;

&lt;p&gt;The generalized eigenvalue decomposition can be expressed in the form of a matrix equation as follows:&lt;/p&gt;

\[AX = BX\Lambda\]

&lt;p&gt;where X is a matrix whose columns are the eigenvectors of A, and  is a diagonal matrix whose entries are the corresponding eigenvalues of A.&lt;/p&gt;

&lt;p&gt;The columns of X are typically normalized to have unit length, so that $X^T B X = I$, where $I$ is the identity matrix.&lt;/p&gt;

&lt;p&gt;The generalized eigenvalue decomposition can be computed using various algorithms, including the QR algorithm and the Jacobi algorithm.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Signal Enhancement</title>
   <link href="http://localhost:4000/2023/02/10/signal-enhancement"/>
   <updated>2023-02-10T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/10/signal-enhancement</id>
   <content type="html">&lt;p&gt;Signal enhancement algorithms are used to improve the quality of signals by reducing noise, increasing signal-to-noise ratio (SNR), and enhancing the overall quality of the signal. Here are some common signal enhancement algorithms:&lt;/p&gt;

&lt;h2 id=&quot;1-wiener-filter&quot;&gt;1. Wiener Filter&lt;/h2&gt;

&lt;p&gt;The Wiener filter is a linear filter that minimizes the mean square error between the original signal and the filtered signal. It is based on the assumption that the original signal and the noise are uncorrelated, and the noise is additive and Gaussian.&lt;/p&gt;

&lt;p&gt;The output of the Wiener filter is given by:&lt;/p&gt;

\[Y(k)=\frac{H^*(k)S(k)}{|H(k)|^2S(k)+N(k)}\]

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Y(k) is the filtered signal at frequency k.&lt;/li&gt;
  &lt;li&gt;H(k) is the frequency response of the filter.&lt;/li&gt;
  &lt;li&gt;S(k) is the power spectral density (PSD) of the original signal.&lt;/li&gt;
  &lt;li&gt;N(k) is the PSD of the noise.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Wiener filter can be implemented in the time domain using convolution.&lt;/p&gt;

&lt;h2 id=&quot;2-kalman-filter&quot;&gt;2. Kalman Filter&lt;/h2&gt;

&lt;p&gt;The Kalman filter is a recursive filter that estimates the state of a system based on noisy measurements. It is widely used in control theory and signal processing.&lt;/p&gt;

&lt;p&gt;The state of the system is modeled as a linear combination of the previous state and the input:&lt;/p&gt;

\[x_k=F_kx_{k-1}+B_ku_k\]

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;x_k is the state of the system at time k.&lt;/li&gt;
  &lt;li&gt;F_k is the state transition matrix.&lt;/li&gt;
  &lt;li&gt;B_k is the input matrix.&lt;/li&gt;
  &lt;li&gt;u_k is the input at time k.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The measurement is modeled as a linear combination of the state and the measurement noise:&lt;/p&gt;

\[z_k=H_kx_k+v_k\]

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;z_k is the measurement at time k.&lt;/li&gt;
  &lt;li&gt;H_k is the measurement matrix.&lt;/li&gt;
  &lt;li&gt;v_k is the measurement noise.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Kalman filter estimates the state of the system at each time step and updates the estimate based on the new measurement. The output of the Kalman filter is the estimated state of the system.&lt;/p&gt;

&lt;h2 id=&quot;3-wavelet-denoising&quot;&gt;3. Wavelet Denoising&lt;/h2&gt;

&lt;p&gt;Wavelet denoising is a signal processing technique that uses wavelet transform to remove noise from a signal. The basic idea is to transform the signal into the wavelet domain, where the noise and the signal have different characteristics.&lt;/p&gt;

&lt;p&gt;The wavelet coefficients are thresholded to remove the noise. The thresholding can be hard or soft. In hard thresholding, coefficients below a certain threshold are set to zero. In soft thresholding, coefficients below a certain threshold are shrunk towards zero.&lt;/p&gt;

&lt;p&gt;The inverse wavelet transform is then applied to obtain the denoised signal.&lt;/p&gt;

&lt;p&gt;The equation for hard thresholding is:&lt;/p&gt;

\[W_{i,j} = \begin{cases} W_{i,j}, &amp;amp; \text{if } |W_{i,j}| &amp;gt; T \\ 0, &amp;amp; \text{otherwise} \end{cases}\]

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;W_{i,j} is the wavelet coefficient at scale i and position j.&lt;/li&gt;
  &lt;li&gt;T is the threshold.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The equation for soft thresholding is:&lt;/p&gt;

\[W_{i,j} = \text{sign}(W_{i,j})(|W_{i,j}|-T)_+\]

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;W_{i,j} is the wavelet coefficient at scale i and position j.&lt;/li&gt;
  &lt;li&gt;T is the threshold.&lt;/li&gt;
  &lt;li&gt;(x)_+ = max(0,x).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-independent-component-analysis-ica&quot;&gt;4. Independent Component Analysis (ICA)&lt;/h2&gt;

&lt;p&gt;Independent component analysis (ICA) is a signal processing technique that separates a multivariate signal into independent, non-Gaussian components. The basic idea is to find a linear transformation of the signal that maximizes&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>A Blind Source Separation Method Based on the Time Delayed Correlations and the Wavelet Transform</title>
   <link href="http://localhost:4000/2023/02/09/blind-source-separation-method-based-on-the-time-delayed-correlations-and-the-wavelet-transform"/>
   <updated>2023-02-09T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/09/Blind-Source-Separation-Method-Based-on-the-Time-Delayed-Correlations-and-the-Wavelet-Transform</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Blind source separation method based on
generalized eigendecomposition of time delayed
correlation matrices in the wavelet domain is proposed.
The wavelet domain algorithm can separate the
mixtures when the number of the sources is more than
three, while the time domain algorithm cant. The
proposed method is a fast, stable and easy to
implement algorithm. The computer simulations
results demonstrate the correctness and effectiveness
of the proposed algorithm.
&lt;/p&gt;

&lt;p&gt;Blind source separation(BSS) addresses the problem of recovering a set of source signals( $\mathbf{s})$ from sensor signals $(\mathbf{x})$ only with the assumption that the source signals are mutually statistically independent. When the sensor signals are assumed to follow a linear mixture model, i.e., $\mathbf{x}=\mathbf{A s}$, where $\mathbf{A}$ is the mixing matrix, the problem is to find a separation matrix to estimate the source signals. Here assume that the number of sensor signals is equal to the number of source signals. The BSS problem has been paid wide attention in various fields such as signal analysis and processing of speech, image and biomedical signals, especially, signal extraction, enhancement and denoising problems.&lt;/p&gt;

&lt;p&gt;One of the solutions for the blind source separation problem is based on the generalized eigendecomposition(GED) of a matrix pencil $\left(\mathbf{R}&lt;em&gt;{x 1}, \mathbf{R}&lt;/em&gt;{x 2}\right)$ formed with correlation matrices $\mathbf{R}_{x i}$, $i=1,2$, computed with the sensor signals, the transpose of the eigenvector matrix is the estimation of the separation matrix. There are many different approaches to compute the correlation matrices. Souloumiac considers two segments of sensor signals with distinct energy, Molgedey and Tom consider filtered versions of the sensor signals to compute the correlation matrices, while Schuster and Chang et al. compute time delayed correlation matrices. In this paper we study a BSS algorithm based on the generalized eigendecomposition of the matrix pencil computed with time delayed correlation matrices in the wavelet domain. The gaussianity of the signals in the wavelet domain is weaker than that in the time domain, so the performance of the BSS algorithm in the wavelet domain is better than that in the time domain algorithm.&lt;/p&gt;

&lt;h3 id=&quot;the-generalized-eigendecomposition&quot;&gt;The generalized eigendecomposition&lt;/h3&gt;

&lt;p&gt;The solution for the blind source separation problem is based on the generalized eigendecomposition of the matrix pencil $\left(\mathbf{R}&lt;em&gt;{x 1}, \mathbf{R}&lt;/em&gt;{x 2}\right)$.The generalized eigendecomposition statement of the sensor pencil reads
\(\mathbf{R}_{x 2} \mathbf{E}=\mathbf{R}_{x 1} \mathbf{E} \mathbf{D}\)
where $\mathbf{E}$ is the eigenvector matrix and $\mathbf{D}$ is a diagonal matrix with the eigenvalues of the sensor pencil. $\mathbf{E}$ will be unique if $\mathbf{D}$ has distinct eigenvalues. Otherwise the eigenvectors which correspond to the same eigenvalue might be substituted by their linear combinations without affecting the previous equality. So, supposing that the diagonal elements of $\mathbf{D}$ are all distinct.
The sensor pencil is related to a pencil $\left(\mathbf{R}&lt;em&gt;{s 1}, \mathbf{R}&lt;/em&gt;{s 2}\right)$ computed with the source signals via the mixing matrix as described by the following relations
\(\mathbf{R}_{x 1}=\mathbf{A} \mathbf{R}_{s 1} \mathbf{A}^T \text { and } \mathbf{R}_{x 2}=\mathbf{A} \mathbf{R}_{s 2} \mathbf{A}^T\)
According to Parlett ,two pencils related as described by Eq.(2) are called congruent pencils if $\mathbf{A}$ is an invertible matrix, then&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proposition.&lt;/em&gt; The eigenvectors of the source pencil are related to the eigenvectors of the sensor pencil by the mixing matrix,
\(\mathbf{E}_s=\mathbf{A}^T \mathbf{E}\)
where $\mathbf{E}_s$ is the eigenvector matrix of the source pencil. We can see from Eq.(3) that the transpose of the eigenvector matrix of the sensor pencil $\mathbf{E}^T$ forms the separation matrix, i.e.,
\(\hat{\mathbf{S}}=\mathbf{W} \mathbf{X}=\mathbf{E}^T \mathbf{X}\)
if $\mathbf{E}_s$ is a diagonal or permutation matrix. Then $\hat{\mathbf{S}}$ will be an estimation of the source signals except for the usual scaling and ordering indeterminacies.&lt;/p&gt;

&lt;p&gt;Similar results are achieved if the number of mixtures is higher than the number of sources.
There are different suggestions to compute the sensor matrix pencil. It can be shown that a pencil of correlation matrices computed with different time delay of the sensor signals has a congruent pencil in source domain as described by Eq.(2). Let $\mathbf{X}$ be a $m \times N$ matrix containing a segment with $N$ samples of each of $m$ sensor signals. The time delayed correlation matrix is the correlation of the delayed data with the original data ${ }^{[2]}$, then $\mathbf{R}&lt;em&gt;{x i}$ for a delay $d_i$ can be written as
\(\mathbf{R}_{x i}=\frac{1}{N-d_i} \mathbf{X H}^T \mathbf{X}^T\)
where $\mathbf{H}$ has only one nonzero diagonal which is the $d_i$ th diagonal lower than the main diagonal, if $d_i=0, \mathbf{H}$ will be the identity matrix. The corresponding time delayed correlation matrix of the source signals is
\(\mathbf{R}_{s i}=\frac{1}{N-d_i} \mathbf{S H}^T \mathbf{S}^T\)
Substituting $\mathbf{x}=$ As in Eq. (5)
\(\mathbf{R}_{x i}=\frac{1}{N-d_i} \mathbf{A} \mathbf{S} \mathbf{H}^T \mathbf{S}^T \mathbf{A}^T\)
It is easy to see from Eqs.(6) and (7) that the sensor pencil $\left(\mathbf{R}&lt;/em&gt;{x 1}, \mathbf{R}&lt;em&gt;{x 2}\right)$ is congruent to the source pencil $\left(\mathbf{R}&lt;/em&gt;{s 1}, \mathbf{R}_{s 2}\right)$ as defined in Eq.(2). The pair of matrices computed for different time delays forms a pencil whose eigenvalues are distinct.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Bss algorithm based on the wavelet transform&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The wavelet transform maps a signal from the time domain to the time-scale domain. The transformation makes the gaussianity of the signals become weaker, and it is very useful for blind source separation problem, as will be analyzed in the next section. A basic wavelet function is defined, called the mother wavelet, which is translated and dilated, resulting in a set of orthonormal wavelet basis functions ${ }^{[6]}$.Then, the wavelet transform of a signal is given by the inner product of the signal with each of the basis function. Discrete wavelets are defined as
\(\psi_{j, q}(k)=2^{-j / 2} \psi\left(2^{-j} k-q\right)\)
where $j, q \in \mathrm{Z}$, and $\mathrm{Z}$ denotes the field of integers, and the wavelet transform of a signal $x(k)$ is given by
\(c_{j, A}=\left(x(k), \psi_{j, A}(k)\right)\)
where $c_{j, q}$ denotes the transform coefficients, and $(\cdot, \cdot)$ represents the inner product. Denote $W{}$ and $W^{-1}{}$ the forward and reverse discrete wavelet&lt;/p&gt;

&lt;p&gt;transform(DWT) operators. Taking the wavelet transform of the vector of the sensor signals, then the wavelet coefficients matrix $\mathbf{C}&lt;em&gt;x$ of the sensor signal $\mathbf{X}$ is given by
\(\mathbf{C}_x=W\{\mathbf{X}\}\)
so, each row of $C_x$ is the wavelet coefficients of the corresponding row of $\mathbf{X}$. Then the correlation matrix of the time delay of the wavelet coefficients is
\(\mathbf{R}_{c_x}=\frac{1}{N-d_i} \mathbf{C}_x \mathbf{H}^T \mathbf{C}_x^T\)
Using the linearity property of the inner $\operatorname{product}^{[7]}$
\(\begin{gathered}
((x(k)+z(k)), y(k))=(x(k), y(k))+(z(k), y(k)) \\
(\alpha x(k), y(k))=\alpha(x(k), y(k))
\end{gathered}\)
when the mixing matrix $\mathbf{A}$ is real and time-invariant, the wavelet transform of the $i$ th sensor signal $x_i(k)$ in $\mathbf{x}=$ As is given by
\(\begin{gathered}
W\left\{x_i(k)\right\}=W\left\{\sum_{l=1}^m a_{i l} s_l(k)\right\} \\
\left(x_i(k), \psi_{j, q}(k)\right)=\sum_{l=1}^m a_{i l}\left(s_i(k), \psi_{j, q}(k)\right)
\end{gathered}\)
So, we obtain, in matrix form
\(\mathrm{C}_x=\mathrm{AC}_s\)
where $C_s$ is the wavelet coefficients matrix of the source signal, Eq.(16) has the same formulation with $\mathbf{x}=\mathbf{A s}$. So, it is easy to prove that the pencil $\left(\mathbf{R}&lt;/em&gt;{c_{11}}, \mathbf{R}&lt;em&gt;{c&lt;/em&gt;{12}}\right)$ has a congruent pencil $\left(\mathbf{R}&lt;em&gt;{c&lt;/em&gt;{11}}, \mathbf{R}&lt;em&gt;{c&lt;/em&gt;{12}}\right)$, as described by Eq.(2), where the pencil ( $\left.\mathbf{R}&lt;em&gt;{c&lt;/em&gt;{t 1}}, \mathbf{R}&lt;em&gt;{c&lt;/em&gt;{t 2}}\right)$ is computed by the wavelet coefficients of source signals. The generalized eigendecomposition of the pencil $\left(\mathbf{R}&lt;em&gt;{c&lt;/em&gt;{x 1}}, \mathbf{R}&lt;em&gt;{c&lt;/em&gt;{x 2}}\right)$ is
\(\mathbf{R}_{c_{x 2}} \mathbf{E}_c=\mathbf{R}_{c_{x 1}} \mathbf{E}_c \mathbf{D}_c\)
The transpose of the eigenvector matrix $\mathbf{E}_c{ }^T$ is an estimation of the separation matrix. So, the estimation of the wavelet coefficients of the independent components is
\(\hat{\mathbf{C}}_s=\mathbf{E}_c^T \mathbf{C}_x\)
The inverse wavelet transform of $\hat{C}_s$ represents the estimation of the source signals
\(\hat{\mathbf{S}}=W^{-1}\left\{\hat{\mathbf{C}}_s\right\}\)&lt;/p&gt;

&lt;h2 id=&quot;note&quot;&gt;Note&lt;/h2&gt;

&lt;p&gt;To blind source separation problem, we can obtain the estimation of the source signals by making linear transformation to $x$ to maximize the non-gaussianity of each column of $x$. We use kurtosis as the measure of non-gaussianity of a random variable
\(\operatorname{kurt}(x)=E\left\{x^4\right\}-3\left(E\left\{x^2\right\}\right)^2\)
Where $E{}$ is the mean, the further away the probability density function of a random variable is from the Gaussian distribution, the further away is its kurtosis from zero. The kurtosis of the sensor signals and their wavelet coefficients are given in Table 4. It can be seen from Table 4 that the non-gaussianity of the sensor signals is weaker than that of its wavelet coefficients. So the separation performance of the wavelet domain algorithm is better than that of the time domain algorithm. This property is especially outstanding when the number of source signals is more than three.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discrete Fourier Transformation</title>
   <link href="http://localhost:4000/2023/02/08/dft"/>
   <updated>2023-02-08T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/08/DFT</id>
   <content type="html">&lt;h2 id=&quot;discrete-fourier-transformation-dft&quot;&gt;Discrete Fourier Transformation (DFT)&lt;/h2&gt;

&lt;p&gt;The Discrete Fourier Transformation (DFT) is a mathematical technique used to transform a discrete-time signal from the time domain into the frequency domain. It allows us to analyze the frequency content of a signal and is widely used in signal processing, communication systems, and scientific computing.&lt;/p&gt;

&lt;p&gt;The DFT can be expressed mathematically as follows:&lt;/p&gt;

\[X_k = \sum_{n=0}^{N-1} x_n e^{-\frac{2\pi i}{N}kn},\quad k=0,1,\dots,N-1\]

&lt;p&gt;where $x_n$ is the input sequence of length $N$, and $X_k$ is the DFT coefficient for frequency $k$. The DFT is a linear transformation, and the inverse transformation can be expressed as:&lt;/p&gt;

\[x_n = \frac{1}{N} \sum_{k=0}^{N-1} X_k e^{\frac{2\pi i}{N}kn},\quad n=0,1,\dots,N-1\]

&lt;p&gt;The DFT is used in many applications, including digital signal processing, spectral analysis, and image processing. In particular, it is often used in the design and analysis of digital filters, as well as in compression and encryption algorithms.&lt;/p&gt;

&lt;p&gt;One of the most famous algorithms for computing the DFT is the Fast Fourier Transform (FFT), which exploits certain symmetries and properties of the DFT to reduce the computational complexity from $O(N^2)$ to $O(N \log N)$. This makes the FFT much faster than the brute-force approach, especially for large values of $N$.&lt;/p&gt;

&lt;p&gt;Overall, the Discrete Fourier Transformation is a powerful tool for analyzing and processing signals in a wide range of applications, and the Fast Fourier Transform algorithm has made it practical to compute the DFT efficiently for large data sets.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discrete Sine Transformation</title>
   <link href="http://localhost:4000/2023/02/07/dst"/>
   <updated>2023-02-07T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/07/DST</id>
   <content type="html">&lt;h2 id=&quot;discrete-sine-transformation-dst&quot;&gt;Discrete Sine Transformation (DST)&lt;/h2&gt;

&lt;p&gt;The Discrete Sine Transformation (DST) is a mathematical technique used in signal processing to transform a discrete sequence of values into a sequence of sine waves with different frequencies. It is closely related to the Discrete Fourier Transformation (DFT), but is used specifically for real-valued input data, where the input signal is odd-symmetric.&lt;/p&gt;

&lt;p&gt;The DST can be expressed mathematically as follows:&lt;/p&gt;

\[X_k = \sum_{n=0}^{N-1} x_n \sin \left(\frac{\pi (n+1)(k+1)}{N+1}\right),\quad k=0,1,\dots,N-1\]

&lt;p&gt;where $x_n$ is the input sequence of length $N$, and $X_k$ is the DST coefficient for frequency $k$. The DST is a linear transformation, and the inverse transformation can be expressed as:&lt;/p&gt;

\[x_n = \frac{2}{N+1} \sum_{k=0}^{N-1} X_k \sin \left(\frac{\pi (n+1)(k+1)}{N+1}\right),\quad n=0,1,\dots,N-1\]

&lt;p&gt;The DST has various applications in image and audio processing, as well as in solving differential equations numerically. It is also used in compression algorithms, such as JPEG2000, to transform image data into a more compact form for storage and transmission.&lt;/p&gt;

&lt;p&gt;Overall, the Discrete Sine Transformation is a useful mathematical tool for analyzing and processing real-valued signals in a variety of applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Numerical differentiation</title>
   <link href="http://localhost:4000/2023/02/06/numerical-differentiation"/>
   <updated>2023-02-06T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/06/numerical-differentiation</id>
   <content type="html">&lt;p&gt;Numerical differentiation is a problem to determine the derivative of a function from the values on an interval or some scattered points. It arises from many scientific researches and applications, e.g., the identification of the discontinuous points in an image process [1]; the problem of solving the Abel integral equation [2]; the problem of determining the peaks in chemical spectroscopy [3] and some inverse problems in mathematical physical equations [4]. The main difficulty is that it is an ill-posed problem, which means that small errors in the measurement of a function may lead to large errors in its computed derivatives [5,4]. A number of techniques have been developed for numerical differentiation [6-8,4,9]. One type of method is to transform the differentiation problem into an operator equation of the first kind. In fact, for given $g(t) \in H^1[0,1]$, to find $f=D g=g^{\prime}$ is equivalent to solve the Volterra integral equation of the first kind
\(\left(K_1 f\right)(s)=\int_0^s f(t) \mathrm{d} t=g(s)-g(0), \quad s \in[0,1] .\)
In this paper we will point out the disadvantage of operator $K_1$ and a new operator which is a modified form of $K_1$ will be presented. Since a singular system of the new operator can be obtained easily, it seems natural to use the TSVD method for this problem and good results may be expected. A convergence result, analogous to the literature [4], will be obtained by our method. Comparing with the Tikhonov regularization method used in [4], the regularization parameter can be obtained easily by TSVD method. Moreover, it is well known that the Tikhonov method has a finite saturation index, which means that it is impossible to improve the convergence rates of the regularization solution with increasing smoothness assumption of exact solutions. But for TSVD method this disadvantage will be overcome. Moreover, we will point out that our method calls for a discrete sine transform when the noisy values of the function to be differentiated at the nodes are given, so the method can be implemented easily and fast.&lt;/p&gt;

&lt;h1 id=&quot;numerical-differentiation&quot;&gt;Numerical Differentiation&lt;/h1&gt;

&lt;p&gt;Numerical differentiation is the process of approximating the derivative of a function using numerical methods. It is an important tool in scientific computing and is used in a variety of fields, including engineering, physics, and economics. There are several approaches to numerical differentiation, each with its own strengths and weaknesses.&lt;/p&gt;

&lt;h2 id=&quot;finite-difference-methods&quot;&gt;Finite Difference Methods&lt;/h2&gt;

&lt;p&gt;Finite difference methods are the most common approach to numerical differentiation. These methods approximate the derivative of a function by computing the difference quotient:&lt;/p&gt;

\[f&apos;(x) \approx \frac{f(x+h) - f(x)}{h}\]

&lt;p&gt;where $h$ is a small positive number. This is known as the forward difference formula. Other difference formulas include the backward difference formula:&lt;/p&gt;

\[f&apos;(x) \approx \frac{f(x) - f(x-h)}{h}\]

&lt;p&gt;and the central difference formula:&lt;/p&gt;

\[f&apos;(x) \approx \frac{f(x+h) - f(x-h)}{2h}\]

&lt;p&gt;The choice of formula depends on the accuracy and smoothness of the function being approximated.&lt;/p&gt;

&lt;h2 id=&quot;lagrange-polynomials&quot;&gt;Lagrange Polynomials&lt;/h2&gt;

&lt;p&gt;Lagrange polynomials are another approach to numerical differentiation that involves fitting a polynomial to a set of data points. Given a set of $n+1$ points $(x_i, f(x_i))$, the Lagrange polynomial is given by:&lt;/p&gt;

\[p_n(x) = \sum_{i=0}^n f(x_i) \prod_{j\ne i} \frac{x-x_j}{x_i-x_j}\]

&lt;p&gt;The derivative of the Lagrange polynomial can then be used to approximate the derivative of the original function.&lt;/p&gt;

&lt;h2 id=&quot;splines&quot;&gt;Splines&lt;/h2&gt;

&lt;p&gt;Splines are a method for approximating a function using piecewise polynomials. The polynomials are typically chosen to be cubic, and are required to be continuous at the points where they meet (known as knots). The second derivative of the polynomials is also required to be continuous, which ensures that the approximation is smooth. The derivatives of the splines can then be used to approximate the derivative of the original function.&lt;/p&gt;

&lt;h2 id=&quot;richardson-extrapolation&quot;&gt;Richardson Extrapolation&lt;/h2&gt;

&lt;p&gt;Richardson extrapolation is a technique for improving the accuracy of finite difference approximations. It involves using the difference quotient at several different step sizes $h$ to derive a more accurate approximation. The formula for Richardson extrapolation is:&lt;/p&gt;

\[f&apos;(x) \approx \frac{4f_{h/2}(x) - f_h(x)}{3}\]

&lt;p&gt;where $f_h(x)$ and $f_{h/2}(x)$ are the difference quotients at step sizes $h$ and $h/2$, respectively.&lt;/p&gt;

&lt;h2 id=&quot;automatic-differentiation&quot;&gt;Automatic Differentiation&lt;/h2&gt;

&lt;p&gt;Automatic differentiation is a method for computing derivatives numerically that is more accurate and efficient than finite difference methods. It uses the chain rule of differentiation to compute derivatives at each step of the computation, rather than approximating them numerically. This approach can be especially useful for functions with many variables or complex structures.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Numerical differentiation is a powerful tool for approximating the derivatives of functions. Finite difference methods are the most common approach, but other techniques such as Lagrange polynomials, splines, Richardson extrapolation, and automatic differentiation can provide more accurate and efficient approximations in certain situations.&lt;/p&gt;

&lt;h1 id=&quot;solving-numerical-differentiation-in-the-presence-of-noise-with-integral-equations&quot;&gt;Solving Numerical Differentiation in the Presence of Noise with Integral Equations&lt;/h1&gt;

&lt;p&gt;When performing numerical differentiation on data that is affected by noise, it can be challenging to obtain accurate and reliable results. However, one possible approach to this problem is to use integral equations to formulate the problem and derive a solution that takes into account the noise in the data. In this article, we will explore how integral equations can be used for numerical differentiation in the presence of noise, and we will provide some examples and techniques to illustrate this approach.&lt;/p&gt;

&lt;h2 id=&quot;the-problem-of-numerical-differentiation-with-noisy-data&quot;&gt;The Problem of Numerical Differentiation with Noisy Data&lt;/h2&gt;

&lt;p&gt;The problem of numerical differentiation consists of estimating the derivative of a function based on a set of discrete data points. When the data is exact and noise-free, this problem can be solved using various numerical methods, such as finite differences, interpolation, or regression. However, in many practical situations, the data is affected by noise, which can cause errors and instability in the differentiation process.&lt;/p&gt;

&lt;p&gt;To illustrate this problem, lets consider an example of a noisy data set:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = [-2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5] 
y = [-2.635, -1.771, -0.768, -0.316, 0.383, 0.108, 0.704, 0.857, 2.275, 2.975, 4.350]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This data set represents a noisy version of the function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(x) = x^3 - 2x^2 - 3x + 2&lt;/code&gt;, which has the derivative &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&apos;(x) = 3x^2 - 4x - 3&lt;/code&gt;. If we try to estimate the derivative using finite differences or other standard methods, we may obtain results that are inaccurate or unreliable due to the noise in the data.&lt;/p&gt;

&lt;h2 id=&quot;using-integral-equations-for-numerical-differentiation&quot;&gt;Using Integral Equations for Numerical Differentiation&lt;/h2&gt;

&lt;p&gt;One possible approach to solving the problem of numerical differentiation with noisy data is to use integral equations. Integral equations involve expressing the problem as an equation involving an unknown function that needs to be solved for, and then using a known relationship between the function and its derivative to derive an integral equation that can be solved numerically.&lt;/p&gt;

&lt;p&gt;To illustrate this approach, lets consider the following integral equation:&lt;/p&gt;

\[\int_{-h}^{h} K(x,t) f&apos;(t) dt = \frac{f(x+h) - f(x-h)}{2h}\]

&lt;p&gt;In this equation, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&apos;(t)&lt;/code&gt; represents the derivative of the unknown function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(x)&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;K(x,t)&lt;/code&gt; is a kernel function that depends on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h&lt;/code&gt; is a small parameter that controls the width of the integral. The right-hand side of the equation represents a finite difference approximation to the derivative of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(x)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To solve this integral equation, we can use a technique known as collocation, which involves discretizing the equation by choosing a set of points &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x_i&lt;/code&gt; at which the equation is evaluated. We can then approximate the unknown function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(x)&lt;/code&gt; using a set of basis functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;phi_i(x)&lt;/code&gt;, and write the integral equation as a system of linear equations:&lt;/p&gt;

\[\sum_{j=1}^{N} K_{i,j} f&apos;_j = D_i\]

&lt;p&gt;In this equation, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; is the number of collocation points, $K_{i,j} = \int_{-h}^{h} K(x_i,t)$&lt;/p&gt;

&lt;h1 id=&quot;numerical-differentiation-with-noisy-streaming-data-using-online-algorithms&quot;&gt;Numerical Differentiation with Noisy Streaming Data using Online Algorithms&lt;/h1&gt;

&lt;p&gt;Numerical differentiation is a fundamental problem in many fields of science and engineering, where we want to estimate the derivative of a function at a given point based on sampled data. However, when the data is noisy or when it arrives in a streaming fashion, this problem becomes more challenging. In this article, we will discuss how to use online algorithms to solve the problem of numerical differentiation with noisy streaming data.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;Suppose we have a function f(x) that we want to differentiate at a point x0. We can use the following formula to approximate the derivative:&lt;/p&gt;

\[f&apos;(x0) \approx \frac{(f(x0+h) - f(x0-h))}{(2h)}\]

&lt;p&gt;where h is a small step size. However, if the data we have is noisy, this approximation may not be accurate. Moreover, if the data arrives in a streaming fashion, we cannot wait until all the data is available to compute the derivative.&lt;/p&gt;

&lt;h2 id=&quot;offline-approaches&quot;&gt;Offline Approaches&lt;/h2&gt;

&lt;p&gt;Before we discuss online algorithms, lets briefly review some of the offline approaches to numerical differentiation with noisy data. One common approach is to use smoothing techniques, such as the Savitzky-Golay filter or the moving average filter, to remove the noise from the data before computing the derivative. Another approach is to use integral equations, such as the Tikhonov regularization or the least-squares method, to estimate the unknown function and its derivative from the noisy data.&lt;/p&gt;

&lt;h2 id=&quot;online-algorithms&quot;&gt;Online Algorithms&lt;/h2&gt;

&lt;p&gt;While the offline approaches discussed above can be effective for solving numerical differentiation problems with noisy data, they are not well-suited for streaming data. Online algorithms, on the other hand, are designed to continuously update their estimates based on new data as it arrives, and they can be more efficient and accurate in a streaming context.&lt;/p&gt;

&lt;h3 id=&quot;recursive-least-squares&quot;&gt;Recursive Least Squares&lt;/h3&gt;

&lt;p&gt;One possible online algorithm for numerical differentiation with noisy data is recursive least squares (RLS). RLS is an adaptive algorithm that can continuously update its estimates based on new data as it arrives, and it has been shown to be effective for solving similar problems in a streaming context.&lt;/p&gt;

&lt;p&gt;To apply RLS to numerical differentiation with noisy data, we can first choose a set of basis functions and a kernel function as before, and then use RLS to estimate the unknown function and its derivative based on the incoming data. The algorithm would work by updating the estimate of the function and its derivative at each time step based on the new data, and using a forgetting factor to weight the importance of the old data versus the new data.&lt;/p&gt;

&lt;h3 id=&quot;extended-kalman-filter&quot;&gt;Extended Kalman Filter&lt;/h3&gt;

&lt;p&gt;Another possible online algorithm for numerical differentiation with noisy data is the extended Kalman filter (EKF). The EKF is a recursive algorithm that can estimate the state of a dynamic system based on noisy measurements, and it has been shown to be effective for solving similar problems in a streaming context.&lt;/p&gt;

&lt;p&gt;To apply the EKF to numerical differentiation with noisy data, we can use the same integral equation and basis functions as before, and then use the EKF to estimate the unknown function and its derivative based on the incoming data. The algorithm would work by updating the estimate of the function and its derivative at each time step based on the new data, and using a Kalman gain to weight the importance of the measurement noise versus the process noise.&lt;/p&gt;

&lt;h2 id=&quot;conclusion-1&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In conclusion, while the specific details of how to apply online algorithms to numerical differentiation with noisy data may vary depending on the specific problem and algorithm, the general approach involves adapting the offline methods discussed above to the streaming context by using adaptive algorithms that can continuously update their estimates based on new data as it arrives. These online algorithms can be more efficient and accurate than their offline counterparts in a streaming context,&lt;/p&gt;

&lt;h1 id=&quot;complex-variable-methods-for-numerical-differentiation-with-noisy-data&quot;&gt;Complex Variable Methods for Numerical Differentiation with Noisy Data&lt;/h1&gt;

&lt;p&gt;Numerical differentiation is a fundamental problem in many fields of science and engineering, where we want to estimate the derivative of a function at a given point based on sampled data. However, when the data is noisy, this problem becomes more challenging. In this article, we will discuss how to use complex variable methods to solve the problem of numerical differentiation with noisy data.&lt;/p&gt;

&lt;h2 id=&quot;the-problem-1&quot;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;Suppose we have a function $f(z)$ that we want to differentiate at a point $z_0$. We can use the following formula to approximate the derivative:&lt;/p&gt;

\[f&apos;(z_0) \approx \frac{f(z_0 + h) - f(z_0 - h)}{2h}\]

&lt;p&gt;where $h$ is a small step size. However, if the data we have is noisy, this approximation may not be accurate. Moreover, if the function $f(z)$ is complex-valued, the above formula may not be well-defined.&lt;/p&gt;

&lt;h2 id=&quot;complex-variable-methods&quot;&gt;Complex Variable Methods&lt;/h2&gt;

&lt;p&gt;Complex variable methods provide an elegant and powerful way to differentiate complex-valued functions, even in the presence of noise. The key idea is to use the Cauchy-Riemann equations to express the derivative of a complex-valued function in terms of its analytic continuation to the complex plane.&lt;/p&gt;

&lt;h3 id=&quot;cauchy-riemann-equations&quot;&gt;Cauchy-Riemann Equations&lt;/h3&gt;

&lt;p&gt;The Cauchy-Riemann equations are a set of conditions that a complex-valued function $f(z)$ must satisfy in order to be analytic in a region of the complex plane. The equations are:&lt;/p&gt;

\[\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} \quad \text{and} \quad \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}\]

&lt;p&gt;where $u(x,y)$ and $v(x,y)$ are the real and imaginary parts of $f(z) = u(x,y) + iv(x,y)$, respectively. If $f(z)$ is analytic, then it satisfies the Cauchy-Riemann equations, and we can use these equations to express the derivative of $f(z)$ in terms of its analytic continuation.&lt;/p&gt;

&lt;h3 id=&quot;wirtinger-calculus&quot;&gt;Wirtinger Calculus&lt;/h3&gt;

&lt;p&gt;The Wirtinger calculus provides a convenient way to express the Cauchy-Riemann equations in terms of partial derivatives with respect to $z$ and $z^&lt;em&gt;$, where $z^&lt;/em&gt;$ denotes the complex conjugate of $z$. Using the Wirtinger calculus, we can write the Cauchy-Riemann equations as:&lt;/p&gt;

\[\frac{\partial f}{\partial z^*} = 0 \quad \text{and} \quad \frac{\partial f}{\partial z} = f&apos;(z)\]

&lt;p&gt;where $f(z)$ is the derivative of $f(z)$ with respect to $z$. These equations show that the derivative of $f(z)$ can be expressed in terms of its partial derivatives with respect to $z$ and $z^*$.&lt;/p&gt;

&lt;h3 id=&quot;wirtinger-derivatives&quot;&gt;Wirtinger Derivatives&lt;/h3&gt;

&lt;p&gt;The Wirtinger derivatives are defined as:&lt;/p&gt;

\[\frac{\partial}{\partial z} = \frac{1}{2}\left(\frac{\partial}{\partial x} + i\frac{\partial}{\partial y}\right) \quad \text{and} \quad \frac{\partial}{\partial z^*} = \frac{1}{2}\left(\frac{\partial}{\partial x} - i\frac{\partial}{\partial y}\right)\]

</content>
 </entry>
 
 <entry>
   <title>A new approach to numerical differentiation</title>
   <link href="http://localhost:4000/2023/02/05/a-new-approach-to-numerical-differentiation"/>
   <updated>2023-02-05T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/05/a-new-approach-to-numerical-differentiation</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In this paper we consider the numerical differentiation of functions specified by noisy data.
A new approach, which is based on an integral equation of the first kind with a suitable
compact operator, is presented and discussed. Since the singular system of the compact
operator can be obtained easily, TSVD is chosen as the needed regularization technique
and we show that the method calls for a discrete sine transform, so the method can be
implemented easily and fast.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Numerical differentiation is a problem to determine the derivative of a function from the values on an interval or some scattered points. It arises from many scientific researches and applications, e.g., the identification of the discontinuous points in an image process [1]; the problem of solving the Abel integral equation [2]; the problem of determining the peaks in chemical spectroscopy [3] and some inverse problems in mathematical physical equations [4]. The main difficulty is that it is an ill-posed problem, which means that small errors in the measurement of a function may lead to large errors in its computed derivatives [5,4]. A number of techniques have been developed for numerical differentiation [6-8,4,9]. One type of method is to transform the differentiation problem into an operator equation of the first kind. In fact, for given $g(t) \in H^1[0,1]$, to find $f=D g=g^{\prime}$ is equivalent to solve the Volterra integral equation of the first kind
\(\left(K_1 f\right)(s)=\int_0^s f(t) \mathrm{d} t=g(s)-g(0), \quad s \in[0,1] .\)
In this paper we will point out the disadvantage of operator $K_1$ and a new operator which is a modified form of $K_1$ will be presented. Since a singular system of the new operator can be obtained easily, it seems natural to use the TSVD method for this problem and good results may be expected. A convergence result, analogous to the literature [4], will be obtained by our method. Comparing with the Tikhonov regularization method used in [4], the regularization parameter can be obtained easily by TSVD method. Moreover, it is well known that the Tikhonov method has a finite saturation index, which means that it is impossible to improve the convergence rates of the regularization solution with increasing smoothness assumption of exact solutions. But for TSVD method this disadvantage will be overcome. Moreover, we will point out that our method calls for a discrete sine transform when the noisy values of the function to be differentiated at the nodes are given, so the method can be implemented easily and fast.&lt;/p&gt;

&lt;h2 id=&quot;numerical-implementation&quot;&gt;Numerical Implementation&lt;/h2&gt;

&lt;p&gt;In practical problem, the perturbed data of functions is usually given at nodes. In this case, our approach naturally calls for a discrete sine transform(DST) of the data.
Give $N+1$ knots
\(t_j=j h, \quad h=\frac{1}{N}, j=0,1, \ldots, N\)
and the noisy vector $\mathbf{g}^\delta=\left(\mathbf{g}&lt;em&gt;0^\delta, \mathbf{g}_1^\delta, \ldots, \mathbf{g}_N^\delta\right)$ of the vector $\mathbf{g}=\left(\mathbf{g}_0, \mathbf{g}_1, \ldots, \mathbf{g}_N\right)=\left(g\left(t_0\right), g\left(t_1\right), \ldots, g\left(t_N\right)\right)$ is given, and the condition
\(\left\|\mathbf{g}^\delta-\mathbf{g}\right\| \leq \delta\)
is assumed. Then we let $\overline{\mathbf{g}}=\left(\overline{\mathbf{g}}_0, \overline{\mathbf{g}}_2, \ldots, \overline{\mathbf{g}}&lt;/em&gt;{N-1}\right)$, where,
\(\overline{\mathbf{g}}_i=\mathbf{g}_i^\delta+(i-N) h \mathbf{g}_1^\delta+i h \mathbf{g}_N^\delta, \quad i=0,1, \ldots, N-1 .\)
Then the expansion
\(\overline{\mathbf{g}}_i=\sum_{k=1}^N C_k \sin (k \pi \mathrm{i} h)\)
can be obtained, where the coefficients
\(C_k=\frac{2}{N} \sum_{j=1}^N \mathbf{g}_j^\delta \sin (k \pi j / N), \quad k=1,2, \ldots, N .\)
We let
\(\mathbf{r}^n=\left(\mathbf{r}_0^n, \mathbf{r}_1^n, \ldots, \mathbf{r}_{N-1}^n\right)\)
where
\(\mathbf{r}_j^n=\sum_{k=n}^N C_k \sin (k \pi \mathrm{i} h)\)&lt;/p&gt;

&lt;p&gt;then we can give the approximate derivative of function $g$
\(f^\delta(t)=\sum_{k=1}^m C_k k \pi \cos (k \pi t)\)
where $m$ is determined by the discrepancy principle
\(\left\|\mathbf{r}^{m+1}\right\| \leq \tau \widehat{\delta}&amp;lt;\left\|\mathbf{r}^m\right\|\)
where
\(\widehat{\delta}= \begin{cases}\delta, &amp;amp; \mathbf{g}_0^\delta=g(0), \mathbf{g}_N^\delta=g\left(t_N\right) \\ \tilde{\delta}, &amp;amp; \text { other cases. }\end{cases}\)
In the following, we present numerical results of some examples. In all the cases, $N=2048$. The perturbed discrete data are given by
\(\mathbf{g}_i^\delta=g\left(t_i\right)+\epsilon_i, \quad\left|\epsilon_i\right|&amp;lt;\delta_1\)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Time Series Classification</title>
   <link href="http://localhost:4000/2023/02/04/time-series-classification"/>
   <updated>2023-02-04T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/04/time-series-classification</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Typical classification approaches can be categorized as
instance-based (e.g., one nearest neighbor classifier with
euclidean distance (NN-Euclidean), or dynamic time warping
distance (NNDTW)), shapelet featurebased  and local pattern-frequency histogram based
methods Instance-based methods, like
NNDTW, have been successfully used for TSC and shown to
be very hard to beat  but they are usually less
interpretable. Shapelet is another promising method for
TSC, and it discovers subsequences that are discriminative
of class membership and provides more interpretable
results, but searching for shapelets on large datasets becomes
time-consuming or even intractable. Feature-based
methods do show promising classification results, but their
capabilities are largely attributed to strong classifiers like
SVM, adaboost and random forest, instead of being due to
better global/local features and representations.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Time series classification methods can be categorized into
instance-based, shapelets, feature-based and pattern frequency
histogram methods.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Instance-based methods predict labels of test time series
based on their similarity to the training instances. The most
popular similarity metrics include euclidean distance and
elastic distances, e.g., the dynamic time warping (DTW)
distance. Using a single nearest neighbor, with euclidean
distance (NNEuclidean) or DTW distance (NNDTW), has
demonstrated successful time series label prediction. DTW
allows time series to be locally shifted, contracted and
stretched, and lengths of time series hence need not be the
same. Therefore, DTW usually gives a better similarity
measurement than Euclidean distance, and NNDTW has
been shown to be very hard to beat on many datasets.
A number of more complex elastic distance measures have
been proposed, including longest common subsequences
(LCSS), Edit distance with Real Penalty (ERP)
and edit distance on Real Sequence (EDR). However,
in 30, the authors claimed that no other elastic distance
measure outperforms DTW by a statistically significant
amount, and DTW is the best measure. Instance-based
approaches, like NN-euclidean and NNDTW, are accurate,
but they are less interpretable, since they are based on
global matching and provide limited insights into the temporal
characteristics.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Shapelet is a localized time series subsequence, which is
discriminative of class membership, and it was first proposed
and used by Ye and Keogh [1] for time series classification.
The original shapelet algorithm [1] searches for
shapelets recursively, and builds a decision tree using different
shapelets as splitting criteria. However, the expressiveness
of shapelets is limited to binary decision questions.
In [4], the authors proposed logical-shapelets, specifically
conjunctions or disjunctions of shapelets, which are shown
to be more expressive than a single shapelet, and toexperimentally outperform the original shapelet algorithm.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The above two algorithms embed shapelet discovery in a
decision tree, while in [2], the authors separate shapelet discovery
from classifier by finding the best k shapelets in a
single scan of all time series. The shapelets are used to transform
the data, where each attribute in the new dataset represents
the distance of a time series to one of the k shapelets.
Hills et al. demonstrate that the transformed data, in conjunction
with more complex classifiers, produces better
accuracies than the embedded shapelet tree. Since shapelets
are localized class-discriminative subsequences, shapeletsbased
methods have increased interpretability than global
instance-based matching. The main drawback is the time
complexity of searching for shapelets, and subsequent
research, e.g.,  focuses on developing efficient shapeletsearching
algorithms.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Feature-based methods generally consist of two sequential
steps: extract features and train a classifier based on features.
Typical global features include statistical features, like
variance and mean, PCA coefficients, DFT coefficients, zerocrossing
rate. These features are extracted either from
time domain or from transformed domains, like frequency
domain and principal component space. Afterwards, the
extracted features either go through feature selection procedures
to prune less significant ones [5], or are fed directly
into complex classifiers, like multi-layer neural network [31].
Global features lose temporal information, although it is
potentially informative for classification. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In [8], the authors
extracted features from intervals of time series, constructed
and then boosted binary stumps on these interval features,
and trained an SVM on outputs of the boosted binary
stumps. In [6], the authors extracted simple interval features
as well, including mean, variance and slope, trained a random
forest ensemble classifier, and showed better performance
than NNDTW. Although feature-based methods
have shown promising classification results, their capabilities
are largely attributed to strong classifiers such as SVM,
adaboost and random forest, instead of being due to better
global/local features and representations.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Another popular method is based on pattern frequency
histograms, widely known as bag of words. The BoW
approach incorporates word frequencies but ignores their
locations. In time series applications, several recent papers
adopted BoW ideas. Lin et al. [25] first symbolize time series
by SAX, then slide a fixed-sized window to extract a contiguous
set of SAX words, and at last use the frequency distribution
of SAX words as a representation for the time series.
Baydogan et al. [9] propose a similar bag-of-features framework.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;They sample subsequences with varying lengths randomly,
use mean, variance, slope and temporal location t to
represent each subsequence, afterwards utilize random forest
classification to estimate class probabilities of each subsequence,
and finally represent the raw time series by
summarizing the subsequence class-probability distribution
information. They showed superior or comparable results
to competing methods like NNDTW on UCR datasets [4].
Wang et al. [10] adopted a typical bag of words framework
to classify biomedical time series data, and they sample subsequences
uniformly and represent them by DWT. Grabocka
and Schmidt-Thieme [32] introduce a similar BoW
pipeline to classify time series: they sample subsequences
from time series instances uniformly, learn latent patterns
and membership assignments of each subsequence to those
patterns, and sum up membership assignments of subsequences
on a time series as the representation of that time
series. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Time series representations are then classified by
polynomial kernel SVM. Our work belongs to this category,
but emphasizes detecting better local feature points and
developing better local subsequence representations.
There are two recent papers using local descriptors as
well [33], [34]. In [33], the authors attempt to improve efficiency
of traditional DTW computation, to be concrete, they
extract local feature points, match them by their descriptors
and compute the local band constraints (based on matched pairs) applicable during the execution of the DTW algorithm.
In this way, they only have to compute the accumulative
distances within the band, and the DTW computation
efficiency is improved. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Our work is different from [33] in
that: our use local descriptors to improve classification accuracies,
while [33] use local descriptors to improve DTW
computation efficiency. In [34], the authors extract local features
from multi-variate time series by leveraging metadata,
and their method for local feature extraction is only
applicable for multi-variate time series data with known
correlations and dependencies among different dimensions.
UCR datasets are univariate time series datasets, and their
method cannot be used here.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;background&lt;/h2&gt;

&lt;h3 id=&quot;nn-based-time-series-classification&quot;&gt;NN-Based Time Series Classification&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;As mentioned in Sect. 1, most studies have been directed at finding techniques
that can compensate for small misalignments between time series. Two main
elastic distance measures, DTW and edit distance, have been widely studied.&lt;/p&gt;

&lt;h3 id=&quot;dtw-based-elastic-distance-measures&quot;&gt;DTW-Based Elastic Distance Measures.&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;DTW is considered as the standard benchmark elastic distance measure to find an optimal alignment between
two given sequences [16]. The standard DTW utilizes a pointwise distance matrix
to record the cumulative distance from the start point pair to current point pair
and employs the dynamic programming method to complete the process. Two
aspects of DTW have been studied in recent years. One is speedup technique
because the standard DTW has a quadratic time and space complexity. Some
works have reduced it to nearly linear time complexity [25]. Another improvement
is to change the calculation way of cumulative distance. A weighted form
of DTW (WDTW) [14] is proposed to reduce warping by adding a multiplicative
weight item to penalize points with higher phase difference between a test point
and a reference point. In standard DTW, there is a scenario where a single point
on one time series may map onto a large number of points on the other time
series, which lead to pathological results. To avoid these singularities, a modification
of DTW, called DDTW, is proposed by transforming the time series
into a series of first-order difference [17]. On the basis of this idea, Gorecki et al.
[11] use a weighted combination of DTW on raw time series and DDTW on first
order differences for NN classification. An extension of DDTW that uses DTW in
conjunction with transforms and derivatives is proposed by Gorecki and Luczak
[12]. They propose a new distance function by combining three distances: DTW
distance between time series, DTW distance between derivatives of time series,
and DTW distance between transforms of time series.
&lt;/p&gt;

&lt;h3 id=&quot;edit-distance-based-elastic-distance-measures&quot;&gt;Edit Distance-Based Elastic Distance Measures.&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;The initial edit distancetechnique is longest common subsequence (LCSS) distance which is extended
to handle the real-valued time series from discrete series by using a distance
threshold. A point pair from two time series can be considered as a match if
their distance is less than the predefined threshold. Like LCSS, edit distance on
real sequences (EDR) [5] also use a distance threshold to define a series match,
but the difference is EDR employs a constant penalty to deal with the scenario of
non-matching point pair. The drawback of EDR is it does not satisfy triangular
inequality. Chen et al. [6] revise the weakness of EDR by utilizing the distance
between point pairs when there is no gap and a constant when gaps occur. TWE
[22] and MSM [27] are two effective edit distance-based approaches proposed
in recent years. TWE makes full use of the characteristics of LCSS and DTW,
which allows warping in the time axis and combines the edit distance with Lpnorms.
In MSM the similarity of two different time series is calculated by using
a series of operations to transform a given time series into the target time series.&lt;/p&gt;

&lt;h3 id=&quot;other-elastic-distance-measures&quot;&gt;Other Elastic Distance Measures.&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;Batista et al. consider the complexityinvariance problem for time series similarity measures and propose a parameterfree
method, complexity invariant distance (CID) [13], to solve this problem.
They describe a method for weighting a distance measure to compensate for the
differences in the complexity when two time series are compared. The sum of
squares of the first differences is used to measure the complexity. Except using
individual elastic distance measure to calculate the similarity of two time series,
Lines and Bagnall [20] combine 11 elastic distance measures through simple
ensemble schemes and get significantly better classification accuracy.&lt;/p&gt;
&lt;h3 id=&quot;basic-nearest-subspace-algorithm&quot;&gt;Basic Nearest Subspace Algorithm&lt;/h3&gt;

&lt;p&gt;The NN classifier may be the simplest supervised method to predict the label of a test instance. Essentially, it seeks the best representation of a test instance in term of one training sample. Unlike NN algorithm, the nearest subspace (NS) classifier (e.g. $[18,21])$ takes all training samples of each class into consideration and tries to find the best representation by fitting the test instance. Formally, we assign a test instance $y$ to class $i$ if the distance from $y$ to the subspace spanned by all samples $\boldsymbol{X}&lt;em&gt;i=\left[\boldsymbol{x}&lt;/em&gt;{i, 1}, \ldots, \boldsymbol{x}_{i, n_4}\right]$ of class $i$ is the smallest one among all classes, i.e.,
\(r_i(\boldsymbol{y})=\min _{\boldsymbol{\alpha}_i \in \mathbb{R}^{n_1, i \in\{1, \ldots, K\}}}\left\|\boldsymbol{y}-\boldsymbol{X}_i \boldsymbol{\alpha}_i\right\|_2\)
where $\boldsymbol{\alpha}_i$ is a fitting coefficient vector.
One may notice that the Eq. (1) is easily overfitting which makes the problem ill-posed when we attempt to get the best solution. In general, we can introduce an additional regularization item to prevent overfitting. An alternative is to restrict the variation of $\boldsymbol{\alpha}$ by adding an $L_2$-regularization term:
\(\widetilde{\boldsymbol{\alpha}}_i=\underset{\alpha_i \in \mathbb{R}^{n_i}}{\arg \min }\left\|\boldsymbol{y}-\boldsymbol{X}_i \boldsymbol{\alpha}_i\right\|_2^2+\lambda\left\|\boldsymbol{\alpha}_i\right\|_2^2\)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Classifying Time Series Using Local Descriptors with Hybrid Sampling</title>
   <link href="http://localhost:4000/2023/02/03/classifying-time-series-using-local-descriptors-with-hybrid-sampling"/>
   <updated>2023-02-03T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/03/Classifying-Time-Series-Using-Local-Descriptors-with-Hybrid-Sampling</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Time series classification (TSC) arises in many fields and has a wide range of applications. Here, we adopt the bag-ofwords
(BoW) framework to classify time series. Our algorithm first samples local subsequences from time series at feature-point
locations when available. It then builds local descriptors, and models their distribution by Gaussian mixture models (GMM), and at last it
computes a Fisher Vector (FV) to encode each time series. The encoded FV representations of time series are readily used by existing
classifiers, e.g., SVM, for training and prediction. In our work, we focus on detecting better feature points and crafting better local
representations, while using existing techniques to learn codebook and encode time series. Specifically, we develop an efficient and
effective peak and valley detection algorithm from real-case time series data. Subsequences are sampled from these peaks and
valleys, instead of sampled randomly or uniformly as was done previously. Then, two local descriptors, Histogram of Oriented Gradients
(HOG-1D) and Dynamic time warping-Multidimensional scaling (DTW-MDS), are designed to represent sampled subsequences. Both
descriptors complement each other, and their fused representation is shown to be more descriptive than individual ones. We test our
approach extensively on 43 UCR time series datasets, and obtain significantly improved classification accuracies over existing
approaches, including NNDTW and shapelet transform.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;A typical BoW framework consists of three major steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;local feature points detection and description,&lt;/li&gt;
  &lt;li&gt;codebook generation and&lt;/li&gt;
  &lt;li&gt;signal encoding.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Afterwards, any classifier can be trained on signal encodings to do the final classification.&lt;/p&gt;

&lt;p&gt;The performance of a BoW framework implementation depends on all steps. In the computer vision community, many efforts have been made to improve each step.&lt;/p&gt;

&lt;p&gt;Regarding local feature detection and description, successful feature extractors (e.g., SIFT, Space Time Interest Points (STIPs)) have been developed to detect local feature points, and manually-crafted descriptors (e.g., Histogram of Gradients, Motion Boundary Histogram (MBH))
have been invented to represent local 2D image patches and 3D visual cuboid patterns around feature points.&lt;/p&gt;

&lt;p&gt;However, as reviewed below, fewer developments have been made with 1D time series descriptors. The next step, codebook generation, attempts to model the local descriptor space and to provide a partition in that space. Two typical ways are K-means and Gaussian Mixture Models (GMM). For the
last step, encoding, there is a large family of research studies; several representative encoding methods are vector quantization (hard voting) , sparse coding and Fisher Vector encoding .&lt;/p&gt;

&lt;p&gt;In this work, we adopt the BoW pipeline: we focus on improving the first step: designing better
local feature extractors and descriptors, while using existing techniques for the second and third steps; specifically, GMM is used to produce the codebook and Fisher Vector is employed to encode the time series.&lt;/p&gt;

&lt;p&gt;While local feature extractors are well studied in the computer vision community, in the time series community, no widely used extractors exist yet, such that most methods sample feature points either uniformly or randomly. In this paper, we introduce an efficient and effective feature point
extractor, which detects all peaks and valleys, termed as landmarks, from time series. Afterwards, subsequences centered on landmarks are sampled. Landmark-based sampling gives deterministic and phase-invariant subsequences, while uniformor random sampling are affected by the phase of the time series.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Due to the observation that dense sampling outperforms sparse interest-points sampling in image classification and activity recognition, in experiments, we
adopt a hybrid sampling strategy: first sample subsequences
from landmarks, then sample uniformly in flat featureless
regions of the signal. In this way, information from both feature-
rich and feature-less intervals is incorporated in the
sampled subsequences. We show experimentally that this
new hybrid sampling strategy outperforms both uniform
and random sampling significantly.&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;To the best of our knowledge, little recent literature on
time series classification is focused on developing better
local descriptors for local time series subsequences. Commonly
used local features are often simple, including mean,
variance and slope. However, statistical features
like mean and variance cannot characterize local segment
shapes well. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Although slope incorporates shape information,
it will underfit the shape of local subsequences if the
interval (here, a subsequence is divided into equal-length
non-overlapping temporal intervals and represented as a
sequence of slopes of intervals) is too long, and becomes sensitive
to noise if the interval is too short. Symbolic Aggregate
approXimation (SAX) is shown be a good representation
for time series, however, its usage in a BoW framework
creates a large codebook, resulting in high-dimensional
encoding vectors for time series, which inevitably enburdens
downstream classifier training and prediction. &lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;
Other widely
used and somewhat older time series representations
include Discrete Fourier Transform (DFT) coefficients, Discrete
Wavelet Transform (DWT), piecewise linear approximation
(PLA), etc. It is important to clarify that SAX, DFT,
DWT and PLA have been used in general to represent the
whole time series, instead of local subsequences.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In our work, we propose two new local descriptors,
namely Histogram of Oriented Gradients (HOG) of 1D time
series (HOG-1D) and Dynamic time warping-multidimensional
scaling (DTW-MDS), which are shown experimentally
to be quite descriptive of local subsequence shapes.
These two descriptors have individual advantages: HOG-
1D consists of statistical histograms, therefore is robust to
noise. Moreover, HOG-1D is invariant to y-axis magnitude
shift. While DTW-MDS is sensitive to noise and magnitude
shift, it is more invariant to stretching, contraction and
temporal shifting. Two descriptors thus complement
each other. By fusing them into a single descriptor, the
fused one, HOG-1D+DTW-MDS, combines the benefits of
both descriptors, becomes more descriptive of subsequences,
and thus is more discriminative for classification tasks.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Experimental results show that our fused descriptor outperforms
existing descriptors, such as DFT, DWT and Zhangs significantly on 43 UCR datasets for time series
classification. Here DFT, DWT and Zhangs are used to represent
local subsequences, instead of the whole time series.
All local descriptors, including our fused one, work under
the same classification pipeline: (1) feature points extraction,
(2) local subsequence representation, (3) time series encoding
by Fisher Vector, (4) linear kernel SVM classification. In
addition, we compare TSC performance of our fused
descriptor with two state-of-the-art algorithms, NNDTW
and shapelet transform, on 41 UCR datasets, and ours
achieves the best performance on 22 of them (including
ties).&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Wilcoxon signed rank test on relative accuracy boost shows our fused descriptor
improves relative classification accuracies significantly compared
to NNDTW (p &amp;lt; 0.0017) and shapelet transform
(p &amp;lt; 0.0452). Our algorithm performs well on UCR datasets,
which have fixed length time series instances, however,
our algorithm is also applicable to datasets with variable
length time series instances, since Fisher Vector is essentially
a normalized encoder, making encodings largely
invariant to time series length.
&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Our contributions are several fold: (1) we introduce a
simple but effective feature point extractor, which detects a
set of landmarks from time series; (2) we explicitly design
two local subsequence descriptors, namely HOG-1D and
DTW-MDS, which are descriptive of local shapes and complement
each other; (3) we obtain significantly improved
classification accuracies using our fused descriptor when
compared with two competing state-of-the-art TSC algorithms,
NNDTW and shapelet transform, and three existing
descriptors, DFT, DWT and Zhangs, on 43 UCR datasets.&lt;/p&gt;

&lt;p&gt;2 PREVIOUS WORK
Time series classification methods can be categorized into
instance-based, shapelets, feature-based and pattern frequency
histogram methods.
Instance-based methods predict labels of test time series
based on their similarity to the training instances. The most
popular similarity metrics include euclidean distance and
elastic distances, e.g., the dynamic time warping (DTW)
distance. Using a single nearest neighbor, with euclidean
distance (NNEuclidean) or DTW distance (NNDTW), has
demonstrated successful time series label prediction. DTW
allows time series to be locally shifted, contracted and
stretched, and lengths of time series hence need not be the
same. Therefore, DTW usually gives a better similarity
measurement than Euclidean distance, and NNDTW has
been shown to be very hard to beat on many datasets [11].
A number of more complex elastic distance measures have
been proposed, including longest common subsequences
(LCSS) [27], Edit distance with Real Penalty (ERP) [28]
and edit distance on Real Sequence (EDR) [29]. However,
in [30], the authors claimed that no other elastic distance
measure outperforms DTW by a statistically significant
amount, and DTW is the best measure. Instance-based
approaches, like NN-euclidean and NNDTW, are accurate,
but they are less interpretable, since they are based on
global matching and provide limited insights into the temporal
characteristics.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Iterative Kalman Filter</title>
   <link href="http://localhost:4000/2023/02/02/ikf"/>
   <updated>2023-02-02T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/02/IKF</id>
   <content type="html">&lt;h1 id=&quot;iterative-kalman-filter&quot;&gt;Iterative Kalman Filter&lt;/h1&gt;

&lt;p&gt;The Kalman Filter is a widely-used algorithm for estimating the state of a system based on noisy measurements. It provides an optimal solution for linear systems with Gaussian noise. However, for non-linear systems, the Extended Kalman Filter (EKF) is used. In some cases, the EKF may not perform well due to its assumption of the Gaussian distribution of noise.&lt;/p&gt;

&lt;p&gt;The Iterative Kalman Filter (IKF) is an improvement over the EKF, which iteratively linearizes the non-linear system around the current estimate of the state. The IKF uses a Taylor series expansion to linearize the non-linear system and estimates the state using the linearized system. The process is then repeated until convergence.&lt;/p&gt;

&lt;p&gt;The algorithm for the Iterative Kalman Filter is as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Initialize the state estimate $\hat{x}_{0&lt;/td&gt;
          &lt;td&gt;0}$ and the covariance matrix $P_{0&lt;/td&gt;
          &lt;td&gt;0}$.&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Repeat for each time step $k$:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Linearize the non-linear system around the current state estimate:&lt;/p&gt;

        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;$\begin{aligned} F_k &amp;amp;= \frac{\partial f}{\partial x}\bigg&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;{\hat{x}&lt;/em&gt;{k&lt;/td&gt;
              &lt;td&gt;k-1}} \ H_k &amp;amp;= \frac{\partial h}{\partial x}\bigg&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;{\hat{x}&lt;/em&gt;{k&lt;/td&gt;
              &lt;td&gt;k-1}} \ \end{aligned}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Predict the state estimate and the covariance matrix:&lt;/p&gt;

        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;$\begin{aligned} \hat{x}_{k&lt;/td&gt;
              &lt;td&gt;k-1} &amp;amp;= f(\hat{x}_{k-1&lt;/td&gt;
              &lt;td&gt;k-1}) \ P_{k&lt;/td&gt;
              &lt;td&gt;k-1} &amp;amp;= F_k P_{k-1&lt;/td&gt;
              &lt;td&gt;k-1} F_k^T + Q_k \ \end{aligned}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Compute the Kalman gain:&lt;/p&gt;

        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;$K_k = P_{k&lt;/td&gt;
              &lt;td&gt;k-1} H_k^T (H_k P_{k&lt;/td&gt;
              &lt;td&gt;k-1} H_k^T + R_k)^{-1}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Update the state estimate and the covariance matrix:&lt;/p&gt;

        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;$\begin{aligned} \hat{x}_{k&lt;/td&gt;
              &lt;td&gt;k} &amp;amp;= \hat{x}_{k&lt;/td&gt;
              &lt;td&gt;k-1} + K_k (y_k - h(\hat{x}_{k&lt;/td&gt;
              &lt;td&gt;k-1})) \ P_{k&lt;/td&gt;
              &lt;td&gt;k} &amp;amp;= (I - K_k H_k) P_{k&lt;/td&gt;
              &lt;td&gt;k-1} \ \end{aligned}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The IKF iteratively performs steps 2-4 until the state estimate converges. The algorithm converges if the difference between two consecutive state estimates is below a certain threshold.&lt;/p&gt;

&lt;p&gt;The IKF is more computationally expensive than the EKF, but it provides better performance for non-linear systems with non-Gaussian noise.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Metrics</title>
   <link href="http://localhost:4000/2023/02/01/metrics"/>
   <updated>2023-02-01T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/02/01/metrics</id>
   <content type="html">&lt;h2 id=&quot;spectral-flatness&quot;&gt;Spectral flatness&lt;/h2&gt;

&lt;p&gt;This feature is called the spectral flatness (F), which is defined as&lt;/p&gt;

\[F_n=10 \log _{10}\left(\frac{m_a}{m_g}\right),\]

&lt;p&gt;where $m_{a}$ and $m_{g}$ respectively, denote the arithmetic and geometric means of the noisy speech spectrum. The spectral flatness is a measure of the noisiness of spectrum and is a good feature in voiced / uncoiced detection [8]. A low spectral flatness indicates that the spectral power is concentrated in a relatively small number of bands, which behaves more like voice frames. However, a high spectral flatness shows that the spectrum power is more uniform in different frequency bands, and appears relatively flat and smooth, which appears more likely as noise.&lt;/p&gt;

&lt;p&gt;The following global measures are utilized to indicate the corresponding characteristics of estimated trend $\hat{T}_{t}$&lt;/p&gt;

\[y(x) = T(x)+\epsilon (x)\]

\[\text{    Smoothness  :} \sqrt{ \frac{1}{N} \sum_{t=1}^{N} ( \Delta^{2}\hat{T}_{t} )^2}\]

\[\text{    Fidelity  :} \sqrt{ \frac{1}{N} \sum_{t=1}^{N} (y_{t} - \hat{T}_{t})^2}\]

\[\text{    Bias  :   } \mathbb{E}(\vert T_{t}-\hat{T}_{t}\vert)\]

</content>
 </entry>
 
 <entry>
   <title>Adaptive Wavelet Packet thresholding with iterative kalman filter</title>
   <link href="http://localhost:4000/2023/01/31/adaptive-wavelet-packet-thresholding-with-iterative-kalman-filter-for-speech-enhancement"/>
   <updated>2023-01-31T00:00:00+00:00</updated>
   <id>http://localhost:4000/2023/01/31/ADAPTIVE-WAVELET-PACKET THRESHOLDING-WITH-ITERATIVE-KALMAN FILTER-FOR-SPEECH-ENHANCEMENT</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In this paper, we propose an adaptive wavelet packet (WP)
thresholding method with iterative Kalman filter (IKF) for
speech enhancement. The WP transform is first applied to
the noise corrupted speech on a frame-by-frame basis, which
decomposes each frame into a number of subbands. For each
subband, a voice activity detector (VAD) is designed to detect
the voiced/unvoiced parts of the speech. Based on the
VAD result, an adaptive thresholding scheme is then utilized
to each subband speech to obtain the pre-enhanced speech.
To achieve a further level of enhancement, an IKF is next
applied to the pre-enhanced speech. The proposed method
is evaluated under various noise conditions. Experimental results
are provided to demonstrate the effectiveness of the proposed
method as compared to some previous works in terms
of segmental SNR and perceptual evaluation of speech quality
(PESQ) as two well-known performance indexes&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Wavelet Packet (WP), as a well-known powerful method,
is used in several signal processing applications including
speech enhancement. Based on an adaptive thresholding in
wavelet packets, a speech enhancement approach is proposed
in [3], where a subband thresholding is applied to detect the
voice/noise frames. The criterion used in [3] to determine
voiced and noise frames is to compare the frame energy with
a constant threshold. Namely, a voiced frame is detected if
the frame energy exceeds the constant threshold. Otherwise,the frame is decided as noise. In practice, however, such an
energy-based decision making would fail to identify all voice
or noise frames. To increase the detection accuracy, other
frame characteristics need to be considered.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The authors in [4] proposed an iterative Kalman filter
(IKF) approach for speech enhancement, where the linear
prediction coefficients (LPCs) and the noise variance are estimated
directly from the noisy speech, which decreases the
accuracy of IKF approach to a certain degree. In [5], another
IKF-based approach is proposed along with a subband processing,
where the noisy speech is decomposed into a number
of subbands followed by Kalman Filtering (KF) on each subband.
The method, however, demands a large amount of computational
resource for the implementation of KF at all the
subbands. More recently, a subband IKF method with partial
reconstruction is proposed in [6], where the noisy speech is
first decomposed into a set of subbands, and then a partial
reconstruction scheme is used to reconstruct the subbands
into high-frequency and low-frequency subband speeches. In
this context, the IKF is employed only in the high-frequency
subband. Since the low-frequency subband is not filtered by
the IKF, this method offers limited enhancement performance
for noisy speeches which contain non-negligible noises in lowfrequency
region.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In order to address the aforementioned limitations, in this
paper we propose an improved thresholding scheme with the
IKF for speech enhancement on a frame-by-frame basis. The
noisy speech is first decomposed into a number of subbands
with the WP. The VAD is then applied to each subband frame
to determine whether the frame is voice or noise. In contrast
to most existing works where only a single parameter is employed
for voice/noise frame detection, our method makes use
of two measurements in the VAD stage. i) frame energy and ii)
spectral flatness. A VAD based adaptive thresholding scheme
is then proposed for speech enhancement in accordance with
each subband frame activity. Finally, an IKF is used for further
noise reduction, which is followed by reconstruction of
the full-band speech from the enhanced subband speeches.&lt;/p&gt;
&lt;h2 id=&quot;iterative-kalman-filter&quot;&gt;Iterative Kalman Filter&lt;/h2&gt;

&lt;p&gt;Here, the pre-enhanced full-band speech signal $\hat{y}(k)$ is further processed by an IKF as modelled below
\(\begin{aligned}
&amp;amp; \hat{y}(k)=\boldsymbol{H} \boldsymbol{x}(k)+w(k), \\
&amp;amp; \boldsymbol{x}(k)=\boldsymbol{F} \boldsymbol{x}(k-1)+\boldsymbol{G} u(k),
\end{aligned}\)
with $\boldsymbol{H}=\boldsymbol{G}^T=[1, \ldots, 1] \in \mathbb{R}^{1 \times p}, \boldsymbol{x}(k)=[s(k-p+1), \ldots, s(k)]$. The term $\boldsymbol{F}$ denotes the $p \times p$ state transition matrix represented as LPCs estimation based on Modified Yule-Walker equations $[10]$
\(\boldsymbol{F}=\left[\begin{array}{ccccc}
-a_1 &amp;amp; -a_2 &amp;amp; \cdots &amp;amp; -a_{p-1} &amp;amp; -a_p \\
1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots \\
0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1 &amp;amp; 0
\end{array}\right]\)
The number of iterations is usually set to 2 or 3 . The operation principle of the IKF includes a prediction step and a measurement update step. In the prediction step, the IKF predicts the state vector and parameter covariance by using the previous samples of the state-space model. The estimate of clean speech $\hat{x}(k)$ and the posteriori estimation error covariance $P(k \mid k)$ are predicted from time step $(k-1)$ to step $k$ (the status are $\hat{x}(k \mid k-1) / P(k \mid k-1)$ ),
\(\begin{aligned}
\hat{\boldsymbol{x}}(k \mid k-1) &amp;amp; =\boldsymbol{F} \hat{\boldsymbol{x}}(k-1 \mid k-1), \\
P(k \mid k-1) &amp;amp; =\boldsymbol{F} P(k-1 \mid k-1) \boldsymbol{F}^T+G \sigma_u{ }^2 G^T .
\end{aligned}\)
In the measurement update step, the Kalman Gain and state vectors are updated by
\(\begin{aligned}
\boldsymbol{K}(k) &amp;amp; =P(k \mid k-1) \boldsymbol{H}^T\left(\boldsymbol{H} P_{(k \mid k-1)} \boldsymbol{H}^T+\sigma_w{ }^2\right)^{-1}, \\
\hat{\boldsymbol{x}}(k \mid k) &amp;amp; =\hat{\boldsymbol{x}}(k \mid k-1)+\boldsymbol{K}(k)(y(k)-\boldsymbol{H} \hat{\boldsymbol{x}}(k \mid k-1)), \\
P(k \mid k) &amp;amp; =(\boldsymbol{I}-\boldsymbol{K}(k) \boldsymbol{H}) P(k \mid k-1),
\end{aligned}\)
where $\boldsymbol{I}$ denotes the identity matrix.&lt;/p&gt;

&lt;h2 id=&quot;comparison&quot;&gt;Comparison&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Three existing methods namely, adaptive threshold (AT) [9],
iterative Kalman filter (IKF) [4] and subband iterative
Kalman filter (S-IKF) [6], are compared with the proposed
adaptive threshold iterative Kalman filter (AT-IKF) method.
Standard objective metrics, i.e., segmental SNR and PESQ,
are applied for performance evaluations. From Fig. 4, it is
observed that in non-stationary noise environment the proposed
method achieves the same performance as compared
with the IKF and S-IKF methods in terms of segmental
SNR. However, the experimental results shown in Fig. 5
demonstrate a performance improvement in terms of PESQ.
Moreover, as shown in Fig. 6 and Fig. 7, the proposed scheme
outperforms the other methods both in terms of segmental
SNR and PESQ.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Optimal Finite Impulse Response (OFIR) Filter</title>
   <link href="http://localhost:4000/2017/04/13/ofir-filter"/>
   <updated>2017-04-13T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/13/ofir-filter</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;The Kalman filter (KF) is the
most widely used real-time optimal estimator. However, the KF is a
Bayesian estimator and its recursive algorithm has the infinite impulse
response (IIR), owing to which the KF often suffers of insufficient robustness. Better robustness is inherent to finite memory filters and to filters with finite impulse response (FIR).&lt;/p&gt;

&lt;p&gt;Unlike the KF, the FIR filter utilizes measurements on an interval of
N most recent neighbouring points called horizon. Compared to the KF,
FIR filters demonstrate many useful properties such as the bound input/
bound output (BIBO) stability, higher robustness against temporary
model uncertainties and round-off errors , and
lower sensitivity to noise.&lt;/p&gt;

&lt;h3 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;/h3&gt;

&lt;p&gt;Consider a general class of discrete-time linear systems represented in state-space with time-variant coefficients as&lt;/p&gt;

\[x_{k}=A_{k} x_{k-1}+B_{k} w_{k} \tag{1}\]

&lt;p&gt;\(y_{k}=C_{k} x_{k}+v_{k}\tag{2}\)
in which $k$ is the discrete time index, $x_{k} \in \mathbb{R}^{n}$ is the state vector, $y_{k} \in \mathbb{R}^{p}$ is the measurement vector, and $A_{k} \in \mathbb{R}^{n \times n}, B_{k} \in \mathbb{R}^{n \times u}$, and $C_{k} \in \mathbb{R}^{p \times n}$ are time-variant matrices. Here, $w_{k} \in \mathbb{R}^{u}$ and $v_{k} \in \mathbb{R}^{p}$ are additive process and measurement noise sources with known covariances&lt;/p&gt;

&lt;p&gt;$Q_k=\E ( w_k w_{k}^{T} ) $ and $R_{k}=\mathbb{E}( v_{k} v_{k}^{T})$, respectively. We suppose that $w_{k}$ and $v_{k}$ are zero mean, white, and mutually uncorrelated; that is, $\mathbb{E}( w_{k})=0$, $\mathbb{E}( v_{k})=0, \mathbb{E}(w_{k} w_{j}^{T})=0$ and $\mathbb{E}( v_{k} v_{j}^{T})=0$ for all $k$ and $j \neq k$, and $\mathbb{E}( w_{k} v_{j}^{T})=0$ for all $k$ and $j$.&lt;/p&gt;

&lt;p&gt;The FIR filter requires simultaneously $N$ data points taken from the horizon $[l=k-N+1, k]$. Therefore, (1) and (2) need to be extended on $[l, k]$. That can be done if to use the recursively computed forward in-time solutions and write&lt;/p&gt;

\[X_{k, l}=A_{k, l} x_{l}+B_{k, l} W_{k, l}\tag{3}\]

\[Y_{k, l}=C_{k, l} x_{l}+H_{k, l} W_{k, l}+V_{k, l} \tag{5}\]

&lt;p&gt;where the extended vectors are $X_{k, l}=\left[x_{k}^{T}, x_{k-1}^{T}, \ldots, x_{l}^{T}\right]^{T} \in \mathbb{R}^{N n \times 1}$, $Y_{k, l}=\left[y_{k}^{T}, y_{k-1}^{T}, \ldots, y_{l}^{T}\right]^{T} \in \mathbb{R}^{N p \times 1}, W_{k, l}=\left[w_{k}^{T}, w_{k-1}^{T}, \ldots, w_{l}^{T}\right]^{T} \in \mathbb{R}^{N u \times 1}$, and $V_{k, l}=\left[v_{k}^{T}, v_{k-1}^{T}, \ldots, v_{l}^{T}\right]^{T} \in \mathbb{R}^{N p \times 1}$. The extended $k$ - and $N$-variant matrices $A_{k, l} \in \mathbb{R}^{N n \times n}, B_{k, l} \in \mathbb{R}^{N n \times N u}, C_{k, l} \in \mathbb{R}^{N p \times n}$, and $H_{k, l} \in \mathbb{R}^{N p \times N u}$ can be represented as, respectively,&lt;/p&gt;

&lt;p&gt;\(A_{k, l}=\left[\mathscr{A}_{k, l+1}^{T}, \mathscr{A}_{k-1, l+1}^{T}, \ldots, \mathscr{A}_{l+1, l+1}^{T}, I\right]^{T}\)
\(B_{k, l}=\left[\begin{array}{ccccc}B_{k} &amp;amp; \mathscr{A}_{k, k} B_{k-1} &amp;amp; \cdots &amp;amp; \mathbf{A}_{k, l+2} B_{l+1} &amp;amp; \mathscr{A}_{k, l+1} B_{l} \\ 0 &amp;amp; B_{k-1} &amp;amp; \cdots &amp;amp; \mathscr{A}_{k-1, l+2} B_{l+1} &amp;amp; \mathscr{A}_{k-1, l+1} B_{l} \\ \vdots &amp;amp; \vdots &amp;amp; \cdots &amp;amp; \vdots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; B_{l+1} &amp;amp; \mathscr{A}_{l+1, l+1} B_{l} \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; B_{l}\end{array}\right]\)
,&lt;/p&gt;

\[C_{k, l}=\bar{C}_{k, l} A_{k, l}\]

\[H_{k, l}=\bar{C}_{k, l} B_{k, l}\]

&lt;p&gt;where&lt;/p&gt;

\[\bar{C}_{k, l}=\operatorname{diag}\left(C_{k} C_{k-1} \cdots C_{l}\right)\]

\[\mathbf{A}_{i, j}=\prod_{r=0}^{i-j} A_{i-r}=A_{i} A_{i-1} \ldots A_{j}\]

&lt;p&gt;At the initial horizon point, (3) becomes $x_{l}=x_{l}+B_{l} w_{l}$ that is uniquely satisfied if $w_{l}$ is zero-valued, provided that $B_{l}$ is not zeroth. That means that the initial state must be known in advance or estimated optimally.&lt;/p&gt;

&lt;p&gt;The FIR filtering estimate can be obtained at $k$ via (4) using the discrete convolution as&lt;/p&gt;

\[\hat{x}_{k \mid k}=K_{k} Y_{k, l} \tag{5}\]

&lt;p&gt;where $x_{t \vert r} $ means the estimate at $t$ via measurements from the past to and including at $r$ and $K_{k}$ is the FIR filter gain, which needs to be defined to obey some cost function. Note that the aforementioned inherent properties of FIR filtering are associated with the fact that measurements prior to $l$ are discarded in (5) and thus do not affect the estimate unlike in the KF which has IIR. It is also necessary to emphasize that when the system considered is time-invariant, the FIR estimate (5) will becomes $x_{k \mid k}=K_{N} Y_{k, l}$, which means that the filter gain $K_{N}$ is time-invariant and can be determined off-line once the horizon length $N$ is available. In this case, $K_{N}$ is not necessarily to be realized into iterative computation structure.&lt;/p&gt;

&lt;p&gt;The optimal gain $K_{k}$ can be obtained for (5) in the minimum MSE sense by minimizing the trace of the MSE as&lt;/p&gt;

\[\hat{K}_{k}=\underset{K_{k}}{\arg \min } E\left\{\operatorname{tr}\left(e_{k} e_{k}^{T}\right)\right\}\]

&lt;p&gt;where $e_{k}=x_{k}-x_{k \mid k}$ is the estimation error. Provided $x_{k \mid k}$ via (5), the one-step prediction required by feedback control and associated with receding horizon filtering can be formed as $x_{k+1 \mid k}=A_{k+1} x_{k \mid k}$, similarly to the KF.&lt;/p&gt;

&lt;h3 id=&quot;ofir-algorithm&quot;&gt;OFIR algorithm&lt;/h3&gt;

&lt;p&gt;Given the model (1) and (2) with white and mutually uncorrelated noise processes $w_{k}$ and $v_{k}$ which have covariances $Q_{k}$ and $R_{k}$, respectively. The iterative form for OFIR estimate (10) with gain (16) is the following,&lt;/p&gt;

\[\begin{aligned}
\Xi_{i}= &amp;amp; A_{i} \Xi_{i-1} A_{i}^{T}+B_{i} Q_{i} B_{i}^{T}-A_{i} \Xi_{i-1} C_{i-1}^{T} \\
&amp;amp; \times\left(R_{i-1}+C_{i-1} \Xi_{i-1} C_{i-1}^{T}\right)^{-1} C_{i-1} \Xi_{i-1} A_{i}^{T} \\
G_{i}= &amp;amp; \Xi_{i} C_{i}^{T}\left(R_{i}+C_{i} \Xi_{i} C_{i}^{T}\right)^{-1}
\end{aligned} \tag{6}\]

\[\hat{x}_{i \mid i}=A_{i} \hat{x}_{i-1 \mid i-1}+G_{i}\left(y_{i}-C_{i} A_{i} \hat{x}_{i-1 \mid i-1}\right)\tag{7}\]

&lt;p&gt;where $i$ ranges from $l+1$ to $k$ and the output is taken when $i=k$. The initial state $x_{l \vert l}$ is given and the initial prior error $\Xi_{i}$ is provided at l by&lt;/p&gt;

&lt;p&gt;$\Xi_{l}=\Theta_{x, l}+B_{l} Q_{l} B_{l}^{T}$&lt;/p&gt;

&lt;p&gt;where $\Theta_{x, l}$ is given.&lt;/p&gt;

&lt;p&gt;As can be seen (7), is the Kalman-like recursion in which $A_{i} x_{i-1 \mid i-1}$ predicts the state from $i-1$ to $i$ and the bias correction gain (6) corrects the prediction for the residual. Although the KF and OFIR filter both minimize the MSE, $G_{i}$ is not the Kalman gain, because the KF has IIR. However, an increase in the horizon length $N$ reduces the estimation error and makes it such that the OFIR estimate converges to the KF estimate: the estimates become practically equal when $N&amp;gt;N_{\mathrm{opt}}$ . In this sense, the KF can be considered as a special case of a more general OFIR filter when $N=\infty$, provided the initial conditions. Another difference is that $N$ measurements are processed by the OFIR filter simultaneously at each time index $k$, while only one measurement is processed by the KF at $k$. That means that the computational complexity of OFIR filter $\mathcal{O}(N)$ is $N$ times larger than $\mathcal{O}(1)$ of the KF. On the other hand, the iterative algorithm reduces essentially the computational complexity $\mathcal{O}\left(N^{2}\right)$ of the batch OFIR form.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hilbert Huang Transform</title>
   <link href="http://localhost:4000/2017/04/12/hht"/>
   <updated>2017-04-12T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/12/HHT</id>
   <content type="html">&lt;p&gt;The EMD method is necessary to reduce any data from non-stationary and nonlinear processes into simple oscillatory function that will yield meaningful instantaneous frequency through the Hilbert transform. Contrary to almost all the previous decomposing methods, EMD is empirical, intuitive, direct, and adaptive, with the a posteriori defined basis derived from the data. The decomposition is designed to seek the different simple intrinsic modes of oscillations in any data based on the principle of scale separation. The data, depending on it complexity, may have many different coexisting modes of oscillation at the same time. Each of these oscillatory modes is represented by an Intrinsic Mode Function (IMF) with the following definitions:&lt;/p&gt;

&lt;p&gt;(a) in the whole data set, the number of extrema and the number of zero-crossings must either equal or differ at most by one, and&lt;/p&gt;

&lt;p&gt;(b) at any point, the mean value of the envelope defined by the local maxima and the envelope defined by the local minima is zero.&lt;/p&gt;

&lt;p&gt;The IMF is a counter part to the simple harmonic function, but it is much more general: instead of constant amplitude and frequency, IMF can have both variable amplitude and frequency as functions of time. This definition is inspired by the simple example of constant plus sinusoidal function given above. The total number of the IMF components is limited to $\ln _{2} N$, where $\boldsymbol{N}$ is the total number of data points. It satisfies all the requirements for a meaningful instantaneous frequency through Hilbert transform.&lt;/p&gt;

&lt;p&gt;Pursuant to the above definition for IMF, one can implement the needed decomposition of any function, known as sifting, as follows: Take the test data; identify all the local extrema; divide the extrema into two sets: the maxima and the minima. Then connect all the local maxima by a cubic spline line to form an upper envelope. Repeat the procedure for the local minima to form a lower envelope. The upper and lower envelopes should encompass all the data between them. Their mean is designated as $m_1$, and the difference between the data and $m_1$ is designated as, $h_1$, a proto-IMF:&lt;/p&gt;

\[X(t)-m_{1}=h_{1}\]

&lt;p&gt;Ideally, $h_1$ should satisfy the definition of an IMF by construction of $h_1$ described above, which should have made it symmetric and having all maxima positive and all minima negative. Yet, in changing the local zero from a rectangular to a curvilinear coordinate system some inflection points could become additional extrema. New extrema generated this way actually reveal the hidden modes missed in the initial treatment. The sifting process sometimes can recover signals representing low amplitude riding waves with repeated siftings.&lt;/p&gt;

&lt;p&gt;The sifting process serves two purposes: to eliminate riding waves and to make the wave profiles more symmetric. While the first condition is absolute necessary for Hilbert transform to give a meaningful instantaneous frequency, the second condition is also necessary in case the neighboring wave amplitudes having too large a disparity. As a result, the sifting process has to be repeated many times to reduce the extracted signal an IMF. In the subsequent sifting process, $h_1$ is treated as the data for the next round of sifting; therefore,&lt;/p&gt;

\[h_{1}-m_{11}=h_{11}\]

&lt;p&gt;After repeated sifting, up to $\mathrm{k}$ times, $h_{1k}$ :&lt;/p&gt;

\[h_{1(k-1)}-m_{1 k}=h_{1 k} \text {. }\]

&lt;p&gt;If $\boldsymbol{h}_{\boldsymbol{1} \boldsymbol{k}}$ becomes an IMF, it is designated as 
$C_1$ :&lt;/p&gt;

\[C_{1}=h_{1 k}\]

&lt;p&gt;the first IMF component from the data. Here one has a critical decision to make: when to stop. Too many rounds of sifting will reduce the IMF to FM page criterion; too few rounds of sifting will not have a valid IMF. In the past, different criteria have been used, including Cauchy type criterion (Huang et al. 19980), $\boldsymbol{S}$-number criterion (Huang et al. 2003), fixed-number criterion (Wu and Huang 2004), and etc.&lt;/p&gt;

&lt;p&gt;With any stoppage criterion, the, $c_1$ should contain the finest scale or the shortest period component of the signal. one can, then, remove $c_1$ from the rest of the data by&lt;/p&gt;

\[X(t)-C_{1}=r_{1}\]

&lt;p&gt;Since the residue, $r_1$, contains all longer period variations in the data, it is treated as the new data and subjected to the same sifting process as described above. This procedure can be repeated to all the subsequent $r_j$ s, and the result is&lt;/p&gt;

\[\begin{gathered}
r_{1}-C_{2}=r_{2}, \\
\cdots \\
r_{n-1}-C_{n}=r_{n}
\end{gathered}\]

&lt;p&gt;The sifting process should stop when the residue, $\boldsymbol{r}_{n}$, becomes a constant, a monotonic function, or a function contains only a single extrema, from which no more IMF can be extracted. By summing up Equations (16) and (17), we finally obtain&lt;/p&gt;

\[X(t)=\sum_{j=1}^{n} C_{j}+r_{n}\]

&lt;p&gt;Thus, sifting process produces a decomposition of the data into $\boldsymbol{n}$-intrinsic modes, and a residue, $\boldsymbol{r}_{\boldsymbol{n}}$. When apply the EMD method, a mean or zero reference is not required; EMD needs only the locations of the local extrema. The sifting process generates the zero reference for each component. Without the need of the zero reference, EMD avoids the troublesome step of removing the mean values for the large non-zero mean.&lt;/p&gt;

&lt;p&gt;Two special notes here deserve our attention. First, the sifting process offered a way to circumvent the difficulty of define the local mean in a nonstationary time series, where no length scale exists for one to implement the traditional mean operation. The envelope mean employed here does not involve time scale; however, it is local. Second, the sifting process is a Reynolds-type decomposition: separating variations from the mean, except that the mean is a local instantaneous mean, so that the different modes are almost orthogonal to each other, except for the nonlinearity in the data.&lt;/p&gt;

&lt;p&gt;Recent studies by Flandrin et al. (2004) and Wu and Huang (2004) established that the EMD is equivalent to a dyadic filter bank, and it is also equivalent to an adaptive wavelet. Being adaptive, we have avoided the shortcomings of using any a priori-defined wavelet basis, and also avoided the spurious harmonics that would have resulted. The components of the EMD are usually physically meaningful, for the characteristic scales are defined by the physical data.&lt;/p&gt;

&lt;p&gt;Having established the decomposition, we can also identify a new use of the IMF components as filtering. Traditionally, filtering is carried out in frequency space only. But there is a great difficult in applying the frequency filtering when the data is either nonlinear or non-stationary or both, for both nonlinear and nonstationary data generate harmonics of all ranges. Therefore, any filtering will eliminate some of the harmonics, which will cause deformation of the data filtered. Using IMF, however, we can devise a time space filtering.&lt;/p&gt;

&lt;p&gt;For example, a low pass filtered results of a signal having $\boldsymbol{n}$-IMF components can be simply expressed as&lt;/p&gt;

\[X_{l k}(t)=\sum_{k}^{n} C_{j}+r_{n}\]

&lt;p&gt;a high pass results can be expressed as&lt;/p&gt;

\[X_{h k}(t)=\sum_{1}^{k} C_{j}\]

&lt;p&gt;and a band pass result can be expressed as&lt;/p&gt;

\[X_{b k}(t)=\sum_{b}^{k} C_{j}\]

&lt;p&gt;The advantage of this time space filtering is that the results preserve the full nonlinearity and nonstationarity in the physical space.&lt;/p&gt;

&lt;p&gt;Having obtained the Intrinsic Mode Function components, one can compute the instantaneous frequency for each IMF component as the derivative of the phase function. And one can also designate the instantaneous amplitude from the Hilbert transform to each IMF component. Finally, the original data can be expressed as the real part, RP, of the sum of the data in terms of time, frequency and energy as:&lt;/p&gt;

\[X(t)=R P \sum_{j=1}^{n} a_{j}(t) e^{i \int \omega_{j}(t) d t}\]

&lt;p&gt;Above equation gives both amplitude and frequency of each component as a function of time. The same data, if expanded in a Fourier representation, would have a constant amplitude and frequency for each component.&lt;/p&gt;

&lt;p&gt;The contrast between EMD and Fourier decomposition is clear: The IMF represents a generalized Fourier expansion with a time varying function for amplitude and frequency. This frequency-time distribution of the amplitude is designated as the Hilbert Amplitude Spectrum, $\boldsymbol{H}(\boldsymbol{\omega}, \boldsymbol{t})$, or simply the Hilbert spectrum.&lt;/p&gt;

&lt;p&gt;From the Hilbert spectrum, we can also define the marginal spectrum, $\boldsymbol{h}(\boldsymbol{\omega})$, as&lt;/p&gt;

\[h(\omega)=\int_{0}^{T} H(\omega, t) d t\]

&lt;p&gt;The marginal spectrum offers a measure of total amplitude (or energy) contribution from each frequency value. It represents the cumulated amplitude over the entire data span in a probabilistic sense.&lt;/p&gt;

&lt;p&gt;The combination of the Empirical Mode Decomposition and the Hilbert Spectral Analysis is designated by NASA as the Hilbert-Huang Transform (HHT) for short. Recent studies by various investigators indicate that HHT is a super tool for time-frequency analysis of nonlinear and nonstationary data (Huang and Attoh-Okine, 2005, Huang and Shen, 2005). It is based on an adaptive basis, and the frequency is defined through the Hilbert transform. Consequently, there is no need for the spurious harmonics to represent nonlinear waveform deformations as in any of the a priori basis methods, and there is no uncertainty principle limitation on time or frequency resolution from the convolution pairs based also on a priori bases. A summary of the comparison between Fourier, Wavelet and HHT analyses is given in Table 1.&lt;/p&gt;

&lt;p&gt;Table 1. Comparisons between Fourier, Wavelet and HilbertHuang Transform in Data analysis.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Transform&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Fourier&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Wavelet&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Hilbert&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Basis&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a priori&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a priori&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;adaptive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Frequency&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;convolution: global, uncertainty&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;convolution: regional, uncertainty&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;differentiation: local, certainty&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Presentation&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;energy-frequency&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;energy-time-frequency&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;energy-time-frequency&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Nonlinear&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Non-stationary&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Feature Extraction&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;discrete: no, continuous: yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Theoretical Base&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;theory complete&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;theory complete&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;empirical&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;After this basic development of the HHT method, there are some recent developments, which have either added insight to the results, enhanced the statistical significance of the results, and fixed some shortcomings in the HHT.&lt;/p&gt;

&lt;h2 id=&quot;recent-developments&quot;&gt;Recent developments&lt;/h2&gt;

&lt;h3 id=&quot;the-normalized-hilbert-transform-and-the-direct-quadrature&quot;&gt;The Normalized Hilbert Transform and the direct quadrature&lt;/h3&gt;

&lt;p&gt;It is well known that, although the Hilbert transform exists for any function of $\boldsymbol{L}^{p}$ class, the phase function of the transformed function will not always yield physically meaningful instantaneous frequencies. The limitations have been summarized succinctly in two theorems.&lt;/p&gt;

&lt;p&gt;First, in order to separate the contribution of the phase variation into the phase and amplitude parts, the function have to satisfy the limitation stipulated in the Bedrosian theorem (1963), which states that the Hilbert transform for the product of two functions, $\boldsymbol{f}(\boldsymbol{t})$ and $\boldsymbol{h}(\boldsymbol{t})$, can be written as&lt;/p&gt;

\[H[f(t) h(t)]=f(t) H[h(t)]\]

&lt;p&gt;only if the Fourier spectra for $\boldsymbol{f}(\boldsymbol{t})$ and $\boldsymbol{h}(\boldsymbol{t})$ are totally disjoint in frequency space, and the frequency content of the spectrum for $\boldsymbol{h}(\boldsymbol{t})$ is higher than that of $\boldsymbol{f}(\boldsymbol{t})$. This limitation is critical, for we need to have&lt;/p&gt;

&lt;p&gt;$H[a(t) \cos \theta(t)]=a(t) H[\cos \theta(t)]$, (28) otherwise, one cannot use Equation (6) to define the phase function, for the amplitude variation would mix with the phase function. Bedrosian theorem requires that the amplitude is varying be so slowly that the frequency spectra of the envelope and the carrier waves are disjoint. This is possible only for trivial cases, for unless the amplitude is constant, any local deviation can be considered as a sum of delta-functions, which has a wide white spectrum. Therefore, the spectrum for varying amplitude would never be totally separate from that of the carrier. This limitation has made the application of the Hilbert transform even to IMFs problematic. To satisfy this requirement, Huang and Long (2003) have proposed the normalization of the IMFs in the following steps: Starting from an IMF, they first find all the maxima of the IMFs, defining the envelope by spline through all the maxima, and designating the envelope as $\boldsymbol{E}(\boldsymbol{t})$. Now, normalize the IMF by dividing the IMF by $\boldsymbol{E}(\boldsymbol{t})$. Thus, they have the normalized function having amplitude always equal to unity, and have circumvented the limitation of Bedrosian theorem.&lt;/p&gt;

&lt;p&gt;Second, there is the new restriction given by the Nuttall theorem (1966), which stipulates that the Hilbert transform of cosine is not necessarily the sine with the same phase function for a cosine with an arbitrary phase function. Nuttall gave an energy based error bound, $\boldsymbol{\Delta E}$, defined as the difference between $y(t)$, the Hilbert transform of the data, and $\boldsymbol{Q}(\boldsymbol{t})$, the quadrature (with phase shift of exactly $90^{\circ}$ ) of the function as&lt;/p&gt;

\[\Delta E=\int_{t=0}^{T}|y(t)-Q(t)|^{2} d t=\int_{-\infty}^{0} S_{q}(\omega) d \omega,\]

&lt;p&gt;in which $\boldsymbol{S}_{\boldsymbol{q}}$ is Fourier spectrum of the quadrature function. Though the proof of this theorem is rigorous, the result is hardly useful, for it gives a constant error bound over the whole data range. With the normalized IMF, Huang and Long (2003) have proposed a variable error bound based on a simple argument, which goes as follows: compute the difference between squared amplitude of the normalized IMF and unity. If the Hilbert transform is exactly the quadrature, the difference between it and unity should be zero; otherwise, the Hilbert transform cannot be exactly the quadrature. Consequently, the error can be measured simply by the difference between the squared normalized IMF and unity, which is a function of time. Huang and Long (2003) and Huang et al. (2006) have conducted detailed comparisons and found the result quite satisfactory.&lt;/p&gt;

&lt;p&gt;Even with the error indicator, we can only know that the Hilbert transform is not exactly the quadrature; we still do not have the correct answer. This prompts a drastic alternative, eschewing the Hilbert transform totally. An exact direct quadrature has been found (Huang et al., 2006), and it would resolve the difficulties associated with the instantaneous frequency computation.&lt;/p&gt;

&lt;h3 id=&quot;the-confidence-limit&quot;&gt;The Confidence Limit&lt;/h3&gt;

&lt;p&gt;The confidence limit for the Fourier spectral analysis is based on the ergodic theory, where the temporal average is treated as the ensemble average. This approach is only valid if the processes are stationary. Huang et al. (2003) has proposed a different approach by utilizing the fact that there are infinite many ways to decompose one given function into difference components. Using EMD, one can still obtain many different sets of IMFs by changing the stoppage criteria. The confidence limit so derived does not depend on the ergodic theory From the confidence limit study, Huang et al. (2003) also found the optimal $\boldsymbol{S}$-number, when the differences reach a local minimum. Based on their experience from different data sets, they concluded that an $\boldsymbol{S}$-number in the range of 4 to 8 performed well. Logic also dictates that the $\boldsymbol{S}$-number should not be too high (which would drain all the physical meaning out of the IMF), nor too low (which would leave some riding waves remaining in the resulting IMFs).&lt;/p&gt;

&lt;h3 id=&quot;the-statistical-significance-of-imfs&quot;&gt;The Statistical Significance of IMFs&lt;/h3&gt;

&lt;p&gt;The EMD is a method to separate the data into different components by their scales. There is always the question: On what is the statistical significance of the IMFs based? In data containing noise, how can we separate the noise from information with confidence? This question was addressed by both Flandrin et al. (2004) and Wu and Huang (2004) through the study of signals consisting of noise only. Using white noise, Wu and Huang (2004) found the relationship between the mean period and RMS values of the IMFs. Furthermore, from the statistical properties of the scattering of the data, they found the bounds of the data distribution analytically. They concluded that when a data set is analyzed with EMD, if the mean period-RMS values exist outside the noise bounds, the components most likely contains signal, otherwise, a component could be resulted only from noise. Therefore, the components with their mean period-RMS values exceeding the noise bounds are statistically significant.&lt;/p&gt;

&lt;h3 id=&quot;ensemble-emd-eemd&quot;&gt;Ensemble EMD (EEMD)&lt;/h3&gt;

&lt;p&gt;One of the major problems existed in EMD is scale mixing: an IMF often contains local oscillations with dramatically different frequencies/scales (Huang et al 1999). Previous solution to that was introducing the intermittency check in which the frequency/scale range is subjectively determined. While such an approach works well in many cases, it also has side effect such as reducing adaptation of the EMD method.&lt;/p&gt;

&lt;p&gt;Recently, a new Ensemble Empirical Mode Decomposition (EEMD) method is presented. This new approach consists of an ensemble of decompositions of data with added white noise, and then treats the resultant mean as the final true result. Finite, not infinitesimal, amplitude white noise is necessary to force the ensemble to exhaust all possible solutions in the sifting process, thus requiring the different scale signals to collate in the proper intrinsic mode functions (IMF) dictated by the dyadic filter banks. The effect of the added white noise is to present a uniform reference frame in the timefrequency and time-scale space; and, therefore, the added noise provides a natural reference for the signals of comparable scale to collate in one IMF. With this ensemble mean, the scale can be clearly and naturally separated without any a priori subjective criterion selection, such as in the intermittence test for the original EMD algorithm. This new approach fully utilizes the statistical characteristics of white noise to perturb the data in its true solution neighborhood, and then cancel itself out (via ensemble averaging) after serving its purpose; therefore, it represents a substantial improvement over the original EMD and qualifies for a truly noise-assisted data analysis (NADA) method.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Sparse representation of signals</title>
   <link href="http://localhost:4000/2017/04/11/sparse-representation"/>
   <updated>2017-04-11T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/11/sparse-representation</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Sparse representation is widely employed for expressing signals using very few linear combinations of elementary signals. These elementary signals are called atoms. Since the
number of the atoms is more than the dimension of the signal
space, any signal can be represented by linear combinations
of these atoms and the representations are not unique.&lt;/p&gt;

&lt;p&gt;Sparse representation is to use the minimum number of atoms to express the signals and this is actually an $L_{0}$ norm optimization problem. That is for a given overcomplete dictionary $A\in\Re^{N \times M}$ and a signal $x\in R^{N \times 1}$, where $N&amp;lt;M$ and $R^{a \times b}$ denotes the space of $a \times b$ real valued matrices, the representation problem is to find $z\in\Re^{M \times 1}$ such that $x=Az$ and $\lVert z\lVert_{0}$ is minimized. That is 
\(z_{0}^{\ast} = \mathrm{argmin}_{z} \lVert z\lVert_{0} \text{  subject to  } x=Az \tag{1}\)&lt;/p&gt;

&lt;p&gt;Here $\lVert z\lVert_{0}$ denotes $L_{0}$ norm of $z$, which is equivalent to the number of nonzero elements in $z$.&lt;/p&gt;

&lt;p&gt;The problem defined in (1) is nonconvex, nonsmooth and NP hard, it requires an exhaustive search for finding the solution. An approximate solution can be obrtained by solving the corresponding $L_{1}$ norm optimization problem if the isometry condition is satisfied. The $L_{1}$ norm optimization is as follows&lt;/p&gt;

\[z_{1}^{\ast} = \mathrm{argmin}_{z} \lVert z\lVert_{1} \text{  subject to  } x=Az \tag{2}\]

&lt;p&gt;Although $z_{1}^{\ast}$ is a good approximation of $z_{0}^{\ast}$ when the isometry condition is satisifed, these two solutions will be very different if $x$ contains significant amount of noise. Nevertheless, this is the typical case in practical circumstances. Hence the exact equality constraint is usually related to an inequality constraint as follows.&lt;/p&gt;

\[z^{\ast} = \mathrm{argmin}_{z} \lVert z\lVert_{1} \text{  subject to  } \lVert Az-x\lVert_{\infty} \le \epsilon \tag{3}\]

&lt;p&gt;where $\epsilon$ is the specification on the maximium absolute difference between $Az$ and $x$. This problem can be efficiently solved via reformulating the $L_{1}$ norm optimization problem to a linear programming problem.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Single Spectrum Analysis</title>
   <link href="http://localhost:4000/2017/04/10/ssa"/>
   <updated>2017-04-10T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/10/SSA</id>
   <content type="html">&lt;p&gt;The main steps of SSA can be summarized as follows:&lt;/p&gt;

&lt;p&gt;For a time series $x(n)$ for $n=1,2\dots N$, let the window length be $L$ , where  $1&amp;lt;L&amp;lt;N$. The first step of SSA is to construct a trajectory matrix as follows. Define the $L$ dimensional vectors as&lt;/p&gt;

\[X_{n}=\begin{bmatrix} x(n)\\ \vdots \\ x(n+L-1)
\end{bmatrix}\]

&lt;p&gt;for $n =1,2,\dots, N  L +1$.&lt;/p&gt;

&lt;p&gt;Denote $K = N  L +1$. These $K$ vectors are put into a matrix and the $L \times K$ trajectory matrix is constructed as follows:&lt;/p&gt;

\[X = \begin{bmatrix}
X_{1} &amp;amp; X_{2} &amp;amp; \dots &amp;amp; X_{K}
\end{bmatrix}\]

&lt;p&gt;The second step is to express $X$ as the sum of component matrices. Let $S=XX^T$ and the eigenvalues of $S$ be $\lambda_{1}\ge\lambda_{2}\dots\ge\lambda_{L}\ge 0$. Define $D=\max{j:\lambda_{j}&amp;gt;0}$. Let $U_{1},\dots,U_{D}$ be the corresponding eigenvectors.&lt;/p&gt;

&lt;p&gt;Denote $V_{j}=\frac{X^TU_{j}}{\sqrt{ \lambda_{j} }}$ for $j=1,2,\dots,D$  be the factor vectors.&lt;/p&gt;

&lt;p&gt;Define:&lt;/p&gt;

\[\tilde{X}_{j} =\sqrt{\lambda_{j}}U_{j}V_{j}^T\]

&lt;p&gt;for $j=1,2,\dots,D$. It can be shown that $X$ can be represented as&lt;/p&gt;

\[X = \tilde{X}_{1}+\dots+\tilde{X}_{D}\]

&lt;p&gt;The third step is to represent $X$ as the sum of grouped matrix components as follows. The indices set ${1,\dots,D}$ is partitioned into $M$ disjoint subsets $I_{1}\dots I_{M}$. Let $I_{m} ={i_{m_{1}},\dots,{i_{m_{c}}}}$ for $m=1,\dots, M$ and&lt;/p&gt;

\[\tilde{X}_{I_{m}}=\tilde{X}_{i_{m_{1}}}+\dots+\tilde{X}_{i_{m_{C}}}\]

&lt;p&gt;Hence we have&lt;/p&gt;

\[X=\tilde{X}_{I_{1}}+\dots+\tilde{X}_{I_{M}}\]

&lt;p&gt;The final step is to reconstruct the signal by the diagonal averaging method.&lt;/p&gt;

&lt;p&gt;First, transform  new text $\tilde{X}_{I_m}$ into new one dimensional signals of length $N$ by the hankelization like procedure.&lt;/p&gt;

&lt;p&gt;The vectors and the transform operator are denoted as $\tilde{x}_{I_m}$  for $m=1,\dots,M$ and  $\Im(.)$ respectievely. That is&lt;/p&gt;

\[\tilde{x}_{I_{m}} = \Im(\tilde{X}_{I_{m}}) ; m=1,\dots,M\]

&lt;p&gt;Thus the original time series can be expressed as a sum of $M$ series,&lt;/p&gt;

\[x(n)=\tilde{x}_{I_{1}}(n)+\dots+\tilde{x}_{I_{M}}(n) ; n=1,\dots,N\]
</content>
 </entry>
 
 <entry>
   <title>Trend extraction with SSA and Sparse Binary Programming</title>
   <link href="http://localhost:4000/2017/04/09/trend-extraction-ssa-sparse-binary-programming"/>
   <updated>2017-04-09T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/09/trend-extraction-ssa-sparse-binary-programming</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;The underlying trend is approximated by the sum of a part of &lt;a class=&quot;internal-link&quot; href=&quot;/2017/04/10/ssa&quot;&gt;SSA&lt;/a&gt; components, in which the total number of the SSA components in the sum is minimized subject to a specification on the maximum absolute difference between the original signal and the approximated underlying trend.&lt;/p&gt;

&lt;p&gt;As the selection of the SSA components is binary, this selection problem is to minimize the $L_{0}$ norm of the selection vector subject to the $L_{\infty}$ norm constraint on the difference between the original signal and the approximated underlying trend as well as the binary valued constraint on the elements of the selection vector.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;This problem is actually a sparse binary programming problem. To solve this problem, first the corresponding continuous valued sparse optimization problem is solved. That is, to solve the same problem without the consideration of the binary valued constraint. This problem can
be approximated by a linear programming problem when the
isometry condition is satisfied, and the solution of the linear
programming problem can be obtained via existing simplex
methods or interior point methods.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;By applying the binary
quantization to the obtained solution of the linear programming
problem, the approximated solution of the original sparse
binary programming problem is obtained. Unlike previously
reported techniques that require a pre-cursor model or
parameter specifications, the proposed method is completely
adaptive.&lt;/p&gt;

&lt;h3 id=&quot;details&quot;&gt;Details&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;The conventional approach for selecting SSA
components for extracting the underlying trend is to employ
only the first several SSA components. However, this
selection rule fails when the underlying trend of a signal has a
complicated structure such as a high order polynomial
structure which cannot be characterized by only the first
several SSA components.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The idea is to formulate the
selection problem as a sparse binary programming problem and proposes an efficient methodology for approximating
the solution of the problem. In particular, the selection
problem is formulated as follows. The number of the
components to be selected is minimized subject to a
specification on the maximum absolute difference between
the approximated underlying trend and the original signal as
well as the binary valued constraint on the selection
coefficients. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Since the sparse binary programming problem is
nonsmooth, nonconvex and NP hard, it requires an exhaustive
search for finding the solution. As a result, the computational
effort for finding the solution is very large and an efficient
algorithm for approximating the solution is very useful and
important. &lt;/p&gt;

&lt;p&gt;To address these issues, the corresponding continuous valued optimization problem (the same
optimization problem without the consideration of the binary valued constraint) is considered. Although this continuous valued optimization problem is with an $L_{0}$ objective function
subject to an $L_{\infty}$ norm constraint, this problem can be approximated by a linear programming problem when the isometry condition is satisfied, and the solution of the linear programming problem can be efficiently obtained via existing simplex methods or interior point methods.&lt;/p&gt;

&lt;p&gt;By applying the binary quantization to the obtained solution of this linear programming problem, the approximated solution of the original sparse binary programming problem is
obtained.&lt;/p&gt;

&lt;h2 id=&quot;methodology&quot;&gt;Methodology&lt;/h2&gt;

&lt;p&gt;SSA is a nonparametric approach which does not need a priori specification on the model of the time series. It is very useful for extracting the underlying trend of a signal by selecting a subgroup of all $D$ SSA components and representing the underlying trend as the sum of the selected components.&lt;/p&gt;

&lt;p&gt;Here, it is required to determine how to partition the index set into $2$ disjoint subsets $I_{1}$ and $I_{2}$ , in which they represent the underlying trend and the residual of the signal, respectively.&lt;/p&gt;

&lt;p&gt;However, how to adaptively select the SSA components corresponding to the underlying trend is still an unsolved problem.&lt;/p&gt;

&lt;p&gt;In order not to select the irregularities in the original signal, only the most important SSA components corresponding to the underlying trend of the signal are selected.&lt;/p&gt;

&lt;p&gt;The selection problem is formulated as the following sparse sparse binary programming problem.&lt;/p&gt;

\[z^{*}= \begin{bmatrix}
z_{1}^{*}&amp;amp; \dots, z_{D}^*
\end{bmatrix}^{T}= \mathrm{argmin}_{z} \lVert z\lVert_{0}\]

&lt;p&gt;subject to $\lVert Az-x\lVert_{\infty} \le \epsilon$ and $z_{i}\in{0,1}$ for $i=1,\dots,D$.&lt;/p&gt;

&lt;p&gt;Here&lt;/p&gt;

\[A=[\tilde{x}_1,\dots,\tilde{x}_D]\in R^{N \times D}\]

&lt;p&gt;and&lt;/p&gt;

\[\epsilon=0.5\mathrm{max}_{n}(e_{up}(n)-e_{low}(n))\]

&lt;p&gt;where $e_{up}(n)$ and $e_{low}(n)$ are the upper and lower envelopes of $x(n)$, respectievely.&lt;/p&gt;

&lt;p&gt;If $z_{i}^{\ast}=1$ (or $z_{i}^{\ast}=0$), then the corresponding component $\tilde{x}_i$ for $i=1,\dots,D$ is selected (or excluded) for the representation of the underlying trend.&lt;/p&gt;

&lt;p&gt;Since the total number of the selected components is minimized, the obtained solution is sparse and only the important SSA components corresponding to the underlying trend are selected. On the other hand, $L_{\infty}$ norm specification forces the underlying trend to follow the global change of the original signal.&lt;/p&gt;

&lt;p&gt;In order to solve this sparse binary optimization problem, the corresponding $L_{0}$ norm continuous valued optimization
problem is considered first. The solution of the $L_{0}$ norm
continuous valued optimization problem is approximated by
the solution of the corresponding $L_{1}$ norm continuous valued
optimization problem when the isometry condition is satisfied. That is, to solve the following optimization problem:&lt;/p&gt;

\[y^{*}= [y_{1}^{*},\dots,y_{D}^{*}]= \mathrm{arg}\min_{y}\lVert y\lVert_{1} \text{  subject to } \lVert Ay-x\lVert_{\infty}\le \epsilon\]

&lt;p&gt;By further applying the quantization on $y_{i}^{*}$ for $i=1,\dots,D$ to either $0$ or $1$ via the following operator.&lt;/p&gt;

\[W_{i}^{*}=
\begin{cases}
1 &amp;amp;  y_{i}^{*}\ge 0.5\\
0 &amp;amp;  y_{i}^{*}&amp;lt; 0.5
\end{cases}\]

&lt;p&gt;the corresponding component $\tilde{x}_{i}$&lt;/p&gt;

&lt;p&gt;for is selected (excluded) for the representation of the underlying trend if&lt;/p&gt;

&lt;p&gt;$W_{i}^{\ast}=1( \text{ or } W_{i}^{\ast}=0)$&lt;/p&gt;

&lt;p&gt;Finally the underlying trend of the signal is obtained by&lt;/p&gt;

\[\Gamma = AW^*\]

&lt;p&gt;where $W^{\ast}= [W_1^{\ast},\dots,W_D^{\ast} ]^T$. The quantized solution is employed for the approximation of the solution of original &lt;a class=&quot;internal-link&quot; href=&quot;/2017/04/11/sparse-representation&quot;&gt;sparse binary programming problem&lt;/a&gt;. It is found that the solution obtained by the proposed method is very close to the actual solution of the original sparse binary programming
problem. That is, $W^{\ast}$ in is very close to $z^{\ast}$ above.&lt;/p&gt;

&lt;p&gt;Therefore, the subset $I_{1}$ can be obtained by&lt;/p&gt;

\[I_{1} = \{i\vert W_{i}^{*}= 1, 1\le i 
\le D\}\]

&lt;p&gt;After obtaining the underlying trend $\Gamma$ for the first $N$ points, the above SSA procedure can be applied for the prediction of the underlying trend for future time indices.&lt;/p&gt;

&lt;p&gt;Denote $\Gamma =[\gamma(1), \dots, \gamma(N)]^T$. In order to predict the underlying trend in the future time indices, we assume that
there is an underlying structure in the time series and this
structure is preserved for the time period to be predicted. A
prediction model based on the linear recurrent formulae (LRF)
is employed.&lt;/p&gt;

&lt;p&gt;That is, the points $\gamma(N-L+2), \dots, \gamma(N)$ are employed for the prediction of $\gamma(N+1)$, and so on. In other words,&lt;/p&gt;

\[\gamma(n+1) = \sum_{k=0}^{L-2}a_{k}\gamma(n-k) \text{   for  } n\ge N,\]

&lt;p&gt;where the coefficient vector of the LRF denoted as $R=(a_{L-2}, \dots, a_{0})^T$ is given by&lt;/p&gt;

\[R = \frac{1}{1-\nu^{2}}\sum_{i\in I_{1}}\pi_{i}U_{i}^{\nabla}\]

&lt;p&gt;Here, $\nu^{2=}\sum_{i\in I_{1}}\pi_{i}^2$, $\pi_{i}$ is the last element in $U_{i}$, and $U_{i}^{\nabla }\in R^{L-1}$ is the vector only containing the first $L-1$ elements of $U_{i}$ for $i \in I_{1}.$&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>ICA with CDWT</title>
   <link href="http://localhost:4000/2017/04/08/ica-with-cdwt"/>
   <updated>2017-04-08T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/08/ICA-with-CDWT</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;It is well known that if the original sounds are mixed in
the real environment (in the time domain) then the observed
sounds are a convolution mixture between the original
sounds with a delay and a reverberation. In order to simplify
this convolution mixture, it is a good idea to convert the
signal from the time domain into the timefrequency
domain and transform the convolution mixture into the
linear mixture by a timefrequency analysis method. By
doing this the drawback of poor performance with unsteady
sounds of the ICA also can be improved.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The time-frequency analysis method is usually a
combination of the &lt;a class=&quot;internal-link&quot; href=&quot;/2017/04/06/blind-source-seperation-ica&quot;&gt;ICA&lt;/a&gt;, the Short Time Fourier Transform
(STFT) and the Discrete Wavelet Transform (DWT).&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The STFT is probably the most common approach for
timefrequency analysis. It subdivides the signal into short
time segments (it is the same as using a small window to
divide the signal), and a discrete Fourier transform is
computed for each of these. For each frequency component,
however, the window length is fixed. So it is impossible to
choose an optimal window for each frequency component,
that is, the short time Fourier transform is unable to obtain
optimal analysis results for individual frequency
components.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;On the other hand, the DWT that was
carried out by Mattals fast algorithm also has a drawback
of lacking shift invariance although it can solve the problem
of the window width and obtain optimal frequency
resolution for each frequency component. Fortunately,
in order to improve the fault, a Complex Discrete Wavelet
Transform (CDWT) was proposed and it has been applied
widely to signal and image analysis&lt;/p&gt;

&lt;h2 id=&quot;ica-and-cdwt-for-blind-source-seperation&quot;&gt;ICA and CDWT for blind source seperation&lt;/h2&gt;

&lt;p&gt;In this method, the signals first were transformed from the timedomain into the
timefrequency domain by using the CDWT and then the ICA was carried out in the timefrequency domain. As in traditional methods, such as the STFT + ICA and the DWT + ICA, the following two problems when the ICA processing was carry out in the timefrequency domain
occurred. 
	1. Scaling problem: the signals amplitude and phase obtained by the ICA was changed, 
	2. Permutation problem: the separated signals are replaced at every frequency level mutually.&lt;/p&gt;

&lt;p&gt;This method discuss the technique for solving the scaling and the permutation problems. Finally, the separated signals are obtained by the inverse CDWT.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/snips/ica_cdwt.png&quot; alt=&quot;ICA_CDWT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, the case of two sound sources and two mikes has been considered for simplicity. First of all,
the two sound signals $x_n(t) (n=1,2,$ where $n$ is the number of channels and $t$ is the time) were observed by mikes from two sound sources $s_{i}(t) ( i =1, 2)$. The relation between the observed signal $x_n(t)$ and the sound source $s_{i}(t)$ is as follows:&lt;/p&gt;

\[x_{n}(t) = \mathbf{A_{n,i}}(t) \ast  S_{i}(t) \tag{1}\]

&lt;p&gt;where $\ast$ denotes convolution, the $\mathbf{A_{n,i}}(t)$ , is the impulse response that is from the sound sources to the mikes and can be shown as the following equation:&lt;/p&gt;

\[\mathbf{A_{n,i}}(t) = \begin{bmatrix} 
a_{11}(t) &amp;amp; a_{12}(t)\\ a_{21}(t) &amp;amp; a_{22}(t)\\
\end{bmatrix}, n,i = 1,2\]

&lt;p&gt;If one transforms the signal $x_{n}(t)$ from the time domain to the timefrequency domain by the CDWT then the (1) can be expressed as (2), in which the convolution of the sound source and the impulse response was changed to simple multiplication.&lt;/p&gt;

\[x_{n}(\omega , T) = \mathbf{A_{n,i}}(\omega) S_{i}(\omega,T) \tag{2}\]

&lt;p&gt;where, $\omega$ is the frequency and $T$ the time in the timefrequency domain.&lt;/p&gt;

&lt;p&gt;Next, whitening of the observed signal was carried out as follows:&lt;/p&gt;

\[\hat{x}_{n}(\omega , T) = Q(\omega) x_{n}(\omega,T) \tag{3}\]

&lt;p&gt;where $\hat{x}_{n}(\omega ,T)$&lt;/p&gt;

&lt;p&gt;is a whitened signal matrix and $Q(\omega)$ a whitened mixture, which can be obtained from the observed mixture signal $x_{n}(\omega , T)$ in each frequency.&lt;/p&gt;

&lt;p&gt;Finally, the ICA was carried out by using the whitened signal matrix $\hat{x}_{n}(\omega , T)$&lt;/p&gt;

&lt;p&gt;, in which the separation matrix $W(\omega)$ can be presumed. As a result, the separated signal $u_{i}(\omega , T)$ shown in (4) can be obtained.&lt;/p&gt;

\[u_{i}(\omega , T) = W(\omega) \hat{x}_{n}(\omega,T) \tag{4}\]

&lt;p&gt;The convolution mixture signal $x_{n}(t)$  shown in (1) can be transformed into the linear mixture signal
$x_{n}(\omega, T)$ shown in (2) by using the CDWT which simplifies the preprocessing of the ICA. A complex wavelet like, RI-Daubechies 6 wavelet can be applied as the mother wavelet.&lt;/p&gt;

&lt;h2 id=&quot;problem-and-correction-rule-of-ica-processing&quot;&gt;Problem and correction rule of ICA processing&lt;/h2&gt;

&lt;p&gt;The ICA is a technique for presuming the sound source $s_{i}(\omega,T)$  and the inverse matrix of $A_{ni}(\omega)$ from statistics without any former information of the observed signal. In this case, the amplitude of the separated signal $u_{i}(\omega,T)$ is a constant times the amplitude of the sound source $s_{i}(\omega,T)$ and a correction is needed.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In this method, a similar amplitude change at each frequency level also occurred in the preprocessing by CDWT introduced. This phenomenon is called a scaling irregularity. Furthermore,
same as in the traditional method, it is also possible that the separated sound is replaced with noise at every frequency
level mutually. This phenomenon is called the permutation
problem. Therefore, after these two problems are solved, the
inverse complex discrete wavelet transform is performed,
and it is necessary to restore the sound signal observed with
each mike.&lt;/p&gt;

&lt;h3 id=&quot;scaling-problem-and-correction-rule&quot;&gt;Scaling problem and correction rule&lt;/h3&gt;

&lt;p&gt;Not only the amplitude of the restored signal but the phase also differs depending on the frequency by making for signal whitening (making no correlation). To take an arbitrary complex value by processing, this is caused. In order to solve the scaling irregularity problem, a method has
been proposed by Murata that uses the independent element $u_{i}(\omega,T)$ , which is obtained at each frequency and divides the spectrum. In this study, the method of correcting scaling is adopted from the divided spectrum and can be shown as follows:&lt;/p&gt;

\[v_{1}(\omega,T)=\begin{bmatrix}
v_{11}(\omega,T)\\ v_{12}(\omega,T)
\end{bmatrix} = (W(\omega)Q(\omega))^{-1}\begin{bmatrix}
u_{1}(\omega,T) \\
0
\end{bmatrix}\]

\[v_{2}(\omega,T)=\begin{bmatrix}
v_{21}(\omega,T)\\ v_{22}(\omega,T)
\end{bmatrix} = (W(\omega)Q(\omega))^{-1}\begin{bmatrix} 0 \\
u_{2}(\omega,T) 
\end{bmatrix}\]

&lt;p&gt;where $v_{11}(\omega,T),v_{22}(\omega,T)$ are divided spectrums. If the sum $v_{1}(\omega,T)+v_{2}(\omega,T)$ is calculated then the sum $v_{11}(\omega,T)+v_{21}(\omega,T)$ is the mixture signal $x_{1}(\omega,T)$ and the sum $v_{11}(\omega,T)+v_{22}(\omega,T)$ is the mixture signal $x_{2}(\omega,T)$&lt;/p&gt;

&lt;h3 id=&quot;permutation-problem-and-correction-rule&quot;&gt;Permutation problem and correction rule&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;The complex Fast-ICA performs separation based on
non-Gaussian characteristics. Therefore, the possibility of
the separating signal with higher non-Gaussian
characteristics being output as the first channel is very high.
However, the height of the frequency is not determined and
noise with low non-Gaussian characteristics might also be
output. &lt;/p&gt;

&lt;p&gt;Therefore, there is a possibility that the output of each frequency level is separated without being united by the sound. The separated signal $u_{1}(\omega,T), u_{2}(\omega,T)$ of the 1st and 2nd channel without permutation is shown as follows.&lt;/p&gt;

\[u_{1}(\omega ,k) \approx s_{1}(\omega,T) \tag{5} ; u_{2}(\omega ,k) \approx s_{2}(\omega,T)\]

&lt;p&gt;The above expression can be shown as the following equation by using the divided spectrum of the scaling correction.&lt;/p&gt;

\[\begin{bmatrix}
v_{11}(\omega,T)\\ 
v_{22}(\omega,T)
\end{bmatrix} = \begin{bmatrix}
g_{11}(\omega,T)u_{1}(\omega,T) \\
g_{21}(\omega,T)u_{1}(\omega,T)
\end{bmatrix}\]

\[\begin{bmatrix}
v_{21}(\omega,T)\\ 
v_{22}(\omega,T)
\end{bmatrix} = \begin{bmatrix}
g_{12}(\omega,T)u_{2}(\omega,T) \\
g_{22}(\omega,T)u_{2}(\omega,T)
\end{bmatrix}\]

&lt;p&gt;On the other hand, when permutation occurs, (5) becomes the next expression&lt;/p&gt;

\[u_{1}(\omega ,k) \approx s_{2}(\omega,T) \tag{6} ; u_{2}(\omega ,k) \approx s_{1}(\omega,T)\]

\[\begin{bmatrix}
v_{11}(\omega,T)\\ 
v_{22}(\omega,T)
\end{bmatrix} = \begin{bmatrix}
g_{12}(\omega,T)u_{2}(\omega,T) \\
g_{22}(\omega,T)u_{2}(\omega,T)
\end{bmatrix}\]

\[\begin{bmatrix}
v_{21}(\omega,T)\\ 
v_{22}(\omega,T)
\end{bmatrix} = \begin{bmatrix}
g_{11}(\omega,T)u_{1}(\omega,T) \\
g_{21}(\omega,T)u_{1}(\omega,T)
\end{bmatrix}\]

&lt;p&gt;From these, we can know that the divided spectrum can be shown as a multiplication of the separated signal $u_{i}(\omega,T)$ and the transfer function $g_{ni}(\omega)$ , which is from the sound source to the mike.&lt;/p&gt;

&lt;p&gt;The separation matrix $W(\omega)$ and the whitening matrix $Q(\omega)$ presumed by the ICA processing are used and the next equation can be obtained.&lt;/p&gt;

\[D = (W(\omega)Q(\omega))^{-1} = \begin{bmatrix}
g_{11}(\omega) &amp;amp; g_{12}(\omega) \\
g_{21}(\omega) &amp;amp; g_{22}(\omega)
\end{bmatrix} = e\begin{bmatrix}
a_{11}(\omega) &amp;amp; a_{12}(\omega) \\
a_{21}(\omega) &amp;amp; a_{22}(\omega)
\end{bmatrix} = eA_{ni}(\omega), e \in \mathbb{R}\]

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;CDWT +Complex Value Fast ICA outperforms, STFT+ Complex value Fast ICA and DWT+Real Value Fast ICA&lt;/p&gt;

&lt;p&gt;Reference : BLIND SOURCE SEPARATION BY COMBINING INDEPANDENT COMPONENT ANALYSIS WITH COMPLEX DISCRETE WAVELET TRANSFORM ZHONG ZHANG , TAKESHI ENOMOTO , TETSUO MIYAKE , TAKASHI IMAMURA&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Piecewise linear representation of time series</title>
   <link href="http://localhost:4000/2017/04/07/piecewise-linear-representation"/>
   <updated>2017-04-07T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/07/piecewise-linear-representation</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;The time series data usually fluctuate frequently and exit a lot of noise. So data mining in the original sequence data directly will not only cost highly in the storage and computation, but also probably affect the accuracy and reliability of the data mining algorithms. Therefore, many time series models are proposed, which can transform original series to new series. Modeling may not only compress the data, but also keep the main form and ignore fine changes. Accordingly, it can help improve the efficiency and accuracy of the data mining algorithms, which will provide policy support for data analysts.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;u&gt;&lt;b&gt;Piecewise Linear Representation Based on Important Point:&lt;/b&gt;&lt;/u&gt; Pratt and Fink proposed a piecewise linear representation based on the important points. The important points are defined as the points which are the extreme points within the local scope and the ratio of the important point and the endpoint exceeds the parameters $R$. After extracting the important points from the time series, the algorithm then combines the points with the line orderly. Thus it will generate a new time series and get various piecewise linear representation with different fine and granularity by selecting different parameters  $R$.&lt;/li&gt;
  &lt;li&gt;&lt;u&gt;&lt;b&gt;Piecewise Aggregate Approximation (PAA):&lt;/b&gt;&lt;/u&gt; Keogh and Yi proposed the method of the piecewise aggregate approximation independently. The algorithm divides the time series by the same time width and each sub-segment is represent by the average of the sub-segment. The method is simple, intuitionistic. It not only can support the similarity queries, all the Minkowski metric and the weighted Euclidean distance, but also can be used to index to improve query efficiency.&lt;/li&gt;
  &lt;li&gt;&lt;u&gt;&lt;b&gt;Piecewise Linear Representation based on the characteristic points:&lt;/b&gt;&lt;/u&gt; Xiao  proposed a method of piecewise linear representation based on the characteristic points. After extracting the characteristic points from the time series, the algorithm then combines the points with the line orderly. Thus it will generate a new time series.&lt;/li&gt;
  &lt;li&gt;&lt;u&gt;&lt;b&gt;Piecewise Linear Representation Based on Slope Extract Edge Point (SEEP)&lt;/b&gt;&lt;/u&gt;:** ZHAN Yan-Yan brought forward a new piecewise linear representation combining slope with the characteristics of time series. The algorithm can select some change points according to the rate of slope change firstly, and then combines the points with the line sequentially. Finally it will generate a new time series.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The literatures above are analyzed as follows:&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;The piecewise linear representation gets some characteristics (e.g., extreme point, trend, etc.) of each section by segmenting the series mainly. The above methods not only have the advantages of simple and intuitive, but also can support dynamic incremental updates, clustering, fast similarity search, and so on. But the cost and fitting error is different.
&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;u&gt;&lt;b&gt;Piecewise Linear Representation of Time Series based on Slope Change Threshold (SCT):&lt;/b&gt;&lt;/u&gt;
Firstly, the algorithm calculates the two segments slope of the certain point connecting with the
two adjacent points(except the two endpoints of time series).Secondly, it determines the change points by the ratio of slope. And then it combines the points with the line orderly. In this way, a new time series arises.&lt;/p&gt;

&lt;p&gt;The key of the algorithm is determining the change points. The change points must follow the
following principles:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The first point and last point are both change point;&lt;/li&gt;
  &lt;li&gt;When the slope of the line combining the certain point with its left neighboring point is zero, we
look on the point as change point if the slope of the line combining the certain point with its right
neighboring point is out the range of$(-d,+d);$&lt;/li&gt;
  &lt;li&gt;When the slope of the line combining the certain point with its left neighboring point is not zero, we look on the point as change point if the slope ratio of two lines is beyond the range of $(1-d,1+d).$ The two lines refer to the line which combines the certain point with its right neighboring point and the line which combines the certain point with its left neighboring point. Above $d$ is a threshold parameter.&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>ICA</title>
   <link href="http://localhost:4000/2017/04/06/blind-source-seperation-ica"/>
   <updated>2017-04-06T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/06/blind-source-seperation-ica</id>
   <content type="html">&lt;p&gt;The main idea can be briefly expressed by the following mixed model:
\(x(t) = \mathbf{A} s(t) + n(t)\)
The statistical model in the above equation is called ICA model, which describes how the observed data are mixed through the components $s(t)$ . The $m$ dimension column vector $x(t)$ is the observed data. $\mathbf{A}$ is a $m \times n$ mixing matrix; $n(t)$ denotes the additive noise vector. The matrix $\mathbf{A}$ is assumed to be unknown. All we observe is the random vector x(t) , and we must estimate both Aand s(t) . Since $\mathbf{A}$ is unknown, so $s(t)$ seems to be unsolvable.&lt;/p&gt;

&lt;p&gt;Fortunately, there are many mathematical methods for calculating the coefficients of $\mathbf{A}$ by requiring the High-Order Statistics (HOS) information during the search for independent
components.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Extreme Point Symmetric Mode Decomposition</title>
   <link href="http://localhost:4000/2017/04/05/extreme-point-symmetric-mode-decomposition"/>
   <updated>2017-04-05T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/05/extreme-point-symmetric-mode-decomposition</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Considering the extraction methods of trend item, including the difference method, average slope method, moving average method, low pass filtering method, and least square fitting method, the type of trend term often needs to be presupposed. These methods are not suitable for processing the nonstationary signals with complex or random change trends.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;According to previous studies, the wavelet transform-based method is required for preselecting the wavelet basis and decomposition levels. This method is influenced easily by
artificial factors and has no self-adaptability. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The method based on Empirical mode decomposition (EMD) can adaptively decompose non-stationary signals regardless of the type of trend term. But, EMD is affected by mode mixing and
end effect, causing the decomposed trend function is rough and the extraction accuracy is restricted. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Professor Wang et al. recently proposed a self-adaptive method called ESMD. The ESMD is a novel development derived from Hilbert Huang transform that can be used to process non-stationary signal. ESMD has been applied to many studies.&lt;/p&gt;

&lt;h2 id=&quot;esmd&quot;&gt;ESMD&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Identify all local extreme points, including maxima and minima points, of the data $Y$. Mark them as $E_{i} (1  i  n);$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Connect all adjacent Ei with line segments, and mark their midpoints as $F_{i} (1  i  n-1);$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Add left and right boundary midpoints $F_{0}$ and $F_{n}$ using linear interpolation method;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 4:&lt;/strong&gt; Construct $p$ interpolating curves $L_{1}, L_{2},\dots L_{p} (p1)$ with all $n+1$ midpoints and calculate their mean value by using equation $L^{\ast}$.&lt;/li&gt;
&lt;/ul&gt;

\[L^{*}= \frac{L_{1}+L_{2}+\dots + L_{p}}{p}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 5:&lt;/strong&gt; Repeat steps $1$ to $4$ on $Y - L^{\ast}$ until $||L^{\ast}|| \le \epsilon$ ($\epsilon$ is a permitted error), or until the sifting times attain a preset maximum number $K$. Then, the first mode $M_{1}$ is obtained.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 6:&lt;/strong&gt; Repeat steps $1$ to $5$ on the residual $Y - M_1$ and obtain $M_2, M_3 \dots$ until the last residual $R$ with no more than a certain number of extreme points.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 7:&lt;/strong&gt; Change the maximum number $K$ on a finite integer interval $[K_{min}, K_{max}],$ and repeat all previous steps. Calculate the variance $\sigma^2$ of $Y - R$ and plot a figure with $\frac{\sigma}{\sigma_{0}}$ and $K$, $\sigma_{0}$ is the standard deviation of $Y$.&lt;/li&gt;
&lt;/ul&gt;

\[\sigma^2 = \frac{1}{N}\sum_{i=1}^N(y_{i}-r_{i})^2\]

\[\sigma_{0}^2 = \frac{1}{N}\sum_{i=1}^N(y_{i}-\bar{Y})^2\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 8 :&lt;/strong&gt; Identify the number $K_0$ which corresponds to the minimum  $\frac{\sigma}{\sigma_{0}}$  in $[K_{min}, K_{max}].$  Use this $K_{0}$ to repeat steps $1$ to $6$ and obtain the whole modes. Then last residual $R$ is an optimal Adaptive global mean (AGM) curve.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Based on the steps above, ESMD can decompose signal into limited intrinsic mode functions and a residual component. The residual component $R$ is an optimal AGM curve that can be considered as the trend term of the original signal.&lt;/p&gt;

&lt;p&gt;&lt;u&gt;The extraction error of EMD is larger than that of ESMD. &lt;/u&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The EMD-based extraction method can adaptively extract the signal trend. Whereas, the extracted trend curve limits the number of its extreme points (no more than 1), and no optimal strategy to find it. Therefore, the extraction error of EMD is relatively larger than that of ESMD.&lt;/li&gt;
  &lt;li&gt;The ESMD-based extraction method has commendable self-adaptability. It can obtain the signal trend with high precision using adaptive decomposition and optimization. The trend type of signal does not need to be preset. And, the extraction results of ESMD are better than that of EMD.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Reference: Adaptive extraction method for trend term of machinery signal based on
extreme-point symmetric mode decomposition - Yong Zhu, Wan-lu Jiang and Xiang-dong Kong&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PCA ICA for 1D timeseries</title>
   <link href="http://localhost:4000/2017/04/03/pca-ica-1d-timeseries"/>
   <updated>2017-04-03T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/03/PCA-ICA-1d-timeseries</id>
   <content type="html">&lt;h3 id=&quot;idea&quot;&gt;Idea&lt;/h3&gt;
&lt;p align=&quot;justify&quot;&gt;Principal component analysis (PCA) isa method that transforms multiple data series into uncorrelated data series. Independent component analysis &lt;a class=&quot;internal-link&quot; href=&quot;/2017/04/06/blind-source-seperation-ica&quot;&gt;ICA&lt;/a&gt; is a method that separates multiple data series into independent data series. However, both require signals from at least two separate sensors. To overcome this requirement and utilize the fault detection capability of ICA and PCA, we propose to use wavelet transform to pre-process the data collected from a single sensor and then use the coefficients of the wavelet transforms at different scales as input to ICA and PCA. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Independent components analysis (ICA) requires little prior knowledge about the components to be isolated; however, at least two sensors must be available for signal collection and the number of sensors must be at least equal to the number of sources to be separated and this method cannot be applied directly when there is only one sensor collecting signals.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Principal component analysis (PCA) is a multivariate data analysis technique that transforms a set of correlated variables into a set of uncorrelated variables. Each member of the resulting set of uncorrelated variables is called a principal component. We are interested in determining its suitability for fault detection because one of the identified principal components may reveal the signature of a hidden fault. As with ICA, however, this method cannot be applied directly when only a single variable is observed.&lt;/p&gt;

&lt;p&gt;Wavelet transform may be considered as a series of band pass filters when applied to the data
collected from a single sensor. The results of the transform, which exist in different frequency
regions, say $N$ regions, may be considered as different mixtures of the sources that have
generated the collected signals.These $N$ groups of data can then be used as input to ICA or PCA
for identification of the hidden sources.&lt;/p&gt;

&lt;h3 id=&quot;ica-and-pca&quot;&gt;ICA and PCA&lt;/h3&gt;

&lt;p&gt;ICA is a technique for separating independent sources linearly mixed in signals. Suppose that
there are $N$ independent sources of vibration, and $N$ sensors at different locations are used to
record vibration signals. The signals recorded by each sensor come from different sources with
different mixing ratios. Let $s_{1}(t),s_{2}(t),  \dots ,s_{N}(t)$ be the signals produced by the $N$ independent
sources and $x_{1}(t),x_{2}(t),  \dots ,x_{N}(t)$ be the observations from the $N$ sensors. The sensors record these signals simultaneously. The task of ICA is to estimate the mixing ratios of the source signals in the collected signals and obtain the independent source signals.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;To identify the independent components successfully, we need a rule for evaluating the
independency of the identified components. According to the Central Limit Theorem, the
distribution of the sum of a large number of independent random variables tends to a Gaussian
distribution. Since the collected signals are weighted sums of the independent sources, the sources
to be isolated must have less Gaussianity than the collected signals. Thus, non-Gaussianity can be
used for separating independent components. Hyvarinen and Oja proposed to use negentropy
to evaluate the non-Gaussianity of the separated components so as to evaluate separation
performance. With this concept, we can seek the separation that provides the least Gaussianness of the separated components. The popular FastICA algorithm proposed by Havarinen and Oja
isoften used to carry out the ICA procedure.&lt;/p&gt;

&lt;p&gt;PCA is a technique that obtains linear transformations of a group of correlated variables such
that the transformed variables are uncorrelated. For example, consider two variables, $x_{1}$ and
$x_{2}$. For each variable, we have obtained the following $N$ observations:
\(x_{11}, x_{12}, \dots , x_{1N}; x_{21}, x_{22}, \dots; x_{2N}\)
where $x_{1i}$ and $x_{2j}$ denote the $i^{th}$ and the $j^{th}$ observations of variables $x_{1}$ and $x_{2}$, respectively. The PCA method seeks two new axes, D1 and D2, that make the projectionsof the collected data onto
D1 have the largest variability and at the same time, the projections of the collected data onto D2
have the smallest variability. This way, we have expressed the collected data as their two principal
components. Most of the variation in the original data is explained by the first principal
component, D1, and the remaining variation in the original data isexplained by the second
principal component, D2.&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;
ICA renders the separated components independent of one another while PCA rendersthe
separated components uncorrelated with one another. PCA separates the components based only
on the second-order cumulant while ICA separates the components on high-order cumulants.
Therefore, ICA can be considered a generalization of PCA.&lt;/p&gt;

&lt;h3 id=&quot;method-of-preprocessing-to-apply-ica-or-pca-on-1d-time-series&quot;&gt;Method of preprocessing to apply ICA or PCA on 1D Time series&lt;/h3&gt;

&lt;p&gt;The available data is a single time series. To apply ICA or PCA for feature extraction, we need
to have more than one time series. A method to generate multiple time series from the single available time series is given below.&lt;/p&gt;

&lt;p&gt;Wavelet transform decomposes a signal series in the time domain into a two-dimensional
function in the time-scale (frequency) plane. The wavelet coefficients measure the time-scale (frequency) content in a signal indexed by the scale parameter and the translation parameter. Let
$\varphi(t)$ be the mother wavelet. The wavelet family consists of a series of daughter wavelets that are
generated by dilation and translation from the mother wavelet $\varphi(t)$&lt;/p&gt;

\[\varphi_{a, b}(t)=\sqrt{|a|} \varphi[(t-b) / a]\]

&lt;p&gt;where $a$ is the scale parameter, $b$ isthe location parameter, and $\sqrt{  |a|}$
isused to guarantee energy preservation. The wavelet transform of signal $x(t)$ isdefined as the inner product of $\varphi_{a, b}(t)$ and $x(t)$ in the Hilbert space of $L^2$ norm defined as:&lt;/p&gt;

\[W(a, b)=\left\langle\varphi_{a, b}(t), x(t)\right\rangle=\int x(t) \varphi_{a, b}^*(t) \mathrm{d} t\]

&lt;p&gt;where the symbol * stands for the complex conjugate.&lt;/p&gt;

&lt;p&gt;Wavelet transform can be thought of as a series of band pass filters. The results of the
transform, which exist in different frequency regions, may be thought of as different mixtures of the independent sources. These different mixtures may be considered to be signals collected at
different locations, or more accurately, through different sensors with different frequency
ranges. This way, the one-dimensional signal is transformed into multidimensional data
that satisfy the requirements of ICA and PCA. The preprocessing of the one-dimensional data with wavelet transform makes ICA and PCA usable for identification of a hidden
source.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/snips/img1.png&quot; alt=&quot;Flowchart&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference-&quot;&gt;Reference :&lt;/h3&gt;
&lt;p&gt;Feature separation using ICA for a one-dimensional time series and its application in fault detection - Ming J. Zuo, Jing Lin, Xianfeng Fan&lt;/p&gt;
</content>
 </entry>
 

</feed>
