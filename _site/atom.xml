<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Pavan Donthireddy</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2023-04-03T22:53:07+01:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Pavan Donthireddy</name>
   <email>quarterpastix@gmail.com</email>
 </author>

 
 <entry>
   <title>Extreme Point Symmetric Mode Decomposition</title>
   <link href="http://localhost:4000/2017/04/05/extreme-point-symmetric-mode-decomposition"/>
   <updated>2017-04-05T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/05/extreme-point-symmetric-mode-decomposition</id>
   <content type="html">&lt;p align=&quot;justify&quot;&gt;Considering the extraction methods of trend item, including the difference method, average slope method, moving average method, low pass filtering method, and least square fitting method, the type of trend term often needs to be presupposed. These methods are not suitable for processing the nonstationary signals with complex or random change trends.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;According to previous studies, the wavelet transform-based method is required for preselecting the wavelet basis and decomposition levels. This method is influenced easily by
artificial factors and has no self-adaptability. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The method based on Empirical mode decomposition (EMD) can adaptively decompose non-stationary signals regardless of the type of trend term. But, EMD is affected by mode mixing and
end effect, causing the decomposed trend function is rough and the extraction accuracy is restricted. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Professor Wang et al. recently proposed a self-adaptive method called ESMD. The ESMD is a novel development derived from Hilbert Huang transform that can be used to process non-stationary signal. ESMD has been applied to many studies.&lt;/p&gt;

&lt;h2 id=&quot;esmd&quot;&gt;ESMD&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Identify all local extreme points, including maxima and minima points, of the data $Y$. Mark them as $E_{i} (1 ≤ i ≤ n);$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Connect all adjacent Ei with line segments, and mark their midpoints as $F_{i} (1 ≤ i ≤ n-1);$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Add left and right boundary midpoints $F_{0}$ and $F_{n}$ using linear interpolation method;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 4:&lt;/strong&gt; Construct $p$ interpolating curves $L_{1}, L_{2},\dots L_{p} (p≥1)$ with all $n+1$ midpoints and calculate their mean value by using equation $L^{\ast}$.&lt;/li&gt;
&lt;/ul&gt;

\[L^{*}= \frac{L_{1}+L_{2}+\dots + L_{p}}{p}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 5:&lt;/strong&gt; Repeat steps $1$ to $4$ on $Y - L^{\ast}$ until $||L^{\ast}|| \le \epsilon$ ($\epsilon$ is a permitted error), or until the sifting times attain a preset maximum number $K$. Then, the first mode $M_{1}$ is obtained.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 6:&lt;/strong&gt; Repeat steps $1$ to $5$ on the residual $Y - M_1$ and obtain $M_2, M_3 \dots$ until the last residual $R$ with no more than a certain number of extreme points.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 7:&lt;/strong&gt; Change the maximum number $K$ on a finite integer interval $[K_{min}, K_{max}],$ and repeat all previous steps. Calculate the variance $\sigma^2$ of $Y - R$ and plot a figure with $\frac{\sigma}{\sigma_{0}}$ and $K$, $\sigma_{0}$ is the standard deviation of $Y$.&lt;/li&gt;
&lt;/ul&gt;

\[\sigma^2 = \frac{1}{N}\sum_{i=1}^N(y_{i}-r_{i})^2\]

\[\sigma_{0}^2 = \frac{1}{N}\sum_{i=1}^N(y_{i}-\bar{Y})^2\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 8 :&lt;/strong&gt; Identify the number $K_0$ which corresponds to the minimum  $\frac{\sigma}{\sigma_{0}}$  in $[K_{min}, K_{max}].$  Use this $K_{0}$ to repeat steps $1$ to $6$ and obtain the whole modes. Then last residual $R$ is an optimal Adaptive global mean (AGM) curve.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Based on the steps above, ESMD can decompose signal into limited intrinsic mode functions and a residual component. The residual component $R$ is an optimal AGM curve that can be considered as the trend term of the original signal.&lt;/p&gt;

&lt;p&gt;&lt;u&gt;The extraction error of EMD is larger than that of ESMD. &lt;/u&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The EMD-based extraction method can adaptively extract the signal trend. Whereas, the extracted trend curve limits the number of its extreme points (no more than 1), and no optimal strategy to find it. Therefore, the extraction error of EMD is relatively larger than that of ESMD.&lt;/li&gt;
  &lt;li&gt;The ESMD-based extraction method has commendable self-adaptability. It can obtain the signal trend with high precision using adaptive decomposition and optimization. The trend type of signal does not need to be preset. And, the extraction results of ESMD are better than that of EMD.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Reference: Adaptive extraction method for trend term of machinery signal based on
extreme-point symmetric mode decomposition - Yong Zhu, Wan-lu Jiang and Xiang-dong Kong&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PCA ICA for 1D timeseries</title>
   <link href="http://localhost:4000/2017/04/03/pca-ica-1d-timeseries"/>
   <updated>2017-04-03T00:00:00+01:00</updated>
   <id>http://localhost:4000/2017/04/03/PCA-ICA-1d-timeseries</id>
   <content type="html">&lt;h3 id=&quot;idea&quot;&gt;Idea&lt;/h3&gt;
&lt;p align=&quot;justify&quot;&gt;Principal component analysis (PCA) isa method that transforms multiple data series into uncorrelated data series. Independent component analysis (ICA) is a method that separates multiple data series into independent data series. However, both require signals from at least two separate sensors. To overcome this requirement and utilize the fault detection capability of ICA and PCA, we propose to use wavelet transform to pre-process the data collected from a single sensor and then use the coefficients of the wavelet transforms at different scales as input to ICA and PCA. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Independent components analysis (ICA) requires little prior knowledge about the components to be isolated; however, at least two sensors must be available for signal collection and the number of sensors must be at least equal to the number of sources to be separated and this method cannot be applied directly when there is only one sensor collecting signals.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Principal component analysis (PCA) is a multivariate data analysis technique that transforms a set of correlated variables into a set of uncorrelated variables. Each member of the resulting set of uncorrelated variables is called a principal component. We are interested in determining its suitability for fault detection because one of the identified principal components may reveal the signature of a hidden fault. As with ICA, however, this method cannot be applied directly when only a single variable is observed.&lt;/p&gt;

&lt;p&gt;Wavelet transform may be considered as a series of band pass filters when applied to the data
collected from a single sensor. The results of the transform, which exist in different frequency
regions, say $N$ regions, may be considered as different mixtures of the sources that have
generated the collected signals.These $N$ groups of data can then be used as input to ICA or PCA
for identification of the hidden sources.&lt;/p&gt;

&lt;h3 id=&quot;ica-and-pca&quot;&gt;ICA and PCA&lt;/h3&gt;

&lt;p&gt;ICA is a technique for separating independent sources linearly mixed in signals. Suppose that
there are $N$ independent sources of vibration, and $N$ sensors at different locations are used to
record vibration signals. The signals recorded by each sensor come from different sources with
different mixing ratios. Let $s_{1}(t),s_{2}(t),  \dots ,s_{N}(t)$ be the signals produced by the $N$ independent
sources and $x_{1}(t),x_{2}(t),  \dots ,x_{N}(t)$ be the observations from the $N$ sensors. The sensors record these signals simultaneously. The task of ICA is to estimate the mixing ratios of the source signals in the collected signals and obtain the independent source signals.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;To identify the independent components successfully, we need a rule for evaluating the
independency of the identified components. According to the Central Limit Theorem, the
distribution of the sum of a large number of independent random variables tends to a Gaussian
distribution. Since the collected signals are weighted sums of the independent sources, the sources
to be isolated must have less Gaussianity than the collected signals. Thus, non-Gaussianity can be
used for separating independent components. Hyvarinen and Oja proposed to use negentropy
to evaluate the non-Gaussianity of the separated components so as to evaluate separation
performance. With this concept, we can seek the separation that provides the least Gaussianness of the separated components. The popular FastICA algorithm proposed by Havarinen and Oja
isoften used to carry out the ICA procedure.&lt;/p&gt;

&lt;p&gt;PCA is a technique that obtains linear transformations of a group of correlated variables such
that the transformed variables are uncorrelated. For example, consider two variables, $x_{1}$ and
$x_{2}$. For each variable, we have obtained the following $N$ observations:
\(x_{11}, x_{12}, \dots , x_{1N}; x_{21}, x_{22}, \dots; x_{2N}\)
where $x_{1i}$ and $x_{2j}$ denote the $i^{th}$ and the $j^{th}$ observations of variables $x_{1}$ and $x_{2}$, respectively. The PCA method seeks two new axes, D1 and D2, that make the projectionsof the collected data onto
D1 have the largest variability and at the same time, the projections of the collected data onto D2
have the smallest variability. This way, we have expressed the collected data as their two principal
components. Most of the variation in the original data is explained by the first principal
component, D1, and the remaining variation in the original data isexplained by the second
principal component, D2.&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;
ICA renders the separated components independent of one another while PCA rendersthe
separated components uncorrelated with one another. PCA separates the components based only
on the second-order cumulant while ICA separates the components on high-order cumulants.
Therefore, ICA can be considered a generalization of PCA.&lt;/p&gt;

&lt;h3 id=&quot;method-of-preprocessing-to-apply-ica-or-pca-on-1d-time-series&quot;&gt;Method of preprocessing to apply ICA or PCA on 1D Time series&lt;/h3&gt;

&lt;p&gt;The available data is a single time series. To apply ICA or PCA for feature extraction, we need
to have more than one time series. A method to generate multiple time series from the single available time series is given below.&lt;/p&gt;

&lt;p&gt;Wavelet transform decomposes a signal series in the time domain into a two-dimensional
function in the time-scale (frequency) plane. The wavelet coefficients measure the time-scale (frequency) content in a signal indexed by the scale parameter and the translation parameter. Let
$\varphi(t)$ be the mother wavelet. The wavelet family consists of a series of daughter wavelets that are
generated by dilation and translation from the mother wavelet $\varphi(t)$&lt;/p&gt;

\[\varphi_{a, b}(t)=\sqrt{|a|} \varphi[(t-b) / a]\]

&lt;p&gt;where $a$ is the scale parameter, $b$ isthe location parameter, and $\sqrt{  |a|}$
isused to guarantee energy preservation. The wavelet transform of signal $x(t)$ isdefined as the inner product of $\varphi_{a, b}(t)$ and $x(t)$ in the Hilbert space of $L^2$ norm defined as:&lt;/p&gt;

\[W(a, b)=\left\langle\varphi_{a, b}(t), x(t)\right\rangle=\int x(t) \varphi_{a, b}^*(t) \mathrm{d} t\]

&lt;p&gt;where the symbol * stands for the complex conjugate.&lt;/p&gt;

&lt;p&gt;Wavelet transform can be thought of as a series of band pass filters. The results of the
transform, which exist in different frequency regions, may be thought of as different mixtures of the independent sources. These different mixtures may be considered to be signals collected at
different ‘‘locations’’, or more accurately, through different ‘‘sensors’’ with different frequency
ranges. This way, the one-dimensional signal is transformed into multidimensional data
that satisfy the requirements of ICA and PCA. The preprocessing of the one-dimensional data with wavelet transform makes ICA and PCA usable for identification of a hidden
source.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/snips/img1.png&quot; alt=&quot;Flowchart&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference-&quot;&gt;Reference :&lt;/h3&gt;
&lt;p&gt;Feature separation using ICA for a one-dimensional time series and its application in fault detection - Ming J. Zuo, Jing Lin, Xianfeng Fan&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Latex cheatsheet</title>
   <link href="http://localhost:4000/2017/03/21/latex-cheat-sheet"/>
   <updated>2017-03-21T00:00:00+00:00</updated>
   <id>http://localhost:4000/2017/03/21/latex-cheat-sheet</id>
   <content type="html">&lt;h1 id=&quot;description&quot;&gt;Description&lt;/h1&gt;
&lt;p&gt;Cheatsheet for LaTex, using Markdown for markup. I use this with &lt;a href=&quot;https://atom.io/&quot;&gt;atom.io&lt;/a&gt;
and :package:&lt;code&gt;markdown-preview-plus&lt;/code&gt; to write math stuff. :package:&lt;code&gt;keyboard-localization&lt;/code&gt;
is necessary when using an international layout (like [swiss] german).&lt;/p&gt;

&lt;p&gt;$\mathrm{abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ23456}$&lt;/p&gt;

&lt;p&gt;$\text{abcdeABCDEF ASDFASDF} \alpha, \beta, \gamma$&lt;/p&gt;

\[E = mc^2\]

&lt;p&gt;$\text{This is a text for math} \Bigg(\frac{a}{b} \Bigg)$&lt;/p&gt;

&lt;p&gt;Further Reference and source: ftp://ftp.ams.org/pub/tex/doc/amsmath/short-math-guide.pdf&lt;/p&gt;

&lt;h1 id=&quot;example-expressions--functions&quot;&gt;Example expressions / functions&lt;/h1&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Input&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Rendered&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code&gt;$a = b + c − d$&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$a = b + c − d$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code&gt;$\sqrt{?\frac{\pi}{2}}$&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$\sqrt{\frac{\pi}{2}}$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code&gt;$y = a x_1^2 + b x_2 + c$&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$y = a x_1^2 + b x_2 + c$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;special-characters--symbols&quot;&gt;Special characters / Symbols&lt;/h1&gt;
&lt;p&gt;###Latin:
#####No dot:&lt;br /&gt;
&lt;code&gt;\imath&lt;/code&gt; $\rightarrow$ $\imath$,
&lt;code&gt;\jmath&lt;/code&gt; $\rightarrow$ $\jmath$&lt;/p&gt;

&lt;p&gt;#####Hat:&lt;br /&gt;
&lt;code&gt;\hat{\imath}&lt;/code&gt;  $\rightarrow$ $\hat{\imath}$,
&lt;code&gt;\hat{\jmath}&lt;/code&gt;  $\rightarrow$ $\hat{\jmath}$&lt;/p&gt;

&lt;p&gt;###Greek Letters:
#####Capital:
LaTex      |   | LaTex    |   |
———-:|–:|———:|–:|
&lt;code&gt;\Gamma&lt;/code&gt;   | Γ | &lt;code&gt;\Delta&lt;/code&gt; | ∆ |
&lt;code&gt;\Lambda&lt;/code&gt;  | Λ | &lt;code&gt;\Phi&lt;/code&gt;   | Φ |
&lt;code&gt;\Pi&lt;/code&gt;      | Π | &lt;code&gt;\Psi&lt;/code&gt;   | Ψ |
&lt;code&gt;\Sigma&lt;/code&gt;   | Σ | &lt;code&gt;\Theta&lt;/code&gt; | Θ |
&lt;code&gt;\Upsilon&lt;/code&gt; | Υ | &lt;code&gt;\Xi&lt;/code&gt;    | Ξ |
&lt;code&gt;\Omega&lt;/code&gt;   | Ω |          |   |&lt;/p&gt;

&lt;p&gt;#####Lowercase:
LaTex      |   | LaTex     |   |
———-:|–:|———-:|–:|
&lt;code&gt;\alpha&lt;/code&gt;   | α | &lt;code&gt;\nu&lt;/code&gt;     | ν |
&lt;code&gt;\beta&lt;/code&gt;    | β | &lt;code&gt;\kappa&lt;/code&gt;  | κ |
&lt;code&gt;\gamma&lt;/code&gt;   | γ | &lt;code&gt;\lambda&lt;/code&gt; | λ |
&lt;code&gt;\delta&lt;/code&gt;   | δ |  &lt;code&gt;\mu&lt;/code&gt;    | µ |  &lt;br /&gt;
&lt;code&gt;\epsilon&lt;/code&gt; | ϵ | &lt;code&gt;\zeta&lt;/code&gt;   | ζ |
&lt;code&gt;\eta&lt;/code&gt;     | η | &lt;code&gt;\theta&lt;/code&gt;  | θ |
&lt;code&gt;\iota&lt;/code&gt;    | ι | &lt;code&gt;\xi&lt;/code&gt;     | ξ |
&lt;code&gt;\pi&lt;/code&gt;      | π | &lt;code&gt;\rho&lt;/code&gt;    | ρ |
&lt;code&gt;\sigma&lt;/code&gt;   | σ | &lt;code&gt;\tau&lt;/code&gt;    | τ |
&lt;code&gt;\upsilon&lt;/code&gt; | υ | &lt;code&gt;\phi&lt;/code&gt;    | φ |
&lt;code&gt;\chi&lt;/code&gt;     | χ | &lt;code&gt;\psi&lt;/code&gt;    | ψ |
&lt;code&gt;\omega&lt;/code&gt;   | ω |           |   |&lt;/p&gt;

&lt;p&gt;#####Other:
LaTex       |   | LaTex       |   |
———–:|—|————:|–:|
&lt;code&gt;\digamma&lt;/code&gt;  | ϝ | &lt;code&gt;varepsilon&lt;/code&gt;| ε       |
&lt;code&gt;\varkappa&lt;/code&gt; | ϰ | &lt;code&gt;\varphi&lt;/code&gt;   | ϕ       |
&lt;code&gt;\varpi&lt;/code&gt;    | ϖ | &lt;code&gt;\varrho&lt;/code&gt;   | ϱ       |
&lt;code&gt;\varsigma&lt;/code&gt; | ς | &lt;code&gt;\vartheta&lt;/code&gt; | ϑ       |
&lt;code&gt;\eth&lt;/code&gt;      | ð | &lt;code&gt;\hbar&lt;/code&gt;     | $\hbar$ |&lt;/p&gt;

&lt;p&gt;###Other:
####Other Symbols
LaTex         |   | LaTex            |   |
————-:|—|—————–:|–:|
&lt;code&gt;\partial&lt;/code&gt;    | ∂ | &lt;code&gt;\infty&lt;/code&gt;         | ∞ |
&lt;code&gt;\wedge&lt;/code&gt;      | ∧ | &lt;code&gt;\vee&lt;/code&gt;           | ∨ |
&lt;code&gt;\neg&lt;/code&gt; &lt;code&gt;\not&lt;/code&gt; | ¬ |                  |   |
&lt;code&gt;\bot&lt;/code&gt;        | ⊥ | &lt;code&gt;\top&lt;/code&gt;           | ⊤ |
&lt;code&gt;\nabla&lt;/code&gt;      | ∇ | &lt;code&gt;\varnothing&lt;/code&gt;    | ∅ |
&lt;code&gt;\angle&lt;/code&gt;      | ∠ | &lt;code&gt;\measuredangle&lt;/code&gt; | ∡ |
&lt;code&gt;\surd&lt;/code&gt;       | √ | &lt;code&gt;\forall&lt;/code&gt;        | ∀ |
&lt;code&gt;\exists&lt;/code&gt;     | ∃ | &lt;code&gt;\nexists&lt;/code&gt;       | ∄ |&lt;/p&gt;

&lt;p&gt;####Relational Symbols
LaTex             |   | LaTex              |          |
—————–:|—|——————-:|———:|
&lt;code&gt;\hookrightarrow&lt;/code&gt; | ↪      | &lt;code&gt;\Rightarrow&lt;/code&gt;     | ⇒         |
&lt;code&gt;\rightarrow&lt;/code&gt;     | →      | &lt;code&gt;\Leftrightarrow&lt;/code&gt; | ⇔         |
&lt;code&gt;\nrightarrow&lt;/code&gt;    | ↛      | &lt;code&gt;\mapsto&lt;/code&gt;         | $\mapsto$ |
&lt;code&gt;\geq&lt;/code&gt;            | ≥      | &lt;code&gt;\leq&lt;/code&gt;            | ≤         |
&lt;code&gt;\equiv&lt;/code&gt;          | ≡      | &lt;code&gt;\sim&lt;/code&gt;            | ∼         |
&lt;code&gt;\gg&lt;/code&gt;             | ≫      | &lt;code&gt;\ll&lt;/code&gt;            | ≪          |
&lt;code&gt;\subset&lt;/code&gt;          | ⊂     | &lt;code&gt;\subseteq&lt;/code&gt;     | ⊆           |
&lt;code&gt;\in&lt;/code&gt;             | ∈      | &lt;code&gt;\notin&lt;/code&gt;         | ∉          |
&lt;code&gt;\mid&lt;/code&gt;            | $\mid$ | &lt;code&gt;\propto&lt;/code&gt;        | ∝          |
&lt;code&gt;\perp&lt;/code&gt;            | ⊥     | ` \parallel&lt;code&gt;     | ∥          |
&lt;/code&gt;\vartriangle`     | $\vartriangle$&lt;/p&gt;

&lt;p&gt;####Binary operators
LaTex        |   | LaTex  |   |
————:|—|——-:|–:|
&lt;code&gt;\wedge&lt;/code&gt;     | ∧ | &lt;code&gt;\vee&lt;/code&gt; | ∨ |
&lt;code&gt;\neg&lt;/code&gt;&lt;code&gt;\not&lt;/code&gt; | ¬ |        |   |&lt;/p&gt;

&lt;p&gt;####Cumulative operators
LaTex     |           | LaTex       |             |
———:|———–|————:|————:|
&lt;code&gt;\int&lt;/code&gt;    | ∫         | &lt;code&gt;\iint&lt;/code&gt;     | $\iint$     |
&lt;code&gt;\iiint&lt;/code&gt;  | $\iiint$  | &lt;code&gt;\idotsint&lt;/code&gt; | $\idotsint$ |
&lt;code&gt;\prod&lt;/code&gt;   | $\prod$   | &lt;code&gt;\sum&lt;/code&gt;      | $\sum$      |
&lt;code&gt;\bigcup&lt;/code&gt; | $\bigcup$ | &lt;code&gt;\bigcap&lt;/code&gt;   | $\bigcap$   |&lt;/p&gt;

&lt;p&gt;####Named operators
$\arccos$,
$\arcsin$,
$\arctan$,
$\arg$,
$\cos$,
$\cosh$,
$\cot$,
$\coth$,
$\deg$,
$\det$,
$\dim$,
$\exp$,
$\gcd$,
$\hom$,
$\inf$,
$\injlim$,
$\lg$,
$\lim$,
$\liminf$,
$\limsup$,
$\ln$,
$\log$,
$\max$,
$\min$,
$\Pr$,
$\projlim$,
$\sec$,
$\sin$,
$\sinh$,
$\sup$&lt;/p&gt;
</content>
 </entry>
 

</feed>
