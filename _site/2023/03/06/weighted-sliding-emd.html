<!DOCTYPE html><html lang="en" ><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series" /><meta property="og:locale" content="en_US" /><meta name="description" content="Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series" /><meta property="og:description" content="Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series" /><link rel="canonical" href="http://localhost:4000/2023/03/06/weighted-sliding-emd" /><meta property="og:url" content="http://localhost:4000/2023/03/06/weighted-sliding-emd" /><meta property="og:site_name" content="Pavan Donthireddy" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-03-06T00:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series" /><meta name="twitter:site" content="@" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-03-06T00:00:00+00:00","datePublished":"2023-03-06T00:00:00+00:00","description":"Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series","headline":"Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2023/03/06/weighted-sliding-emd"},"url":"http://localhost:4000/2023/03/06/weighted-sliding-emd"}</script><title> Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series - Pavan Donthireddy</title><meta charset="UTF-8"><link rel="canonical" href="http://localhost:4000/2023/03/06/weighted-sliding-emd" /><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Abstract"><meta property="og:site_name" content="Pavan Donthireddy"><meta property="og:description" content="Abstract"/><meta property="og:title" content="Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series"><meta property="og:type" content="article"><meta property="article:published_time" content="2023-03-06T00:00:00+00:00"><meta property="article:author" content="http://localhost:4000/"><meta property="og:url" content="http://localhost:4000/2023/03/06/weighted-sliding-emd" /><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="Pavan Donthireddy" href="/atom.xml"><link rel="alternate" type="application/json" title="Pavan Donthireddy" href="http://localhost:4000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ jax: ["input/TeX","input/MathML","output/SVG", "output/CommonHTML"], extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "CHTML-preview.js"], TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true, processEnvironments: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }, messageStyle: "none", "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }, TeX: { equationNumbers: { autoNumber: "AMS" }, extensions: ["AMSmath.js", "AMSsymbols.js","AMScd.js"], TagSide: "left", Macros: { field: ['\\mathbb{#1}', 1], C: ['\\field{C}'], E: ['\\field{E}'], F: ['\\field{F}'], N: ['\\field{N}'], P: ['\\field{P}'], Q: ['\\field{Q}'], R: ['\\field{R}'], Z: ['\\field{Z}'], ha : ['\\hat{#1}',1], Re: ['\\mathop{\\mathrm{Re}}'], Im: ['\\mathop{\\mathrm{Im}}'], Res: ['\\mathop{\\mathrm{Res}}'], } } }); </script> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full"></script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}.post-archive{font-size:15px;line-height:2;padding-bottom:.8em}.post-archive .date{padding-right:.7em}.pagination{width:100%;padding:0 20px;text-align:center}.pagination ul{list-style:none}.pagination ul li{display:inline;margin:0 5px}.pagination ul li a{color:#000;text-decoration:none}.pagination ul li a:hover{color:gray;text-decoration:underline}.pagination ul li.current-page a{background:#ddd;color:#fff}.post-link{position:relative;display:inline-block}.post-excerpt{display:none;position:absolute;z-index:1;top:100%;left:0;width:100%;padding:10px;background-color:#fff;box-shadow:0 2px 5px rgba(0,0,0,.1)}.post-link:hover .post-excerpt{display:block}.img-padding{width:200px;height:200px;padding:20px 20px 20px 20px}</style></head><body><main role="main"><header role="banner"> <!--<h1 class="logo">Pavan Donthireddy</h1>--><nav role="navigation"><ul><li><a href="/" >Notes</a></li><li><a href="/tags" >Tags</a></li><li><a href="/search" >Search</a></li><li><a href="/about" >About</a></li></ul></nav></header><link rel="stylesheet" href="/assets/js/prism.css"><link rel="stylesheet" href="/assets/js/prism-line-numbers.css"><section class="post"> <script src="/assets/js/prism.js"></script> <script src="/assets/js/prism-line-numbers.js"></script><h1 style="text-align: center;">Weighted Sliding Empirical Mode Decomposition for Online Analysis of Biomedical Time Series</h1><div style="text-align: center;"><span class="meta"><time datetime="2023-03-06T00:00:00+00:00">March 6, 2023</time> </span></div><div style="text-align: center;"><span class="meta"> <a href="/tag/EMD">EMD</a>, <a href="/tag/online_algorithms">online_algorithms</a></span></div><h2 id="abstract">Abstract</h2><p align="justify">Biomedical signals are in general non-linear and non-stationary. empirical mode decomposition in conjunction with a Hilbert-Huang Transform provides a fully adaptive and data-driven technique to extract intrinsic mode functions. The latter represent a complete set of locally orthogonal basis functions to represent non-linear and non-stationary time series. Large scale biomedical time series necessitate an online analysis, which is presented in this contribution. It shortly reviews the technique of EMD and related algorithms, discusses the recently proposed weighted sliding EMD algorithm (wSEMD) and, additionally, proposes a more sophisticated implementation of the weighting process. As an application to biomedical signals we will show that wSEMD in combination with mutual information could be used to detect temporal correlations of arterial blood pressure and intracranial pressure monitored at a neurosurgical intensive care unit.We will demonstrate that the wSEMD technique renders itself much more flexible than the Fourier based method used in Faltermeier et al.</p><h2 id="introduction">Introduction</h2><p align="justify"> Recently an empirical nonlinear analysis tool for complex, non-stationary time series has been pioneered by Huang et al. [6]. It is commonly referred to as empirical mode decomposition (EMD) and if combined with Hilbert spectral analysis it is called Hilbert-Huang Transform (HHT). It adaptively and locally decomposes any non-stationary time series into a sum of intrinsic mode functions (IMF) which represent zero-mean amplitude and frequency modulated (AMâ€“FM) oscillatory components. The EMDrepresents a fully data-driven, unsupervised signal decomposition technique and does not need any a priori defined basis system. The empirical nature of EMD offers the advantage over other empirical signal decomposition techniques like exploratory matrix factorization (EMF) [8] of not being constrained by conditions which often only apply approximately. Especially with biomedical signals one often has only a rough idea about the underlying modes and mostly their number is unknown. Furthermore, large scale biomedical time series recorded over days necessitate an online analysis [13], while EMD can analyze data only globally so far. This contribution will review the technique of EMD and its recent extensions, propose an online EMD variant called weighted sliding EMD (wSEMD) and discuss some biomedical applications related to neuromonitoring. In the following we will denote by N the total number of time samples tn in the time series, by M the size of a segment, by S the total number of segments and by L the total number of IMFs into which the time series is decomposed in every segment.</p><h2 id="sliding-emd">Sliding EMD</h2><h3 id="the-principle">The Principle</h3><p>This new technique presents an improved EMD algorithm which is suitable for online processing of non-stationary time series. Sliding $\operatorname{EMD}$ (SEMD) $[3,4]$ offers a robust and easy -to-implement solution to the problem of dealing with e.g. biomedical time series which often are recorded over long time spans with high sampling rate. Using Sliding EMD the recorded time series is split into segments which can be analyzed with EMD. The segment size $M$ has to be a multiple of the step size $K$ with which the segments are shifted relative to each other. Thus, if $\frac{M}{K} \in \mathbb{N}$ holds, neighboring segments can be joined without resulting discontinuities or boundary artifacts. With this choice, every sample is represented equally often, i.e. $E=\frac{M}{K}$-times, in the overlapping segments for a later estimation of the corresponding mean sample value. The time series in every segment $s$ is decomposed by EMD into $L$ IMFs $x_{l, s}(t)$ and a local residuum $x_{L+1, s}(t) \equiv r_s(t)$ according to \(x_s(t)=\sum_{l=1}^L x_{l, s}(t)+r_s(t)\) whereby the number of sifting steps $L_s$ is kept equal in all segments $s$. Resulting IMFs are collected in a matrix with corresponding sample points forming a column of the matrix with $E=\frac{M}{K}$ entries. Only columns which contain an identical number of entries are used to estimate average IMF amplitudes at every time point $t_n$ in each segment. Consequently, the first and last $M$ samples of the time series are omitted. This finally yields: For $t_n&gt;M$ and $h=\left\lfloor\frac{t_n-M}{K}\right\rfloor+2:$ with $h \in \mathbb{N}$. By construction SEMD fulfills the condition to be complete, much as EMD does. Except for the stopping criterion, which here amounts to keeping the number of sifting steps $L_S$ constant, any EMD algorithm can be applied. Furthermore the number of IMFs has to be kept constant in every window e.g. according to $L=\left\lfloor\log _2 N\right\rfloor$. A schematic diagram of the SEMD procedure is presented in Fig. 1.</p><p>!<span title="There is no note that matches this link." class="invalid-link"> <span class="invalid-link-brackets">[[</span> wsEMD.png <span class="invalid-link-brackets">]]</span></span></p><h3 id="properties-of-semd">Properties of SEMD</h3><p>Because of the segmentation involved, contrary to global EMD the local residua estimated with SEMD for every segment when joined together may result in low-frequency oscillations instead in an average global residuum, as the residuum is only monotonous in every single window, but not in the resulting global residuum. By choosing the segment size properly, it may be determined which oscillations should appear as distinct IMFs and which should be absorbed as apparent local trends into the respective residua.</p><p align="justify">These apparent local trends, which combine to low-frequency oscillations in the final average global residuum, may be down-sampled, because of the high sampling rate, to a useful time resolution and subsequently analyzed with SEMD again. This process can be repeated until finally a truly monotonous trend remains. Hence, this cascaded application of SEMD acts as a low-frequency filter for long-term oscillations and trends in biomedical time series.</p><p align="justify">Similar to ensemble empirical mode decomposition (EEMD) [11], also with Sliding EMD an averaging over differently decomposed data sets is achieved. While due to added noise, with EEMD a given sample is associated with different amplitudes, with sliding EMD the same amplitude is associated with different samples in different shifted segments. This latter behavior alleviates effects related with a non-unique data decomposition via EMD. Furthermore, artifacts resulting from end effects loose their impact via averaging. Finally note that while local IMFs fulfill all defining conditions, this is not necessarily true for the resulting average IMFs though the related deviations should always be small.</p><h3 id="weighted-semd">weighted SEMD</h3><p>Despite the averaging operations involved inSEMD,reconstruction errors due to the boundary effects remain to be observed in SEMD.In order to diminish the impact of the latter, awSEMD was developed recently. Every value of the ensemble of samples E, whose average forms the final time series, is weighted by a coefficient drawn from a predefined distribution of weights. These coefficients become larger when the estimated data point origins from the middle of the window, and smaller when it is located near one of the boundaries. The coefficients are assumed to form a discrete Gaussian distribution $p_{G}(E) (te)$ with E samples $e = 1, . . . , E$. Using such weights, boundary effects are strongly suppressed.</p><p>!<span title="There is no note that matches this link." class="invalid-link"> <span class="invalid-link-brackets">[[</span> wsEMDex.png <span class="invalid-link-brackets">]]</span></span></p><h3 id="improvement-of-the-weighting-process">Improvement of the weighting process</h3><p>In this subsection we consider an alternative way of applying weights to the time series to suppress boundary artifacts. It amounts to applying a weight to every sample of a window rather than weighting the estimates. Thus every window of the resulting IMFs and the residuum is multiplied by the weighting function. The latter, again, is assumed to form a discrete Gaussian distribution $p_G^{(M)}\left(t_m\right)$. But instead of weighting the estimates, every sample point inside the window is weighted according to its distance to the closest border of the window, which effectively suppresses samples near the boundaries. Therefore, the weighting function consists of $M$ samples, instead of $E$. Furthermore, the Gaussian distribution is shifted along the ordinate via $p_G^{(M)}\left(t_m\right)-p_G^{(M)}\left(t_1\right)$, so that $p_G^{(M)}\left(t_1\right)=0$ and $p_G^{(M)}\left(t_M\right)=0$, respectively.</p><p>This technique produces a more sophisticated and precise weighting of the estimates as several similar distributions $p_G^{(M)}\left(t_{m, e}\right), t_{m, e} \in[1, M]$ with $e=1, \ldots, E$ are utilized to weight the estimates. After the calculation of the ensemble mean of $K$ data points, every sample position $t_m, m=1, \ldots, M$, and therefore point of the weighting function of the window $p_G^{(M)}\left(t_m\right)$, has been used exactly once for averaging, as $K=\frac{M}{E}$ (see scheme in Fig. 3).</p><p>Hence $K$ shorter and slightly different distributions $p_G^{(M, i)}\left(t_{m, e}\right), i=1, \ldots, K$ are picked out of the weighting function and are used to weight the estimates, whereas all picked out samples for one ensemble weighting function have a distance of $K$ points respectively. The $K$ different distributions $p_G^{(M, i)}\left(t_{m, e}\right)$ can be described as â€˜partâ€™ of $p_G^{(M)}\left(t_m\right)$ using the following set of samples: \(\left\{p_G^{(M, i)}\left(t_{m, e}\right) \mid t_{m, e}=i+0 K, i+1 K, \ldots, i+(E-1) K\right\}\) To calculate the final result for a specific sample of an IMF or the residuum, the sum over $E$ estimates multiplied by $E$ weighting coefficients is computed and the value is normalized by the reciprocal sum of all used weights for that particular data point, so that the amplitude of the signal is preserved. For a step size of $K=1$ both methods, the weighted estimates and the weighted window SEMD, are the same, as $E=M$. Otherwise both approaches differ in that a specific set of weights for one data point is repeatedly used again-and only again-after $K$ samples. In the following, the improved wSEMD will be used for the further analyses.</p><hr> <side style="font-size: 0.9em"><h3 style="margin-bottom: 1em">Notes mentioning this note</h3><div style="font-size: 0.9em"><p> There are no notes linking to this note.</p></div></side> <a href="" class="post-link"><h2></h2><p class="post-excerpt"></p></a> <script src="https://giscus.app/client.js" data-repo="pavandonthireddy/pavandonthireddy.github.io" data-repo-id="[ENTER REPO ID HERE]" data-category="[ENTER CATEGORY NAME HERE]" data-category-id="[ENTER CATEGORY ID HERE]" data-mapping="url" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light_high_contrast" data-lang="en" data-loading="lazy" crossorigin="anonymous" async> </script></section></main></body></html>
